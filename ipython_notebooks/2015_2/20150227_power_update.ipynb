{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: J W Debelius<br/>\n",
    "**Date**: 27 Feburary 2015<br/>\n",
    "**Scikit-bio version**: 0.2.2\n",
    "\n",
    "The goal of this notebook is to compare the order of power loops. Currently, in scikit-bio 0.2.2, power is calculated by generating a paired subsample, and selecting the counts. So, we loop through the runs and then loop through the counts. <br>\n",
    "I think it will be more robust, and improve speed later, hopefully after optimization.<br>\n",
    "The new code has already been tested locally, and it passes in both python 2 and python 3. \n",
    "\n",
    "I'd also like to try timing the code execution. This is sort of a hacky way to do some intially profiling, but it will give an idea if the switch has signifigantly slowed the code. The idea of timing and profiling comes mostly from [this](https://zapier.com/engineering/profiling-python-boss/) blog post by Bryan Helmig.\n",
    "\n",
    "This change primarily affects the way `subsample_paired_power` functions. I could generate dummy data, but I'd rather check against real data. So, I'm going to profile AGE in American Gut rounds 1-14 in health adults. I've done a fair bit of work with this as a reference set.\n",
    "\n",
    "I'm also trying added the possibility of returning multiple p values, with the hope that this can be included in a generalized linear model for time series analysis. I'd like to follow up on timeseries analysis, but I think the code needs to be streamlined, first.\n",
    "\n",
    "### Relevant System State\n",
    "* Python 2.7\n",
    "* Numpy 1.9.1\n",
    "* Scipy 0.15.1\n",
    "* Scikit-bio 0.2.2\n",
    "* Biom 2.1.3\n",
    "* Matplotlib 1.4.2\n",
    "* Pandas 0.15.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports necessary functions\n",
    "import os\n",
    "import time\n",
    "import cProfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biom\n",
    "import skbio\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from future.utils import viewitems\n",
    "import skbio.stats.power as power\n",
    "from americangut.power_plots import collate_effect_size, plot_effects\n",
    "\n",
    "from statsmodels.stats.power import FTestAnovaPower\n",
    "\n",
    "ft = FTestAnovaPower()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class timewith():\n",
    "    def __init__(self, name=''):\n",
    "        self.name = name\n",
    "        self.start = time.time()\n",
    "\n",
    "    @property\n",
    "    def elapsed(self):\n",
    "        return time.time() - self.start\n",
    "\n",
    "    def checkpoint(self, name=''):\n",
    "        print '{timer} {checkpoint} took {elapsed} seconds'.format(\n",
    "            timer=self.name,\n",
    "            checkpoint=name,\n",
    "            elapsed=self.elapsed,\n",
    "        ).strip()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.checkpoint('finished')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define the new subsample funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subsample_paired_power(test, meta, cat, control_cats, order=None,\n",
    "                           strict_match=True, alpha_pwr=0.05, ratio=None,\n",
    "                           min_observations=20, max_counts=50,\n",
    "                           counts_interval=10, min_counts=None,\n",
    "                           num_iter=500, num_runs=10):\n",
    "    r\"\"\"Estimates power iteratively using samples with matching metadata\"\"\"\n",
    "\n",
    "    # Checks for the number of sampling pairs avaliable\n",
    "    sub_ids = paired_subsamples(meta, cat, control_cats, order, strict_match)\n",
    "\n",
    "    # Determines the minimum number of ids avaliable\n",
    "    num_ids = len(sub_ids[0])\n",
    "\n",
    "    # Checks there are enough samples to subsample\n",
    "    if num_ids <= min_observations:\n",
    "        raise ValueError('There are not enough samples for subsampling.')\n",
    "\n",
    "    # Checks the ratio\n",
    "    num_groups = len(sub_ids)\n",
    "    if ratio is None:\n",
    "        ratio = np.ones((num_groups))\n",
    "    ratio = np.asarray(ratio)\n",
    "    if not ratio.shape == (num_groups,):\n",
    "        raise ValueError('There must be a ratio for each group.')\n",
    "\n",
    "    # Determines the number of p values returned by the test\n",
    "    p_return = test(sub_ids)\n",
    "    if isinstance(p_return, float):\n",
    "        num_p = 1\n",
    "    elif isinstance(p_return, np.ndarray) and len(p_return.shape) == 1:\n",
    "        num_p = p_return.shape[0]\n",
    "    else:\n",
    "        raise TypeError('test must return a float or one-dimensional array.')\n",
    "\n",
    "    # Calculates the effect size vector\n",
    "    if min_counts is None:\n",
    "        min_counts = counts_interval\n",
    "\n",
    "    if (max_counts - min_counts) < counts_interval:\n",
    "        raise ValueError(\"No subsamples of the specified size can be drawn.\")\n",
    "\n",
    "    sample_counts = np.arange(min_counts,\n",
    "                              min(max_counts, num_ids),\n",
    "                              counts_interval)\n",
    "\n",
    "    # Prealocates the power array\n",
    "    power = np.zeros((num_runs, len(sample_counts), num_p))\n",
    "\n",
    "    # Calculates power instances\n",
    "    for id2, c in enumerate(sample_counts):\n",
    "        count = np.round(c * ratio, 0).astype(int)\n",
    "        for id1 in range(num_runs):\n",
    "            sub_ids = paired_subsamples(meta, cat, control_cats, order,\n",
    "                                        strict_match)\n",
    "            ps = _compare_distributions(test=test,\n",
    "                                        samples=sub_ids,\n",
    "                                        num_p=num_p,\n",
    "                                        counts=count,\n",
    "                                        num_iter=num_iter,\n",
    "                                        mode=\"matched\")\n",
    "            power[id1, id2, :] = _calculate_power(ps, alpha_pwr)\n",
    "\n",
    "    if num_p == 1:\n",
    "        power = power[:, :, 0]\n",
    "\n",
    "    return power, sample_counts\n",
    "\n",
    "\n",
    "def _compare_distributions(test, samples, num_p, counts=5, mode=\"ind\",\n",
    "                           num_iter=1000):\n",
    "    r\"\"\"Compares two distribution arrays iteratively\"\"\"\n",
    "\n",
    "    # Determines the number of groups\n",
    "    num_groups = len(samples)\n",
    "\n",
    "    # Checks the mode\n",
    "    if mode not in {'ind', 'matched'}:\n",
    "        raise ValueError('Supported sample modes are \"ind\" and \"matched\".')\n",
    "\n",
    "    # Handles the number of samples for later instances\n",
    "    if isinstance(counts, int):\n",
    "        counts = np.array([counts] * num_groups)\n",
    "\n",
    "    if not len(counts) == num_groups:\n",
    "        raise ValueError('If counts is a 1-D array, there must be a count to'\n",
    "                         ' draw for each group.')\n",
    "\n",
    "    # Checks the group length\n",
    "    samp_lens = [len(sample) for sample in samples]\n",
    "    # Checks the group length\n",
    "    if mode == 'matched' and np.array([samp_lens[i] != samp_lens[i+1] for i in\n",
    "                                       range(num_groups-1)]).all():\n",
    "        raise ValueError('In \"matched\" mode, each sample must have the same'\n",
    "                         ' number of observations.')\n",
    "    if np.array([samp_lens[i] < counts[i] for i in range(num_groups)]).any():\n",
    "        raise ValueError('You cannot choose more observations that exist '\n",
    "                         'in a sample.')\n",
    "\n",
    "    # Prealocates the pvalue matrix\n",
    "    p_values = np.zeros((num_p, num_iter))\n",
    "\n",
    "    for idx in range(num_iter):\n",
    "        if mode == \"matched\":\n",
    "            pos = np.random.choice(np.arange(0, samp_lens[0]), counts[0],\n",
    "                                   replace=False)\n",
    "            subs = [sample[pos] for sample in samples]\n",
    "        else:\n",
    "            subs = [np.random.choice(np.array(pop), counts[i], replace=False)\n",
    "                    for i, pop in enumerate(samples)]\n",
    "\n",
    "        p_values[:, idx] = test(subs)\n",
    "\n",
    "    if num_p == 1:\n",
    "        p_values = np.hstack(p_values)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "def _calculate_power(p_values, alpha=0.05):\n",
    "    r\"\"\"Calculates statical power empirically\"\"\"\n",
    "\n",
    "    if len(p_values.shape) == 1:\n",
    "        p_values = p_values * np.array([[1]])\n",
    "\n",
    "    w = (p_values < float(alpha)).sum(1)/float(p_values.shape[1])\n",
    "\n",
    "    return w\n",
    "\n",
    "def paired_subsamples(meta, cat, control_cats, order=None, strict_match=True):\n",
    "    r\"\"\"Gets a set of samples to serve as controls\n",
    "    \"\"\"\n",
    "\n",
    "    # Sets the index data\n",
    "    # Groups meta by category\n",
    "    cat_groups = meta.groupby(cat).groups\n",
    "\n",
    "    # Handles the order argument\n",
    "    if order is None:\n",
    "        order = sorted(cat_groups.keys())\n",
    "    order = np.array(order)\n",
    "    num_groups = len(order)\n",
    "\n",
    "    # Determines the number of samples, and the experimental and control group\n",
    "    group_size = np.array([len(cat_groups[o]) for o in order])\n",
    "    ctrl_name = order[group_size == group_size.min()][0]\n",
    "    order = order[order != ctrl_name]\n",
    "\n",
    "    # Gets a control group table\n",
    "    ctrl_match_groups = meta.groupby(control_cats).groups\n",
    "    ctrl_group = meta.loc[cat_groups[ctrl_name]\n",
    "                          ].groupby(list(control_cats)).groups\n",
    "\n",
    "    ids = [np.array([])] * num_groups\n",
    "    # Loops through samples in the experimental group to match for controls\n",
    "    for check_group, ctrl_ids in viewitems(ctrl_group):\n",
    "        # Checks the categories have been defined\n",
    "        undefed_check = np.array([_check_strs(p) for p in check_group])\n",
    "        if not undefed_check.all() and strict_match:\n",
    "            continue\n",
    "        # Removes the matched ids from order\n",
    "        matched_ids = ctrl_match_groups[check_group]\n",
    "        for id_ in ctrl_ids:\n",
    "            matched_ids.remove(id_)\n",
    "        pos_ids = []\n",
    "        num_ids = [len(ctrl_ids)]\n",
    "        # Gets the matrix of the matched ids and groups them\n",
    "        exp_group = meta.loc[matched_ids].groupby(cat).groups\n",
    "        for grp in order:\n",
    "            # Checks group to be considered is included in the grouping\n",
    "            if grp not in exp_group:\n",
    "                break\n",
    "            # Gets the id associated with the group\n",
    "            pos_ids.append(exp_group[grp])\n",
    "            num_ids.append(len(exp_group[grp]))\n",
    "        # Determines the minimum number of samples\n",
    "        num_draw = np.array(num_ids).min()\n",
    "        # Draws samples from possible ids\n",
    "        exp_ids = [np.random.choice(ctrl_ids, num_draw, replace=False)]\n",
    "        exp_ids.extend([np.random.choice(id_, num_draw, replace=False)\n",
    "                        for id_ in pos_ids])\n",
    "\n",
    "        if len(exp_ids) == num_groups:\n",
    "            for idx in range(num_groups):\n",
    "                ids[idx] = np.hstack((ids[idx], exp_ids[idx]))\n",
    "\n",
    "    return ids\n",
    "\n",
    "def _check_strs(x):\n",
    "    r\"\"\"Returns False if x is a nan and True is x is a string or number\"\"\"\n",
    "\n",
    "    if isinstance(x, str):\n",
    "        return True\n",
    "    elif isinstance(x, (float, int)):\n",
    "        return not np.isnan(x)\n",
    "    else:\n",
    "        raise TypeError('input must be a string, float or a nan')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll import the American Gut data. This has been saved in the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath('../..')\n",
    "data_dir = os.path.join(base_dir, 'data/ag_fecal_one_sample_sub')\n",
    "\n",
    "otu_ = biom.load_table(os.path.join(data_dir, 'AGP_100nt_even10k_fecal.biom'))\n",
    "map_ = pd.read_csv(os.path.join(data_dir, 'AGP_100nt_even10k_fecal.txt'),\n",
    "                   sep='\\t',\n",
    "                   index_col=None)\n",
    "map_.index = map_['#SampleID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'd like to define the test function. We'll test that there's a difference in alpha diversity between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_alpha(x):\n",
    "    vals = [map_.loc[i, 'PD_whole_tree_mean'].values for i in x]\n",
    "    return scipy.stats.kruskal(*vals)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_sampling_age done_age took 51.16091609 seconds\n",
      "new_sampling_age done_age took 54.0248610973 seconds\n"
     ]
    }
   ],
   "source": [
    "# Times the old skbio functions\n",
    "timer = timewith('old_sampling_age')\n",
    "pwr_age_220, cnts_age_220 = skbio.stats.power.subsample_paired_power(test_alpha,\n",
    "                                                                     map_,\n",
    "                                                                     'AGE_CAT',\n",
    "                                                                     ['TYPES_OF_PLANTS', 'ALCOHOL_FREQUENCY',\n",
    "                                                                      'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                                     ['20s', '60s'],\n",
    "                                                                     num_iter=500,\n",
    "                                                                     counts_interval=2,\n",
    "                                                                     max_counts=25)\n",
    "timer.checkpoint('done_age')\n",
    "timer = timewith('new_sampling_age')\n",
    "pwr_age_new, cnts_age_new = subsample_paired_power(test_alpha,\n",
    "                                                   map_,\n",
    "                                                   'AGE_CAT',\n",
    "                                                   ['TYPES_OF_PLANTS', 'ALCOHOL_FREQUENCY',\n",
    "                                                    'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                   ['20s', '60s'],\n",
    "                                                   num_iter=500,\n",
    "                                                   counts_interval=2,\n",
    "                                                   max_counts=25)\n",
    "timer.checkpoint('done_age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_sampling_EtOH done_EtOH took 34.7270410061 seconds\n",
      "new_sampling_EtOH done_EtOH took 36.4641721249 seconds\n"
     ]
    }
   ],
   "source": [
    "timer = timewith('old_sampling_EtOH')\n",
    "pwr_etoh_220, cnts_etoh_220 = skbio.stats.power.subsample_paired_power(test_alpha,\n",
    "                                                                     map_,\n",
    "                                                                     'ALCOHOL_FREQUENCY',\n",
    "                                                                     ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                                     ['Never', 'Daily'],\n",
    "                                                                     num_iter=500,\n",
    "                                                                     counts_interval=2,\n",
    "                                                                     min_observations=15,\n",
    "                                                                     max_counts=16)\n",
    "timer.checkpoint('done_EtOH')\n",
    "timer = timewith('new_sampling_EtOH')\n",
    "pwr_etoh_new, cnts_etoh_new = subsample_paired_power(test_alpha,\n",
    "                                                     map_,\n",
    "                                                     'ALCOHOL_FREQUENCY',\n",
    "                                                     ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                     ['Never', 'Daily'],\n",
    "                                                     num_iter=500,\n",
    "                                                     counts_interval=2,\n",
    "                                                     min_observations=15,\n",
    "                                                     max_counts=16)\n",
    "timer.checkpoint('done_EtOH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_sampling_season done_season took 48.9305009842 seconds\n",
      "new_sampling_season done_season took 55.2347548008 seconds\n"
     ]
    }
   ],
   "source": [
    "timer = timewith('old_sampling_season')\n",
    "pwr_season_220, cnts_season_220 = skbio.stats.power.subsample_paired_power(test_alpha,\n",
    "                                                                     map_,\n",
    "                                                                     'COLLECTION_SEASON',\n",
    "                                                                     ['AGE_CAT', 'ALCOHOL_FREQUENCY', 'TYPES_OF_PLANTS', 'SLEEP_DURATION'],\n",
    "                                                                     ['Winter', 'Summer'],\n",
    "                                                                     num_iter=500,\n",
    "                                                                     counts_interval=2,\n",
    "                                                                     max_counts=22)\n",
    "timer.checkpoint('done_season')\n",
    "timer = timewith('new_sampling_season')\n",
    "pwr_season_new, cnts_season_new = subsample_paired_power(test_alpha,\n",
    "                                                        map_,\n",
    "                                                        'COLLECTION_SEASON',\n",
    "                                                        ['AGE_CAT', 'ALCOHOL_FREQUENCY', 'TYPES_OF_PLANTS', 'SLEEP_DURATION'],\n",
    "                                                        ['Winter', 'Summer'],\n",
    "                                                        num_iter=500,\n",
    "                                                        counts_interval=2,\n",
    "                                                        max_counts=22)\n",
    "timer.checkpoint('done_season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I think the switch is more expensive, and kind of a pain-in-the ass for running big sets of data. But, I also think it will allow more robust sampling. Because, theoretically, we'll be able ot determine how many runs and counts are necessary. Or, at least, that's the goal.\n",
    "\n",
    "More importantly, I'd like to see if the change ultimately changed the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collates the power for age\n",
    "age_mean, age_bounds = collate_effect_size([cnts_age_220, cnts_age_new], [pwr_age_220, pwr_age_new], 0.05)\n",
    "etoh_mean, etoh_bounds = collate_effect_size([cnts_etoh_220, cnts_etoh_new], [pwr_etoh_220, pwr_etoh_new], 0.05)\n",
    "season_mean, season_bounds = collate_effect_size([cnts_season_220, cnts_season_new], [pwr_season_220, pwr_season_new], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculates lower and upper bounds\n",
    "counts = np.arange(5, 305, 5)\n",
    "etoh_220_mean = np.array([ft.solve_power(effect_size=etoh_mean[0], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_220_lower = np.array([ft.solve_power(effect_size=etoh_mean[0] - etoh_bounds[0], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_220_upper = np.array([ft.solve_power(effect_size=etoh_mean[0] + etoh_bounds[0], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_new_mean = np.array([ft.solve_power(effect_size=etoh_mean[1], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_new_lower = np.array([ft.solve_power(effect_size=etoh_mean[1] - etoh_bounds[1], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_new_upper = np.array([ft.solve_power(effect_size=etoh_mean[1] + etoh_bounds[1], nobs=c, alpha=0.05) for c in counts])\n",
    "\n",
    "season_220_mean = np.array([ft.solve_power(effect_size=season_mean[0], nobs=c, alpha=0.05) for c in counts])\n",
    "season_220_lower = np.array([ft.solve_power(effect_size=season_mean[0] - season_bounds[0], nobs=c, alpha=0.05) for c in counts])\n",
    "season_220_upper = np.array([ft.solve_power(effect_size=season_mean[0] + season_bounds[0], nobs=c, alpha=0.05) for c in counts])\n",
    "season_new_mean = np.array([ft.solve_power(effect_size=season_mean[1], nobs=c, alpha=0.05) for c in counts])\n",
    "season_new_lower = np.array([ft.solve_power(effect_size=season_mean[1] - season_bounds[1], nobs=c, alpha=0.05) for c in counts])\n",
    "season_new_upper = np.array([ft.solve_power(effect_size=season_mean[1] + season_bounds[1], nobs=c, alpha=0.05) for c in counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x102dba9d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD/CAYAAAD/qh1PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4nNWV/z9nRr03y5IsW7LccMUdm2aDsYFUEhzIZluy\n",
       "iUmyvw3ZX2Eha8hoFkjCQ7KbhWSTBcKmLJtAICEV22Ajm2Js3HuRJXfLtrrVRtLM/f3xvmON5OlN\n",
       "7X6eZx7NzFvufTV3ztz33HO+R5RSaDQajWbkYhnsDmg0Go0mtmhDr9FoNCMcbeg1Go1mhKMNvUaj\n",
       "0YxwAhp6EblXRFaIyJoA+z0U6jEazVBERJ7ys02Pbc2ww6+hF5H5AEqpjebreT72uwNYGcoxGs1Q\n",
       "REQeAO71sU2Pbc2wJNCM/j6gyXxeA9zhYz/PGM37gzxGoxlyKKWewxi33gj2+6DRDCkCGfocoNHj\n",
       "df7AHURknnuGY5Id6BiNZpgS8Pug0QxFglmMlQDb88I4RqMZruixrRl2BDL0zfQZ8lygwXOjl9l8\n",
       "wGM0mmGMHtuaYUlCgO0vAwuBjcBE4E0AEclRSjUDFSJSgXELm2cuTnk9xhMR0boLmpiilIrazNtj\n",
       "vOuxrRl0whnbfg29Umq3iCwUkRVAs1Jqj7npLWChUuo1ADPULNs4RO3xcUzEnY0UEalUSlXGu93B\n",
       "bHuUXnPYxlZEVgMLReRLSqkXzLfd493X96EfsR7bsfy/iogVyAC+CWOeh9I8yMqG5AzIthg3Mnnm\n",
       "IwPja1+aCSUlkD0WUgoRSxFiKUAlFKCs2YjLibW7nYTODhI7ukjscJDQ1UmCw0Hrd8ZR+JUjJHT1\n",
       "YO3sxdruwtrmJP1cEllnUsm4mExafQopV1JIakshqSuVhJ4UEnpTsDpTsKgkFA5c0gF0oFQHik7j\n",
       "OZ2AgzeYyF3sBrqBLsBhPnci9GIEkzgRFIIL6DUfTsCF0IvgNPdxAj1YcJjnMR4/4q/4Kj82j+sx\n",
       "j3Wfx2U+1IDnasD7KuCjks5wPtdAM3qUUs+bTzd6vLfQyz7P+ztGoxkOKKVeBV4d8N5Cj+cjamyb\n",
       "hj0XCvOhYjx8JA8qBNZNgG/PhqIuGOeA4npIUcBYYBYwDdRUYDLicpHYUUdqfROZx6+QeeEy6Rer\n",
       "yTzXSua5NhIdnTiTnDgTe3EmOenttdDbmUTS5SyObruT27Y6SWsrJNmRS7IzlwRXLoouFPVXH1AP\n",
       "NCDUY6UJoQVoAdoRFJZrftutQBKQRBN/SQq/xzCWnj/CXUCH+ej0eLiNda+Xh0vZrlWClEpZpmzq\n",
       "wyh8JH6RyvDmEAENvUajGVmIiAUYAzPK4O4JMNcKs1wwuw2mXzLMwsJ2WH0ZyARuAhaDWgAqkeQr\n",
       "x8ipraNo9z6Kd71J1vkOnIlOelMd9KR1o6x9htCRbKWtO4WE89kUVI8ju6GUjK6xpPQUYSGFFjoo\n",
       "5jLCPqycAc4BFxC6grycJCAVSKbPiAvGTLsVuEwLF4H3oN8svNubwR6pjDZDXzUK2x6sdge77ZFM\n",
       "VTgHiUgKFJbB7dfBTamw1AFLmyDHOWDXVPhqEvAUqJlYHYfIqz7Gda//D0W7WwBFT7qD7swulFVx\n",
       "ZVzfka5eCz31aVguplN0uJy8pjIyHeNJUGNQVAMHsVAFVAPncXI9CXh1gXkh1Xwkmq8VcAU4jxH2\n",
       "2o45O1c21XP1uislQ9nU2RD/XaFSFePzR4QMhh69iKjB8NFrRgeDOb6G4tgWkWQongSLZ8LHBFY1\n",
       "w4RuL7tOAj4J3Ial5wAFh3ex8EcNZFxSuBKcdOa240oa+KMALocVR2M6adXZjKuZSkHbZJJc5SiO\n",
       "YuFDYDdwDMP1EXS3gXQgzXyuMKKeLmAY9TagTdnUtf0ZwYQ7vrSh14w4tKE3EBGBrAlwy0K4xwqf\n",
       "aoB8b4ZxFvBXwCSSm9cz96eHKduShMvqoiuvDWfytccoJzgaM0g4kUHZ0akUXplBoioFtiJsAXZA\n",
       "yAuHqRgrvBaMxck6DFdOM9CqbCqUH4oRiTb0oxARlgPLzZfL6bt9rFJqaN9KxhJt6EFEMuD6BfCJ\n",
       "cfCleh8z+AnAV4FyUhp+w83fqSG/Opue1G4689u85oY5uxJwnM+kYM9YKupmk+a8HtiNsB7YhrGI\n",
       "GQoZGDN3wZCXOAlcBlpG22w9GGJm6EXkXoxf1AqPiAPP7asxPqDPKKW+Yr73lFLqYRFZ4+OYIfFl\n",
       "GEmIoJTSWZugDb2IjIWP3gxfccHHmrzskgL8HbCKhPZXuOnpfRTtGUt3Rhddee1eT9rTnkTPyXTK\n",
       "dpczoWkxVvIRfg/8iT79n2BJw1jkBbiIoRtUr2yqI8TzjDrCHV9+F2M91fpEpMLMhN3tsX0FsEIp\n",
       "9VUReVhE5pqxxWtE5NPAl0PtkEajCQ/DVVM4Fb64AB5qhGneIldmA4+A6yDTfvcwc14qwZWQS+v4\n",
       "Bq8z+N6ORBy1mUzcUcaE1luwAMJLGHePocy4EzC0ghIwQiU/AC4qmwo2ukYTAYGibu4DNpjP3Wp9\n",
       "Vw29KX/gjifO80ggWeNOptJoNLHHMPLjZsNfz4aH67xE0gjweeCjpDT9kBX/3Ex6XSntY5u9L7D2\n",
       "Wug6lU3xtjFMbliOlTSEFzDCFEPx96YBWRgJSkeA08qmWsO5Rk34BDL0wahXZgMPAN/2eDvPnO3P\n",
       "V0o9HXEvNRqNT0wjPwf+bib883kzscmTDGAtkMqEqn/ihh+Ox5mYzpXx3rV6ui5lkLwjiyU1i0lR\n",
       "sxB+gjHhC2UGn4Xhe28E3gXq9GLq4BFMHL1ff5BSqgV4WkQ2iMgupVSt2y8vIitFZIUX4TONRhM1\n",
       "SmfBF2fCIxe8GPki4GlQ21nyb29Qvnki7YWt9KZeu2jqdFjpOprD9G1lFHV9HGEj8LcY8enBko1h\n",
       "4M8BWzF876MmMWmoEsjQB1KvnI+hb7Mb2AWsFpFmoNF03TQAFXhJFxeRSo+XVUqpqnAuQKMRkeX0\n",
       "RR+NKkSyy+Dv5sAj3mbyE4DvIj0vc9s3DzLmcBmtpY39MlfdOOrTSN6Wzc01y0hkLMIjwNEQupKJ\n",
       "cedwHnhH2VRjgP01cSRS9coVGAYeDDfPdgz9iR3me/l4UfgDGCyhLc3Iw5wkVLlfi4ht0DoTR0Sk\n",
       "AP7qRnjokhcjPxl4CmvXC6z6v3Vk1hV7XXBVTug8mcuEd/OpaL0fYRPwTQyfejCkYEwGLwFblU3V\n",
       "R3ZVmlgQkXol8BxwnylV3KSU+g1cLaAMUO9L4U+j0YSPiKTBnbfCPzVDyUA3TCnwFNbOZ7nz/7aQ\n",
       "Vp/JlXHXhkC6HFY69ueyYPtUsp13IHwHY7IWDBagAEMYbAtwTrtohi46YWoIEUkClI6j7yOS8RVE\n",
       "3kig7TEf28bi66yb4F8K4VMDXSQFwA+wOn7Bnf/7PGn1mbQXXRvl0tOehGt7NksOLCOJfMCGMSsP\n",
       "hmyMLNaDwBFPXRlNbIlJHL0mvpjGvAquGu7lg9mf0UYQeSPzgBrzTpeB2+NHZhl8agJ86vyADWnA\n",
       "04jz96x8+Azpl3NpK2655vDu5lSS3slh4cmPY+Ui8HWCc9VYgTEYcfBVyqauPbdmSBJMzViNZrRw\n",
       "H31Znu68kYE8Zf6tGAwjLyKZsHIRfOXywE3AN0Dt55bHd5B1Ot+rkXc0ppOxMY9FJ/8KK7uBfyE4\n",
       "I5+JYeR3A5u0kR9e6Bm9RtOH37wRcyZfKyKNwJq49uwqs+fBF3u8+OX/Ashj/nP/RfGeicbC6wAc\n",
       "l9PJ2ZjD7Mt/g/BrBhRY8UMhhlrkOmVTzRF1XzMo6Bm9RtMfn/5PEcnB0FFfAzwvIhPj1iuj/SK4\n",
       "sxQ+MtDYLgA+zbht/8aUNyZyZVzjNZfhaEwnd1M+sy9/HuEXBGfkE4FxGNf8pjbyw5eAM/owRc38\n",
       "HqPRDFH85o1gGPj/VEq1mvkiq4FrMr9jkSNilPy7dQH8zcDomSzgEVIan2bpv5bQUdB6TZx8d1Mq\n",
       "WZtymHXpr80s13VBNOlWlXxX2dSpSPuvCY9o5YhEW9RsHuZUwtcxGs0QJlDeCEoZOi3u8e3tJLHJ\n",
       "Eckrh49nwuy6ARv+EZybWbG2G5c1kd60/i6dnitJpGzO5foLn0P4H4Iz8nkYRUI2KJsKVZlSE0Wi\n",
       "lSMSyHXjd3FKKbVRKfVV82WeadDv93eMRjNUcU9IfOSNoJR6WkQeMvNEvEpwxwKjQtSN8+BzA+8w\n",
       "bgMms+g/NpB+MYfOgrZ+W51dCcgHeSw48xmEdcBvg2iuECPp8U1t5EcOsRA1yw50jEYzVPEw3hs9\n",
       "3lvo8XwQRPrGTIRPWgYswOYAXyOn5kkqNo3nSkn/eHpXrwXH7lxuObIKC/uAXwRoRDB0cWqBHVqA\n",
       "bGQRdVGzYI7RaDTBISJJ8NGZ8PGBiVEPIM6NLPuXBBxZHdf45TuP5LBk5yIScALPBGjGAhQDB4B9\n",
       "OsN15BF1UbNAx3gcW+nxUouaacJmZIua5U2AuxJgrOcMewawiPnPf5OkK0W0DZA36DybzZz3JpOq\n",
       "pgL/gH95YSvGTH43cFgb+ZFJLETN3vJ2zEC0qJkmWoxUUTMRSYCVs+HTnrN5C/B1Uhp+xqT1xbSV\n",
       "9Dfy3c2pFG0eQ3733Qj/gBH/7gu3kd+mbKo66hegGTLEStTM2zGaAIjdY2b6+WWIfXOlualK2a69\n",
       "4wl1f81wI3M83J0M/Yz5R0F1sdx2jt60tH4uG5fDSsK2PKY1fgbhXzE04X3hNvIfKJs6EZv+a4YK\n",
       "WtQshkQkUmYXpWyB/0ci3AqsYlnlWjZXPglsUIotYXZ5RDASioMbwmW3fBRe7IHJDvPtFOAlxu76\n",
       "Nsv/JZvWCf3doh3787m56mMkcgz4kZ/TayM/TNGiZkORSo/P4+SyZZRvrup7I/IfWNPI36kUa8Vu\n",
       "X6uqKh8V4UkRGO3GfgRQAEszYfIFj/c+jTj3cdP3kunMv9Jv7666TGa/P50EkjHutH1hwTDyH2oj\n",
       "P3rQhj6GmO6TKgCxi03Zor4usUop1vZrU7FWhMdBG/rhzZzJsLLD440M4D4mv/EtErrS6czvK+/X\n",
       "25FI7ruF5HevRPh7fC++ukMo9yibOhazrmuGHFrrZnjjK9Y5lCLOmiGGUVRkehks91SI/CyWnveZ\n",
       "+7M02gv7K0f2HMxh5oWPIjyPf7/8WOAwcCj6vdYMZQIaejMLcIWIeFXrE5E15uM7Hu895d4Wva6O\n",
       "DkS4VYQneNuGCE+Y7hlf+Lojs8aib5p4UTgeVrk8Pt4c4OPMeGUjCoUr0XV1184LWczbMR8rdcAf\n",
       "/Z0UOA3s1SGUow+/ht5T68Z8PW/A9hXAW2Y2YYX5GmCNiBwHtA8wBDx87o9ymx2leBS404+x3yDC\n",
       "kwPO8S18hLRqhj4iYoFZ18EdnkqR92J1bGHGb7LoKOyrFuV0WMl/fyxZvUuB7/o5bS6GLMmHyqZc\n",
       "fvbTjFAi0roBKjzeq8GImwdYo5SaopTaFJVejh68+tyBld52Nhdc14vwuHkH8DiwTi/EDmsKYEkq\n",
       "THAXA0kDPsHMV97HZXX2C6d0HM1h+vlVpstmYOasmwwMV967uuTf6CWQoQ9UiOF5D22Q+cAO83me\n",
       "6e55KDrdHDWE7HNXii1K8Zh5B/CYNvKREYSrcr5b1Cw2PZhRDjc7PN74OJbu3Vz3m1TaC/sibRxN\n",
       "aczcNgsr7cCffZwsCUNq+B1lU52x6a9mOBDMYmwQsdwyH9jpTo4yfwA2Avke7hxNYLTPfRAJ5Ko0\n",
       "eUQp9RqQ42N7JO0nwsQyuMW92JoIrGbSus24EnvBYszmlRNSdoxhTNftCN/De6yuBaP033tahVIT\n",
       "kdaNByuUUt+AqwuwjeaXoQHDvbNx4AFa68YrG0R40tN9Y/rcg9EQH7VEUevmPmCD+dztqvSsv7Aa\n",
       "+BBipmI5Bm6yQobbj34H0nuKuT9XtI/tm813XcjmhmM3IfwOOOPjXIUYAmVnY9BPzTAjUq0bROQB\n",
       "96A3Z+819Llw8tFaN0GjFFtEMHzty2xIpfa5B0MUtW4CyXIvNM8/D7gj+sZ+QQXc5Bk7/xnGbfs1\n",
       "wFXfvNNhpfi9MlJc5cBjPk6UB1wADka3f5rhil/XTaBCDCJyB/AdEak2CyYr87b3DrOcYL3WugkN\n",
       "7XMfdAK5Kus9vhf3Rq1RkWQoHwc3uqNqrgeXlRueaadjTF+kTfeJHCZfWoHwH4DDy6lSMVw523WE\n",
       "jcZNwMxYf4UYlFJv0efa8TzmtWh1UKOJI4FclQ0YhTnc+y4Crhnr4bklk8fCLXh8Je8hp/ZtrL3W\n",
       "q3HzPe1JTPtgNhYawatWkhXjruQtvfg6MohLzViNZpQRyFX5KkbNBeiT5b6G8NyS8ybBUresQT6o\n",
       "hSz5t3fp8NS0OZzH2PZlCL6i2QqB3cqmLofevmYoEq+asZoICTHTFbHLrWKXJ8znT4hd/O6viR5B\n",
       "1IytBZpNl02eW5Y7Ugy3TelYmO/Wjv8Yya3vk3Ve4UwxQm67W1KZsWsBwnbAm3Z8LlAHaA0bzTVo\n",
       "Qx9DQs10NY36ncqmHgUw/97pz9jrH4bo4g4N9iz8PaBm7PNKqdfcUWZRogBuwLzBtgIfY+av9tKd\n",
       "0ed+SdpbSK7jBoQXvRyfZB6n/fIar2hDH1tCynQFVimb6r+/8drr/uH8MGiGInMmwAK3UV+KpecS\n",
       "k9d34sgx3nM0pTHj4GKEN4CLXk4wBtiqbKrdyzaNJmaiZn6PGUWEmuka6v4h/TBohh5GucDxpbDI\n",
       "7Yu/m8J923Em9Y2FjJ0lZPTOAv7byykKgGplU/5UKzWjHL+LsZ6ZgiJSISLz3H5Mc7tb1KxWRF4x\n",
       "Xzf6O2Y4E0bFqARzdr0KDNcKsAGUr0zXUDNjtUzx8CcP5ruTpPJAzWHRjzbTmW/46x1Nacw6fgPC\n",
       "q8CVAcemYHzWe+PbZc1wI9qiZhXA/RihZ76OGbYoRZVSVCpFJbDM/dxnWcC7Hqzj0Ke/1c+1cuje\n",
       "b3PXg95uvwE2iF36q1HaxZ8apZZMGPZMKoGFbgGzlaQ07ySlqedqglTmjnGk9U7BSxgnRkLXVmVT\n",
       "XXHqrGaYEgtRsxz6xx8PzC4cPSx5tohXXvvnfuqSr7z6DZY8O9bb7sqmDDVKuzwOYP5dZ77vjVB/\n",
       "GDRDCKMubPlEuMFMiFJ3MfUPh3FkG752R1MaU6uXILwCdAw4fAxwTNlUXTz7rBmeRFvUzO2iGfGF\n",
       "v4Ok10emq281SpvaomzqMfP5Y36MfDg/DJqhRQ7MSoaxvcA0xJXCtN9dpifDmOFn7RhPWu8k4LcD\n",
       "jkvGGEP749tdzXAl6qJmwR4zSkTNYu5aMY36FrHLo+4fiNFGFEXN4kxuASxw/+jfTU7NNlyJhmZ8\n",
       "d0sqs6qXILwMDMxyLQCqtMtGEyyBZvQvY/jdYUCmoHsHL6JmXo8ZiFKq0uNRFfYVDG20ayUOKKWq\n",
       "PMfTYPcneKaVwex2IAHUbcz9aS2deYbbJn3PONJ6K4DXBxyUB5wEzse1q5phTSxEzXwdM+rQrhWN\n",
       "L4xs2HH5MKsDWIDVUceYw62oBBc97UlMPrIYw8h7zuYTMO4G9+i6r5pQiJWo2TXHjFa0a0Xjg1wj\n",
       "fiEBYAVFew7QnWm4YpIPFpPZPR3hiQHHFAA7dGKUJlR0ZqxG40GwyX6Rl8mcVASzeoBkUDcy+6WT\n",
       "OLI7cXYlMGnvYoxiM60eB2RgrH/VRNauZjSiDX2IXBUpM54HFCmLcV+Wi1ApQqUZvllpPpYPVp+G\n",
       "M0GWEnS7LCPMPh5fBguvAEtIbKsl84Jh1KV6DLld15shlVebBDKBD7WWjSYctKEPgX4iZRBQpCyM\n",
       "84dkuPslcBnhm/4TuDSBCJQg6CYi/7iIZMKkVCjpAXU7pR8cpSunA9UrTNqxEMW7gKfUcD5wVNmU\n",
       "r6g3jcYvEWvdmPs85e31CNS6CVWkLCS04R50ApUSxJT0iHDtKTkXFiggHdRCZrxaQ29aDz3n8ii4\n",
       "shALv/LYOdH8eyiyNjWjGb+GPphbWRF5ABhYUm2NiBwHTkSpn0ODBc+Vil0qxS6VfH45V58veG78\n",
       "YHdNEzUCJftdE3wQOrMmwOwO4EZSWo6R2tQGLijbej1wHCN80k0+sEvHzGsiIVDUzX3ABvO5+1a2\n",
       "n0CZUuo5EVk94Lg1I7Kc4M4HzqodD1QCiF1symbEbJtFvDXDH7/JftGYzYuIBe4sgrmNoJYx/t0a\n",
       "OvPacTSlU1y/EAvf89jdvQB7MpI2NZpAhj7grawP8sw4+vnuZKoRwgYRnvR034jwLYwICc3wJ1Ap\n",
       "wQoRqcD4HuT5UmYNkPWdDdOtkJEMrvlM/eMPcCU7Kdo6A6tyADs99s0C3tQLsKOXeNaMDVm3xh1H\n",
       "LyIrRWRF5D7NoYFSbBHBECdbZnPP5NeZ+jWaYY5SareILPSRILjQfZdqrj1l42NR1n92bkYuzAFY\n",
       "TEpzLSmtV2hNS2L8mUWm3IGbXKBW138d3cSrZmywWjdXMYuQuH32DfTJIYwIfIiUeUWHPw4/ApUS\n",
       "9NhnSnhZ39PHwXXt4FrGuG3VdOa2k76/jOTeQuRqgqEFQ7jsQASXotFcJdCMPtCtrDdqMOSKwbjF\n",
       "9arrMtiiZmEUEQkZ8zxVAGK321RVZaXfPtn73aZtFvvV/1GVso1YPaCIGS6iZiJihbuKYF4LcANT\n",
       "/vwfuFCUHViE4g9Aj7lrAXBQ2dTAQiMaTVj4NfSBbmUBzIXYhSLyJaXUC2ZlqXtFBKDe16xnsMWn\n",
       "+hlhQSk1+IbCNOZVg9yNYUe0bm/jQBZcZ4GUhSQ3nyO9voW2ljFkd87EgjtEOQmjctjRQeynZoQR\n",
       "kdaN+fxV4NUBx4y8iBsTb6UBtUiZJjgy8mCuAucySj48TmdeO2Vv3oJiB31uUXfVqG4/J9JoQiKY\n",
       "xdhhQTxcMaaRv1PZ1Fqxy1plU4+KXZ4UuzAYxl67eoYb142DmV0gS5m0/kW6W1IpbFyAlW+aO6Ri\n",
       "6NucGcROakYgI8bQx8kVs0rZVP/MWMPoPw7xj7zRrp7hg+mfHwtzx5HU3kTW+XrSdsxCVAt9Wa+5\n",
       "wNvKpnRxd01U0Vo3odHr4339xdQEIhtmWhC5icL9J+hI76T45ALkqtszC6gzHxpNVAk4ozdDJZuB\n",
       "Cs+QswH7PKWUejiUY2KBKS62ynxu+M99hD/2c3t8fhli31xpbvLn9gipNKB2rWj6yMiBOQrULZRt\n",
       "fp3kY+NJ7SnGcnXtKx14TxcU0cQCv4beU+tGRCq8ZQJ6aN08HOwxscBDWXKtCGuV4lERnhQxYt8H\n",
       "7q9sqkoEF7CKZZXw06oE/PwwALD165fks5/awsu/3WQmTFVy/z0raP76r73trl0rmj6mjoObC7D0\n",
       "JjB2/1lK9tyNizex0I3hsjmp1Sk1sSKQ6yagbKtS6jn6F0MIVuo12oSkLNlPcthIfgooOazWff8Z\n",
       "pr/+KJVi5TY7VIqV6b9bq9Z9/5moXolmRGHo24wZi5QuIP9YNe3dVnJb55DAbzAyz5OBg4PcTc0I\n",
       "JpChD0frJlx9nEgJ1X8eluSwsqkt7pKAyqYe06GVmiDIhElWhJsp/eA4JTvmojgBnKNPa741wDk0\n",
       "mrCJidZNmMdExvznJ4ndUJbs53Of/1wFeJXF7/UWEw864kETbZKzYWUOylJK6du/ovDcFxBewFjb\n",
       "saCTozQxJupaN2EeEzm71jxPpUpUNlVJ+WaUTVVSqZLYteYFr/vPfbECIybeqBZl/L2TeT+ZGJf+\n",
       "akYRU4tg6RxyTp0g+cRYknrTsfIexmz+gLKpjsHuoWZkEwutG6/HDCTaWjdKsUXufnCO3H/uHVKX\n",
       "Ifff+w53jXtZvfGMd9fKkmegUoFnsnylEr48F/hiJF3RxJloat0EihjzqJo2SSn1SBDnE1gxDmvm\n",
       "QoreOU7xkQW4eAMrFgy34sgqzqMZkvid0bujZXxo3WBuu6p1E+CYgeeu9HhURXohYpdbWfJssXr5\n",
       "tVuYuBn18mu3sOTZYtM9cy1Fe2uA9SI8bipLPg6so3hvbaR90cQXpVSV53gK9zyBKqqZY/ot8weg\n",
       "wnwdiHSYk44reQ5lvzlHzpWZJPI6xmx+r7IpR7j91WiCJWDCVCDZVqXUq0qpPKXUC/6OiQNes1bx\n",
       "vbia4ENy2GtMvGZUEChirMLjvRqCk+DOhr+YRWpDHaXvTsLJAQyZgy505ShNnBgxEgicX1AqQiXA\n",
       "1Rh3gAcW+KrnukHs8qTnj4PYxW+1KJ0ANeLxGzE2YOIyH/oV8fbB1EISyhYy5sAJCi7MRXgWYw1r\n",
       "q7IpX5FiGk1UGTmGvmTnWaUM4+6p/S72nV7ruSqb2iJ2wdSpcf9d5y9cUidAjQoCRoyZLp6dwRUe\n",
       "KSnBlTOP2T94h8TeJKzsw7iTPhtxTzWaIBlJWjcbxC5Per5hztC9LgaDjonXXEOwEWMrlFLfCHQy\n",
       "EUmBz83E2gOT3yzDyRsYJQh3a+EyTTwZMTP6cGboGs0AAkaZicgD7oL3vuohe0SUpWNpX0zxByfJ\n",
       "apsOfBdjDeBCzK9EMyKIVkSZqEHQUBIRpZSKWVKV2EUpm//z9/O3n1xmo3yz3dyk/e3DnEjGlxk+\n",
       "WYNHeKWI7FBKLRSRO4BXMPz4ecBqpdQmX22LlMwg4dCf+PTqJiZv7CGJfwc2KZvSCpWasAh3bEes\n",
       "Xultu1vNUkTWxCvyJuSF0sp+P3Cb+20bqoXoNDHHX0U1pdRb9Ll2guDT03GlFlOxJQ3hP4GL5kOj\n",
       "iSsRqVf62b5GRD4NfDmWnfck1IVSz0IlGk20EZEEEt9YyZRXL5LQk0YCRzHi5rUMsSbuRKpe6Wv7\n",
       "GqXUlIG3tRrNKCIbmbGIJd+z4qQKOK1sqn6wO6UZnUSqXulre56IrBCRhyLsn0YzTJmZjzVlBuP2\n",
       "FpDAJuDAYPdIM3oJJrwykOP/mu3uzFggP8g0cY1mZJH4zx9lwY96cboOY2WXsqmmwAdpNLEh0GJs\n",
       "oLhiz+05QIMZtdColHrN3L8Cj4UtN9EWNdOMXqIpahYNRERI3n4XCx+yILwFHB7sPmlGN5GqV3pu\n",
       "r8AQO8sDdpjH5+MjYSkS8SmNxhNzklDlfi0igx03lUlR/Q2kNbpI5GVdVEQz2ESkXull+27TZXOH\n",
       "GXZZH1w26F7UAAAgAElEQVSauEYzgkj+wRzmvZSBy7ERPZvXDAFGZMKUZnQzmONLRBRjf//vfPGz\n",
       "X4OOlepJHXmmiR7hju2RpHWj0QwN7v+0ix7nMZJ4f7C7otHACNK60WiGDHm9z0Lvn5RNdQ12VzQa\n",
       "0K4bzQhksF03emxrYoV23Wg0Go3GK7ESNfN7jEYzVAlnvGs0Qx2/M/ogiiVfsz3QMYOJmVgzqtoe\n",
       "jdccLuGM93j30Wx3+UhoI17tjJQ2IiEWomb3Ycx4fB0TNHL3g/8g969+R+67r0ruX/2O3P3gP4R7\n",
       "LpPlER4/HNserHYHu+1wCFfEL94sHyFtxKudkdJG2ARy3YQjahbomKCQux/8B7LOfVa9/NrNV9+7\n",
       "/9535e4HUW8884NwzqnRBCBcET+NZkgTE1GzqJB1/n5PIw+gXn7tZrLO3xeT9jQag8EZ7xpNDIm6\n",
       "qJn5PGCBZREJGNcpr3jfx9f7wTCYOiiD1fZovOYwCWW8RzS2IyUe/9d4fXYj5VqG8liPtqjZmxgz\n",
       "nmuO8UTHGWuGKKGMdz22NcOGaIua7fFzzKhDRJ4a8PpesyDLmji3+5T5N6btDnfCGe+D0tEoE8w4\n",
       "jXTsBjMm4/X9GJUopeL2AO4FVmCUGox320+Zf+PSNvAAUO3xej5wr7sPwLx4tGu+1wgcB26P8TWv\n",
       "MR/fiedn7qPdeH/eMbtOb9cSrfaCGaeRjt1gxmQ0vh/Bjr9I/nfBjrUI21htHvvjaF1H3DJjh0AM\n",
       "8hoROQ6ciEdjSqnnMELw3MQlNM9LuxCHGr7mLPctZSQRVZgzs3lmn2L2mXtr19wUt887DmO737VE\n",
       "s70gx2lEIdNBjsmIvh/Bjr9I/nfBjrUotLHCPLbCV59DbSOeEgiDHYM82AXLBzM0Lx41fCvo+0xr\n",
       "zNf3E6WcihDanWg+j+fnHeuxHVWjGICYhUwPYOCYjLSNYMdfJD9awY61sD8fpdRGpdRXzZd5ynAX\n",
       "3u/lfCFdRzwN/WDHIA+FguWDslCn4lDD12zDLQkwH6PKmGckFsTgM/fRLsT384712I62UQxEzMep\n",
       "jzEZdrshjL+w/3chjLWIPh8RyTbP9W3zrWwv5wupjXiLmg1aREI8jF0AggrNizYissbUZ4G+Gr6x\n",
       "bG8+sNOciUCcPnOPdvfAoHzeMbvOaBvFAHgLmY7q2PUxJqPSRjzGX5BjLZIfrRal1NPAl0XEfdcQ\n",
       "0XXE09APiqGD+Bs7H7zs0a7X0LwYUYMZNYLxq/9hjNtboZT6hvk8np/51XYH4fOO2XXG0ij6wHOc\n",
       "ukOmoz12vY3JaLXha/xF80cr0FgLuw0Rme/hb9+FsTAb8XXE09APlqGD+Bs7RGQ1sFBEvgTxC83z\n",
       "0m7caviKyAPmTMR9nXH5zL20G+/PO5bXGUujGNQ4jXTsBjMmo/H9CDD+ovKjFeRYi6SNFfQ36iei\n",
       "cR1xLTxixsfWMAgSrx6/uhOVUt+NZ9ujARG5A3gFw2+YB6xWSm2K9Wfup924ft6xvE5v1zKY36Wh\n",
       "SCjjL9z/XShjLYI2sjEWWjGPvXrnEMl1DEqFKY1Go9HED11hSqPRaEY42tBrNBrNCCegoQ9Gf8KL\n",
       "jsV88zitWaHRaDSDTESlBM33HsDQXPDkEaXUa0DOIEgdaDRhE2hiIyIP6UmMZrgRaSnBa3QszFCq\n",
       "D81tT3skLmg0Q5pAExsz6gJzEjPJI5lFoxnSBDL04aTyLsTIEJs3yHIDGk2oBJrY3EGfSNoJL9s1\n",
       "miFJNEoJeqPeIwFioFtHoxmqBJrYNHi8lwtMikenNJpICWTow0nlbQBqPY5fFF7XNJpBwd/E5lX6\n",
       "jHsFUB/77mg0kRNpKUFvvIqhzwDGDGn7wB0kDjU1NaMbFV5JP78TG6VUrYi8bPrum7lWY12PbU3M\n",
       "CWds+zX0SqndIrLQi/7EWxg/AP10LJRSL5hfhmbTZZPn1oWIRmcjRUQqlVKV8W53MNuOd7til+XA\n",
       "cgD+zOf5CD81N1Upm6qKSx/CN7Z+JzamgV+olHpeRL6slPqNt5PEemzH4zON17gZKdcSx/9XWGM7\n",
       "0IweDw2FjR7vLfR4/irGLN7bMa+F0ynN8MU05lUA8rbYlG1wfljDIdDExtxeYU5ifjx4PdVoQiOg\n",
       "oddoRhNBTGz05EUTF8QuAmRguMCL6XMrhsxoM/RVo7DtwWoXyget5ZFO1QhpI17tDJs2xC5pGOtD\n",
       "JUApkISDBFpIwGHNB2d45x0M9UoRUYPho9fEF7GLUrZBWYsZtPGlx7YmFMQuCRiGfSwwAcjCidBE\n",
       "Ig2JVhrG5OPIzoQiSD+fy5+Pfi3qi7EazWjD9L8340PjO9B2jSYQYpd0jHyMMgyXjNBGAg0Il8bk\n",
       "0p6VhyqyIGNdJOR0kpZuJPFZLmaG22ZAQx/MwBaRp5RSD3t5/yFfUTcazVDDUwLBXHSd5ynhYUbd\n",
       "1JiLsgzcrtF4w/S1Z2PM2iuAbJxAExYuJifRVFhET14qlEJCbhcpWS2INap98GvoAw18cx+3qNnD\n",
       "A96/A1gJaEOvGS7cB2wwn7slEAYa8qeAVRgTn41oNF4Qu1jo87VXAKl0A5cRLuZkcSWvEFdRIlLi\n",
       "JCmnnbTUJr8njJBAM/qAA18p9ZwZSz8QnTiiGW74lUAwZ/K1ItIIaPVKTT9M456HYdwnYSykwkUs\n",
       "XMzPp62gAEoFa2EPSTntWBJc8epbIEMfjqiZ+5Z2o4hc487RaIY4Phe6RCQHqMYw8s+LyC6lVK2v\n",
       "/TUjH9Mtk4MRITMJSKELxSUs1BWMoX1MPowXrIVdpGY1R9slEyzBLMaGE0EQdrynRjOIBNJ2WgP8\n",
       "p1KqVUSaMaQ+rnFNikilx8sqpeKTEayJH2KXDGAcMBVIoxvFJYQL+QW0jSmACRYSCjtJy26KqJDf\n",
       "yT2TaTg7GYDEhuxwTxPI0IcsauaezYfbIY1mEAmo7aSUajX/bhSRCm8nGSyZDU1sEbskYSyoTgPy\n",
       "cQKXcXEhO4eWwiLUBAvWom5Ss6M3cy+fW0353GoAktdP5lzrknBOEwtRswrzC5AP5PmKTNCzHk20\n",
       "EPHQ14mAICQQnjZrLNRg6Djp8MoRjumaycOwfxWA0IyTcykpNIwtxTk+GUtpDym5rUhC9NclM87n\n",
       "UHhwFpkXZpHUOpHXwztNwIQps2RaDR7hlSKyw50Wbi7EPgf8k1LqhQHH/RPwGY8vjHubTioZBeiE\n",
       "Kc1wReySjLGoOh3IoptezmPlQlEpXUXZSLmTpMI2rMnhpar6REFuTREFR+aQUTebBEcuHfmHqJ96\n",
       "hJ2r8tn/zY+EM750ZqwmZmhDrxluiF3yMGbuxuy9gV7OZuTSVDwONdFKYnEHiVld0W1VQf6xcRQc\n",
       "nUt63fWIK5GOwn2cW3CcD/4xg/oZs+nIn0RGbR1XppbpzFiNRqMJEbGLFSNDdQaQTw+9nEc4V1yK\n",
       "ozQbKeslecyV6IZDKsg7Po4xh+eScXEuILSN3cOh1b9l+/8qoHHq9TiyFpN+6QhjDu6k7J3/JvOV\n",
       "MfyR/x1Oa9rQazSaUYnYJRVDX2YGkEwrPZxJSebyuCmoigQSSzpIy2oMcJrQyKktpPDAfDIuzEeU\n",
       "hbaiPRy47zW2/30hjdPm0p2xlIwLBxm3/W3KNh8lqaM3Gs1qQ6/ReOBP8sPMFN9BX2Wpt5RSX4lz\n",
       "FzURInbJwoh5n4ILuIyTM3n5XBk3FpnkJHnsFSxJ0Zu9p1/MomjPfLLOLsDak0Xb2N0c+eRrfPD1\n",
       "MTRcN4/uzKVknj/A+PfepHzzMRIcUfb7x0jrxlyIBZiklHokKj3VxJ1+1aKMv1Xm87hVi4onQUh+\n",
       "5CqlLOa+84CYpq1roovYJR+4DhhPL07OA2dKynCUZZJQ3k1aXmNEMe+eJLYnUbxzNrknF5HUNp6O\n",
       "gv2cuuUN3nsog0tz5tOVcwMZdQcZv3Uj5VVHY2HcPYm61o0ZmvaWWVLwFRFZoePqhyf9qkUZC6vL\n",
       "B7M/ccCv5MeAcbxQh1cOfczwyEJgJjAWBz2ctggXxk/FOSmZxAntpGdGyT2jYOy+CgqOLiatfg6O\n",
       "zFrqp27n/f/3HmdunEdb0V+TVl/N2L0fMHHTT0hu64lOu4GJhdaNe8X6efOYCjyq9Wg0Q5igJD/M\n",
       "ycwrcemRJixMA18EzAby6aSb2pRELpVORU2xkjyuleTU9qg0llGXTfGuxWSdXYyy9NIyfhtbH9zJ\n",
       "4dWzaCn7FIkd9RQc2cHcn75KxqWOqLQZIlHXuhkwy5kP/CqMfmk0g0UwoWsr9V3q0MTDwF8P5NJG\n",
       "F7WpqTRMmIqaJqQUXcEShdh36bVQsmMG+ceXknylnPbCPRz5xK95//8UUT/jBlyJt5J74kPm/eTf\n",
       "GXOkPuL2IiRWWjdut8/OgclSGs0QJljJj/n+TqKzvuOPaeDHAnOBXK7goCYjncYJ1yFTXSQXRyc8\n",
       "MvNcLsW7lpB17gZ6kxtpnPQB7z20lVPLF9Je+AUyLhyg4q3XKdtSjcUVeZLSUNW68WCFUuobYfVK\n",
       "oxkcAkp++NK38URr3cQXsUshMAco5ApdhoEvn45M6SW1qDlyaQKXULLzOgqO3kRy60Tainaw52//\n",
       "m21fq6Bxyl1Yu9sYc+gD5j//K9Iao5tM5al1Y904gXOHhozWDSLygLuylK/FWD3rGZmIsBx3pM4y\n",
       "G1JJpbmpSqnYFGmOl9aNezfgRKRtaSLHzGKdA5TQThc1aSnUl09DpjlJLWqK2MAnN6dSuu0Gck7d\n",
       "hMvaRePk93j34W3U3r6YzvwvkH16NzNf+QklO89F5YJiSNS1bszKUq9g+PbzgNVKqU0DzqnTxIcZ\n",
       "4cgZaAkETSwQu2RiJDlV0EU3J1IyuVRejlynSCmOXFwst7qI4t23kn55Lp15hzh56w7e+UYJ9dNv\n",
       "xNrTQeH+95nyxi6Sr3RH5YL8Yem2ktqUjqXXSmt1Cuv2/ZPWutFElf6z80obmyvt5qagZufa0Gui\n",
       "idglBUP/fQY99FKTkMyF8kmoGRZSxrVG5oN3CSU7pjPmyDISO4poKX2PHV85xYHPLqCteBaZ5/cz\n",
       "4Z13Kd1+JlrX45Orxr0nAWdSDxdnn+fsjfWc/lUqrud+qQ29JmboGf3Qb3ukYmrRlAPzcGLhDMLp\n",
       "8ik4pyeRMr4loiiahI5Exm9dRO6J5Sirg/rrtrDxCcW5JTfRm5JNwZF3mfLnbWRcjE4opi8sPRZS\n",
       "mjKw9lhxJvZeNe5nirtw7sqC9yzwYSt8+GctaqbRREigTHAzmmwiWo8+LohdioAFQCYX6KWmpBzH\n",
       "tAySK66QnNYW9olTG9IZv/UWss7cRHfmSU6sep23K0uon/FRktovM27bJiavP4DFGbuZsDiF1MZ0\n",
       "rN2JuBJ6uTjrPGduvmwY9w+z4JUUOOiEI/vhch3QEm5T2tBrNCbBZIIDjyil7hORh3wV1dFEjumH\n",
       "nwuMpwkHx/PH0DalkKRp7aRHIDSWdSafcduXk3FxPu1j9rL9f/032782m5YJf0nm+QPM/uVzFO8+\n",
       "H7ULuQYFKU3pJHYkoawuGqZe5OSyOs5M6KJnVyb8OhUOuI37BaBVebhdRMK7WdSGfhQx2rRrwsBv\n",
       "JrgZePAhgDuqTBNdxC6JGH742XTh5HhaCvWTr8M6vZv0wlDCu/uTd7yYkh13kNo0jZbS91n33Zc4\n",
       "+NmldOb9FfnH3mPp975N1vnw7xACkdSaQvKVVACaJ17m1M0XOHVdG137M+GPybDPCccPwPkLQIuK\n",
       "sk89VqJmAY8ZDQw1wzoKtWtCJVAmuDvSbB5whzb20UXsUgwswkkapywWzkycgmumldRx4YdKjjlQ\n",
       "TvGeO0i6Mp6miZv587MHOXHnLfQmz6NobxU3PPPzmGnOJHQmktKUjriE9sIWau6o4dS8VlpPpMF7\n",
       "ifDDVDhyFM6eA5qibdz7dcXfxjBFzYK5/R0VaMM6LAl0b1xvxtvfISL3KqVei0uvRjBilwwMN80E\n",
       "LtPL8eJSHNOzSJ7UijUlDD12BWP3TqZo7yoSugpomPY2658+wJmbb8PS62Dc9o1M+fO+mPjfpddC\n",
       "amMGVoeV7owuTi4/wamlDVxqSoStKfBSOpyoheOngUalVBSLmfgmFqJmAY/RjGzELrcCq8znTwAb\n",
       "lE1tGdxeBUWgTPAGoNZj30XANYZeJwMGhxlNMxGYRycWjmak0zhtPInTO0nLDcMPr6BozxSK9t6F\n",
       "tTuLi7M28cb3E6lbcDtJbZeYtOFVyquOIzGYOCc3p5LUnoqyOLk08zwnb7/I6RQnamsGPJkBJ87A\n",
       "vlqMiULQP17RSgaMuqhZmMdohiihGm1z/zuVTa0Vu6xVNvWo2OVJsQvDwNgHygR/FXBPanKA7d5O\n",
       "oiUQAiN2yQUW4SKPUxYLpydOQs22kFbSiFhDP2HRnskU7bkba3cmF+Zu4o1n0rl4/V2kNp5i+msv\n",
       "xiT+3dqVQGpjBuK0cGVcA0fvOU7txHa69mXCi6lwtAF27wfHRaWUI5wmzElClfu1iNjCOU+sRM10\n",
       "HPEIIEyjvYpKtV4qecKUQHgC1HoqZSUwpA19IAkEs8ZCs7kGlad99KEjdkkApgOzaMbFkTFFdMzM\n",
       "J2VKS1humsJ9FRTvvpsERw7n57/Nn5/N5NLsj5J+6RhzfvEjivbVRfcKXEZIZEJXEr2pDk4uP0Ht\n",
       "0gbqz6XA5iR4JgEO74VL55RSsVvcDZFYiJpFIoSmGVqsUja11vMN0+g/ji+jfWHeOOBOpVgrdvta\n",
       "VVX5qAhPcmFeSRz6GzEewQMbPd5b6GW79s2HiNilALiBHrI4npzMxakVWGc5SC8I3UYUHB5PyYcf\n",
       "IbGzkAvz3uZPP0zn0uyPkFF3mHkvPkPhoctR7XxCRyIpzRmAomnyJWpuP8+pNCfOD9LBlg5Ha6D6\n",
       "FNAQy0XVcImFqJnXYwai/ZjX0k9yYGCUjhfJgVD3D4NeEQzXzdXZORuoxHcmYlPFZKX4gudbSrFW\n",
       "7q+I2Ww+Wn5MTWwwQyZnADO4DBwtmUDPnDRSJjaHLFuQe6KI0g/uJvlKGRdnv80ffnySi9ffRUbd\n",
       "Iea/8P3oar+7hLQGY/buyOqk+u4jVM9t4cqhdPhlChy+BHt2m66ZuFWLCge/hj4YNT9zIXahiHxJ\n",
       "KfWCn2MGnrsyepcxQqj08HidXLaM8s1VfW9cO0kwjXkVgAhKKf/GLmRlybrrK4DEa2fn15f6bOT4\n",
       "XdVilyc97wTELt/i+PMxU3yMlh9TE336zeIPp6VTf10ZibM6SMsOrd5u5rlcJrx7N6mN06mftplf\n",
       "/u4s5xbfQUbdEeb/5N8Zczh6M3gjLDIDUVA/rc6YvQNqSyr8KgkOHoQLZ5RSV6LWZozRWjcxxmMx\n",
       "cy3wJEFGoISqE2Ma+uD3D+L8Mu/Fn3PPF8+Y7hqlbErELt/idy+MU7u++Lc++vEElbIBWAk8CjwB\n",
       "vEmlWqkUjwXbv0iIZHwFIYHwlFLqYRFZ42P7qBnb/vDwxc/mInC0rBznnCRSxzeHtNia0pRGedVK\n",
       "Mi8spql8K3/6YQenli8jrb6GKX9ax9gDF6PTY4Xhe+9Mpju9k9M3n+b4nGauHEyHtyxw5CzsPQ5c\n",
       "jldIpDfCHV/a0MeQAYuZbkP5JLA+kLEfEoZeqKRSNnGt0b5dqat3AwOPMa5Z0XfNwreAdUrFZzE2\n",
       "7C+DqWOjlHrNlOfe4SVvpBFj3enLA+W3I2l7JCF2yQGW0E0+R9LTqJ8xgaSZV0jMDF7WN6EzkfKq\n",
       "W8itvZ22sXtZ/91LHL1nGckt55m87g1KdkVHA97SbSWtPhNRFprLLlG98iynAOfmFNjeAXsOQ9M5\n",
       "pdSg1HodSLjjS0sgxJbQFzOHFgnmD9IWscujyqYeA5BKVvo6QCm2iIAIj5vuoceJo5GPkGByQNbo\n",
       "JCnviF0swCRgAZexcmT8BHrnJpM2viH4WbxLmPDufMYc/ijdGWdY//Q6dq25mQTHWKb97udMeP9k\n",
       "VDqb1JpCcmsarsQeztxYy7GFjTQeS4WfpcCh07C/GiPmfdBm79FEG/rY4itcLPLixPFhgwhPKkWf\n",
       "v92cnfs7yDTqW8Ruf1RVVcbFXRMlgskByTPXn+br8Mo+xC7pwEJ6Gc/R1FQuzpxA0qw20jJ9VqK7\n",
       "hrF7J1Gy45Mgih1f2cjb9kUoy1Imbnqdio1HIk90cglpDRlYHYl0FLRyYPV+qvN66H4/BewWOLAH\n",
       "Lp0dKrP3aKINfWzx9f8NIyMk/gzz2Xm4+L0t9qiyttJXmczRhtilBFhKE6kcLBlHz9xU0sqDn8Vn\n",
       "ncmnbMsnSGobT/Vd7/CHH03CkXs7pR/8mWm/2xVxkW2rw0pqQwaiLNRfd4Fjt9RxtiEB1ifA/ouw\n",
       "+xhwaaTM3r2hDX0s2fr1S/LZT23h5d9uuhrlcv89K2j++q+jcfp+ommfX4bYN1eam6ImmjaMZ+fh\n",
       "4DcHxPTbN5qumwagAo94e4/9Kj1ejtjQYXPBdQ5OplOTmMKZ6WUkXt9JWk5ws/ik1hQqNq0k8/wN\n",
       "XJz9Pq+91EHj5Nsp2vsWM77/XyR2RXbnm9iWTEpLOs6kbk7dWsuRqa207kuBf7fCwSNw5tRQj5yJ\n",
       "lwRCMFEI12wfDPXKOMSUh4xa9/1nxC57zKxQuM1uBdb6lRDwErfuawatbKpKBJexfyX8tCrB3/6h\n",
       "nn8UEihvpAbYYe6bj48ckdEQOix2yQaW0s4Y9hcU0DE3l9QpQcbFu4TyzYspOPIR2sce5aU/fEDt\n",
       "ihvJrdnOzd/5Fun1neH3zB0905FEV14bBz61n+o0F91VSfByJ+zcCY4LoejNDCbRCh32G3UTKArB\n",
       "23aPDu42fZmNXiIXYhqZEGoEStDn/ciD/0hG3T3GKzUXxMgRaCt6Xf35me/7PTa4KBdvEStGlI4X\n",
       "YxzW/nNf/BL3fPE07nDP138ygT1/90IgYz9aSgma47iG/hOXHe7sWHMSA8a4/2402x4uiF3KgRs4\n",
       "TxrHpk5A5jlJKQwu3X/MgXJKt30aZXGy+bHDbHtwKWn1tUz/zR/Jrw6/oIg4hbTLmVh6EmieeImj\n",
       "N9ZxutmCestiiIkdrsawRUMuazUUYhV1EygKwdv2t4CnMGLHK0aSD9M05t+HmMkOr6JS1oudJ8w2\n",
       "nqCS9VQqXzoxqzwXSsHMQhW8R/UYRv6MqVljaNcgTyLqi/BFPasnKAmEURtxY2a4zqOHqRzOyKZ+\n",
       "ThEpM1qwpgaeHaddzmTipo+T2jSVw/d8wB/+cwbIDKb/9meM33oy7E4Z/vcsEEXdnLMcmdHE5WOJ\n",
       "8IILdh2Ay6dH4uJqqESqXnnNdnMmX2vGG6+JQh9HD/NeMHRiBoiIMe+FEviStyNCi+qZ9sdyZVN/\n",
       "4/mWsqm1cujezfDFiLquGdmYrpqbaKaQAyVj6VmQSvqEBrAEOLDXQsWmW8irXkn9tD38dNNJmitu\n",
       "oHTrH7jud7vCjqRJbEsipSkDZ0o3J2+t5lBhF+3bEuBf22DnQXDUDRf3TDyIhnplv+0ikg1UYxj5\n",
       "50Vkl1Kq1uuRUSQeC5MxZ8q6ycqm+uvE2NRaObR6iw9DH1pUjzPR+94uvSbvJtj1JRF5aLSEV4pd\n",
       "JuBiKacTsqidPp6EucEtuBbuq6B0+2p6U9p47Re7Obx6PgVH3uHWx18Ku6pTcksqya2pdGV3cPCj\n",
       "hzlm7aVnkxX2noP9xxiiomKDTaTqlZ7bc8ztDwD/qZRqFZFmDP3ua74Q0Y5MGFDNyaZsw3BBLLem\n",
       "2mvc+pdrfOnEhBbnXnD0pPfzHz0ZnQsYHKIVmRBsdTQRuQMjW3hEG/qrUTUOZnMoK5um+WNIndqM\n",
       "Jdl/NEza5QwmbvoEKc1T2P2FPaz/3vWkNrez+AdPk1sbfFz9VcwF1sSOFNqKmti/oobaZnD9wQV7\n",
       "j8KpmqEkCTwUiVS90nN7BYZ//g6lVCv0fWG8nXg0RCZAiFEuxbvPYRjvfnHrFO/2momqFFvk7gfn\n",
       "yP3n3iF1GXL/ve9w17iX1RvPeD9/0d4X+Mr1XxLZ23f+r1w/nqJ9w7qubxRFzYKtjjbiZ4xmAtSN\n",
       "NDOefROKcC1IJL00gJywS5j49lLyj93NpZkHef6DejoLpjHljZco3xKGqJ2Z4JTQlUTTxIscnFfN\n",
       "uVMCP+uCPQeh8Uy4BT1GG34dbO7ZjA/1Sm/bdyulnhaRh0TkXl/CT8MZscutZqUlxC5PmHo23vft\n",
       "i4p5lNvsKMWjwJ3m+97YQKXcqRSPmfs/RqXchS+pZ7vcypJni9XLr93CxM2ol1+7hSXPFvvqk7Kp\n",
       "LRTte4FKgdvshlpm0b7nh0Hlp3gRMDPWnOWPmAADb4hdCnFxF6etk9g9pxzLbS5SS1v8HpR3bBxz\n",
       "f/p1ss4t4rX/Pszz22eScWkvyyu/G7KRF6eQXpdF5oVcGideYtMnDrHB0sC5HzfDY+/Apj8q1VCt\n",
       "jXzwjChRs77Zc+VaNlcaSpFRjBEPVaRMFjz/Cz7xgDHITy6zUb7ZDsDvn6tQO9f8zcD9PdroJyLm\n",
       "yxCLXZ5QNvWo+fxqKKPY5XG3Lo2fawlNNC3I/ftLIVfa2FxpNzfFLZ8hAlGzH2O4Hd2hwSuVUo8M\n",
       "2GeFeae6QSm1KlptDwXELgJMpZvFHM7Mp35+AWnXNWJJ8h0bn9iWxKS37iLjwiL2/eV+/vTDGaRf\n",
       "PsLs//kDmXXtIXXA0mMhrT4TlIXz15/mQGEHLduB3edg92EM7ZkRfzflj1EvatY/prxPO13kanZn\n",
       "NAitTN6uNSfUzjWVZv9sbsVHDx34a/AmIuaHIael008j3263qarKysHqSxgEyowdsbN5M3RyAVeY\n",
       "yb6SQnoWJZFRWu/3pr9k+wyKd6+mZcI5frSnniul47nud//F+A9OhdS4oSCZhbI4OTPvDAcyHLS9\n",
       "74SXTsDRY0op/3cTmoCMGENPqDHl4RB6mbxYa93E9PwhFyoZ/gRak6ow15zyMcTNfC3WVnq8HPIS\n",
       "CGKXDOBm6ijn8PRiEhZ0kZrr27imXc6k4q1Pk9Q2njefOsmHfz+V4l3rWFD5HhZn8DNua1cCaQ2Z\n",
       "OJGqt5cAABMESURBVBN7qVl4kkPWbjrf7TZm72dqdPx7HCUQhhG9HkU+MP3oG0BFb3Ybepm8sNQf\n",
       "Q2CD12pOUTr/MJ+dh0ygimruZCkzezYbH4uywynQQOxSSC/LOJFSzNl5haTOavZdpFtBedUNFBz5\n",
       "GKdvPsHLr1pI6nCx9N+eIutc8JoxCZ2JpDVk0pvczdEltRxx9ODY1AE7DkDTae177yNagQax0rqZ\n",
       "jzEjyovbYuzcF42yd9ckG/2kNGrJQCGWyeun/sjVv1FTf1Q2tUXsgqlv7/67LlqLq/1yE2Cz2K/O\n",
       "VIdPbkKIBMqM9dhnWAcZmP74SXRyE4fyx9K6KIP0inqfipNZpwuY+PZ9KEs6v3y9jlPLS5i0/pdM\n",
       "rDoedKMJHYmkNmTSm+bgwOJajrV10/OnVti1H66c1QlOscOvoQ8UV+xn+yNKqfvM6Buvt7dRZ8kz\n",
       "UKnA8/euUglfnkvUDP3uL53jk2s2DDSs7P6S30IcwBYRHo1FKb0QffqhnrsKRqSLZlQjdrEC82hm\n",
       "PgfKi3AudpE21rvOjPRamPTWMnJqV7D/L2r5w49LyK/eyzL7xqDVJRPbjSzWnrQu9i2upbrJQe8f\n",
       "m+C9fcCFkSwPPFSIutaN6cP8ECCumYNFe2uATdfGoO+9PYqtbKBSuUXEHlU29Vg0XTGh+sRjvb9m\n",
       "5CF2SQWWcF5mcmRWIUkL2knJ9O4qyasupmzLX9CVrXj+g1ZaypKY99PvM+ZIfVCNuQ18d3onexac\n",
       "oqauk97fXoIPDwAXR3sETTwJpF75Y+DHSqk93sLNvG33OPxljOQpb1mxUQ9BCzXUMFxZYzO6ZyXL\n",
       "Kh9lc6UR/hiEKyYWNV3juX84DEf1yuHcdiDELjn0soya1MmcWZBL2owmr1mulm4rkzesJOvszWz9\n",
       "x7O8bS+hdNvvmP7bnUFp01w18GmdHJx8mdqzHfTuPAd7DiqlgvuR0HglluGVIWndmNSbC1t3iMi9\n",
       "cVL8C2lhst9Co2GElwfTyCgrxKEZIYhdiulgBUfyJtCyJJmMid5DJ/OPlFL27udoLe3hBwd7cCW1\n",
       "cOP3fk7GpcARMJ4Gftes09Sc7sD1m1Ow/7BSKnwJYk3ExELrBqDWY/siIOaGPtSFSbHLci7M+1sa\n",
       "pkzik6nIZzq3kH/8BMW7fzZSFxo1gQki+GA10AR8Rin1lXj3L1SuJkG1cCsHJ5TQs8RJ2tima3a0\n",
       "OqxMXn8nGRdu5O3Ky2z7WgaT3/wfJr4deLH1qoFP7WLXdWepOX0F16s1cPiIjoEfGkRb6+ZNoAVD\n",
       "yAwM47/d24ljEWsc0sJkpXIB55XiC6aL4VazaIeLcJVSBjDAPbRZJIAPfRRGuUSDeImame7JFUqp\n",
       "r4rIwyIy1yMEc8hhLrrO5aLlRg5PLyRhUZtXf3zB4fFMePdzNE7u5b+qILGzhlu/tS6gwmRCRyKp\n",
       "jZl0p3Sxa9o5Tta00vvrY1B93K13pRka+DX0QcQVe90uIs3mzCjP14LsEIg1DjnBqp8hPrmMQIbY\n",
       "0z0UDKFGuegfBoN4iZqZWbHusMu8IW7kk3GylNNJi6mZn0XqnCasA/zxxiz+LjIuLOXNp1rY87dw\n",
       "3e9/RMnOc35PntCZSGpDBt3JPeyedI7amhZ6XzkKNce1iuTQJKCPPoiKO962u98bytV4QpYP6CeF\n",
       "7CFpMFjo8MeoE4yoWTaGFPe349WpUBG7ZOLgNqozZ3PxhmTSp14bH59/tJSydz5H/TR4cbOQ1rCT\n",
       "ZU9UYe3xHepo7UogrT6T3sRe9pRdpOZUA72/PgKnqpVSoenaaOLKSMqMDZVYyxNohid+gw9Mn/PT\n",
       "IrIhXkV1QkHsUsAV7uLYmClcuclJ+vj+i6CWbiuT168k88ItrH+6gwOfbWHmq//FmMOXfZ7U6rCS\n",
       "Wp+F0+JiX+klTpxupOe3B00DP+plCoYDo9nQb5B5L/7cLJRtSCa8/mIZfGFYZzz6Q7t6AhJI1Gw+\n",
       "oEy//S7iVFQnWMQupTTyEY5MnEDvjZ2k5vWfZedVF1O2+S9pmJLITzdBZt3b3PrkViwu7zGTlh4L\n",
       "aZezcaE4VNhA9dnLOH57AM5WK6U643FNox2tdTMA+ciD/0hG3T3Gq9Utct99VQC0Fb1uFvXuT6VA\n",
       "3RyoVIpllbC5UvGV6xX3/B2+6kqEurg61NCunoAECj5YgWHgwU+gQbzXn8zImmlcsN7FsRljsC5q\n",
       "ITm9u2+HXguT3ryN7DMrePPbDg589gKzf/kjck96r/YkvRbSL2Xiclk4kt/I8XOX6PqjNvCDQLTW\n",
       "nwLq0YejdeOxzWtdzaGQVPL/2zvX2CiuK47/j1/r9xrj2KWA40fsPFoi7DgSCSRN67QRQkRpsHBK\n",
       "lKbQQNQKoUgVjdoPSVatlKBU/dBGfUA+9BlMGvLoK20wwUDACi8TkxSM8dpe413b67eNbYzt2w87\n",
       "a9Zm1zPemTv7Oj9p5PXOzpy5e/9z5u59nKMnljujjUhcMKUELLNjbuymM0KICqV/frPy0SIhxE+M\n",
       "tB3U9dooHlMoR4elEm3l6UheNXcRlLXtNhTWPY2h/Azsf9eCTNf7uPvdM34XPtE0IbUnE5iKx5Ul\n",
       "g2h2deHaF41ARws7+PBAyoIpHbFuIiGvZtjFcmdCz0KTD5T++bDp2iMbJWEc69CW8TBca+KQWuIz\n",
       "6DpDKDq8FktaN+DIy5NofKYdq956B9arfqY9zhDSejJA1xNhtw7hsrsLI7XngY4rQogJUwvFSMHw\n",
       "WDc++8M7joVrdfFs14tv3Jfny/zmuGWYcIJslIZhfAv2nAoMPjSJtBU3B13TXVkoOrwF13LysPfU\n",
       "NNLc72Pt6w23tuIFkNqbgbgxCxxpo2gaasVgQwO34KMPNUevNt3M735vJh4ielH/JUpi2fl9eIWU\n",
       "tICeWOtKyIQ3Q31pkQwP+MqHbLQEfdiAlvyvYGLtCFJylJkvAsg/fh9ymjbh5I9mcO65ZqzafxAZ\n",
       "rlvntqf0piN+NBnOlHFcHG9G/7lz3AcfvciKdZPt572wQnYs91gl0gd8NYxJbVdeFs/PJ2sGZKM8\n",
       "uOKeRGtpAWbW9MGS4Rl0Te5PQ/GhakwnFeEPR6ZhGf4bHvxl4y0nSB5IReJQKroSJnFp3I6ehtPs\n",
       "4KMfw2PdRFJeTZmx3JnIQ2MIhFohRCsRve1NFG7a9b1EBbiaWIX2e5ci4b4eJCqDrstP3YPcC1tw\n",
       "/nuE+hea8NW3DyK9e+7UyqThZFj609FL07g41grXldM8Dz52MDrWTS2iNK8mE74YNdcY6mNSRcq2\n",
       "T9lfBJ9BW1mQjQjXsArO1G+j8/4kJN/TA0oQSBy1oPijJ5EweS9q3psGiRqs+fWFOQcnjiYhuS8T\n",
       "A1MCZ8cdcLZ8ihlHMzv42MLoWDcNUG6MaMqryYQ3Bsa6WXBMal5XTjmAmiDtaIZsFI8hrMHVJRvg\n",
       "fvAGUoo8K1hzLxRi2dln0bzBgmM/vYi7PnhnTijhhPFEpLgzMHQ9ERcmHGh31GPG3syhCmIT1Xn0\n",
       "UoyGxzz6RxAo8QgPGkY0wepLSaTze6UBc0uiHZ/PlcMTpljqPHqyURLceBTOvK9j8OEhJH9pFPHX\n",
       "41FUuwEp/Wvxz99OYSKrBqX/vtmKj78ej5RuK66NW3B5ogMdjnpcb7vEDj46kJl4JCqJ9EFDRgpq\n",
       "Y1JeKv05eS9GdEuSjVLhpMfRWXA/Jh7qRbJ1HNlXlmH5qW3orMjExz+/hDv+c2C2FR93Iw4pXVZM\n",
       "jKbg84lOtHXWY7z1fxxNMrIxLAR3rLbomehFR4u+DJ4uyX1EtBvAISVNpndMCkS0QwixV3l9y2Cs\n",
       "EdomG1nRHv8UnHeWYuaBLiRapnD70W8gy/EYDu2ZwkDBfpR+6GnF0zQhtTsTk4PpaB13oa2rHiP2\n",
       "z4UQI3qugQlPgtY2O3om2pAYAuFRAG/D04+fDaBKCPGxUbYBgF6kPDiTn0HPqjxQuQvWniys+HQb\n",
       "hlfm4tCrl5B/osbTip8hpHVn4EZ/BjrG3LB3ncRg22fs4KMbdvQMoxCpycHpBSpGV8Yz6KuwIOGu\n",
       "bqw89SByLj+BE7un4Szbj5KPGj2rWXsyMNWbBddoL9rcJ9HT2sAZnWIDdvQMoxBpjp5sRHBhNfqW\n",
       "fgcDD0wgK30Sy09tw5QlH7WvNSGv8a9I7xlDijsdM+5s9AwNoq3/EzjtZwXnZI0ppDn6YKJXqq0e\n",
       "ZEfPyERn182Celc+s0cI4Te8x2Jtk43i0Y6vYeDLGzGyrg/5zhLkfv4UGrYKONa9hcK6RiT3p0K4\n",
       "ctA3OIL2/hNwtJ3yjhkwsUXYRK+Ep+8yZKsHGSZY1PSufGYHgE0AdMdxIhsl4Ur84xgqeBgzq3tR\n",
       "+sXTSLpWin+9cRnZ9j/jrvcE4FyJgf4xOPoPwe6oZwfPBIOM6JWDCMHqQYYxADW9Qwixl4iq9Bqi\n",
       "nZSGPsvTGCm9B9bcNCw/ugNNGwkt3/wjiv/bhLiOXAz3T+LqwBG0t58QE2JAr00mdjE8eqWYm2jE\n",
       "lNWDDGMQqsnBjYC+TzkYSd+K8TtXYBlVIvPi3Thia0JWaw1K3rTimjsbnUPH0OI4xg6eMQJZ0Su9\n",
       "P4PP+oRNYJhIQOrYEW2hQkxmbwPdXYLS1ifQsZbQsO0vWHHQjYmudNiHjqH16nExLPrVz8Yw2jAy\n",
       "euX8/dJXDzIMYGhQM60rY4OCqqkM03nPIq34MeQ234n6Fy4h/cwh3PbGDXQMnIDDdVS42cEzxmNk\n",
       "9Erf/Tu8XTiBBmM5qBljFAYGNVPTuybmN2LwCo6hMaESdO8PsXJwPbqXEE4++wGsf7LDPXgSnV11\n",
       "wikMfagw0YFpIRAWWinob78ZqwcZZiFkrYxVXlcB2Avgx0KIW7KRzbdNmykRU2lbkFL2MpY3FeDs\n",
       "d1sQX/chhjuOorunTrSyg2e0wwumGEYhXBZM0eOUifiy17FyeCsGCwTabvsHZmpr0Nt7RFxiB88s\n",
       "Hnb0DKMQDo6eNmbdjrTyWuRfuAOfbWzCyOGXMOo4LBrZwTPBw46eYRRC7eixvmorCi/sxdjSGVzJ\n",
       "+RnG/v4bcZanSTL64Xj0DBMuTGWWoH31p+iue0KcPsEteCbkyIp1o3YMt+gZaciMdcPaZkJJsPqK\n",
       "UznpbOwP5f8ytf1qxzBMuBKM3s2+RoYJhgUdPTyxP7x9i97YH2r7N8PT4gl0TMhQ5qTGlO1YLLMO\n",
       "gtG76ZjxvZpVd9FSlnDXupqjX3SsGw3HaIbW79pJ1VXHafPmOqquOk7rd+0M9lwKj+g8PhJth8pu\n",
       "qG0HQzB6DwWPRIkNs+xEi42gkRbrRi+0ftdOZHY+JQ4cXDf7XvWmT2j9LogPf/WGDJsMgxDpnWFk\n",
       "otaiX0ysmyxlvzHxQjKd1b5OHgDEgYPrkOncHNT5GEYdPbGdGCZ8EUIE3ACUAdiuvN4NYLXyOivQ\n",
       "/kDHzDuv4I03mdtCujZS76xt3szegtH2gl03QogGIqogokoAgz4hh2sBVATaH+AY3/Pyz18m7AhW\n",
       "7/POwdpmwo6QrIyNFebnFtWSj1SS3T1CiBeJaLtMu0xkokWnerWrRZNm3R+xiFofvaEQ0SYiqvRJ\n",
       "Hm6m7T3KX1Ns++QW9f5vyhzs+XYVthNRM4AWGTZ9bG9Xttd83pNe5wHsml3f0srpryxG2dOiU73a\n",
       "1aJJI+4PrfrT891p1ZpOG1XKsb8zqhymOfowWGxiirPzIoTYC89cay+mzMH2Yxfw9CuXiHnhoo1E\n",
       "6c6oVVpiRYoAy5Rrklbn/uwqu0yrbxO0bbhT9KJRp7rWxmjUpK77Q6v+9Hx3WrVmgA1vDo+iQNe8\n",
       "WBtmtuhDvdhEurNTIZRzsLMV4e+WaKMIN+vUmxS+GvIXz823W6i8NrO+ZWvbUKeogtS1MT7M16Re\n",
       "G1r1p+ehpVVrQdePEOKwEOIHyr/ZQogGpRy6Hr5mOvpQLzYxw9mpEZKBOiHEPuXJv9SnFSLDhrdf\n",
       "tRzAGdyccuvF8DoPYBcwt75la9top6iGdJ0G0GTQdhehv6C/u0VoTVf9EJFVOderyltWP+dblA1T\n",
       "++gRwsUmZjg7FUIyB1vpT/T2j/bB0yqRac+bFL7B+5ZMe37sngdCUt/Symm0U1RB3toYhQCaNMSG\n",
       "GfrTqDU9D60h4UnF+jwReX816CqHmY4+ZItNzHZ2ATjgY3c2H6kJ2OGZHgh4nvqnJdvzTQpvZp3P\n",
       "2g1BfUsrp0ynGABfnRbBo1OjtetPk0bZCKQ/Ix9aaloL2gYRlfv0t58DUGVEOcx09KFydID5zs6b\n",
       "W7SCiJ4DPHO0lfcDzsGWZPcwgEcVMfbKsqvYnpMUHibVuR+7Zte3zHLKdIqadKpXu1o0acT9oaI/\n",
       "Qx5aGrWmx0Yl5jr1FiPKYeo8evKTeNlE296nbqEQ4hdm2o4FKEBSeNl1voBdU+tbZjn9lSWU91I4\n",
       "shj9BfvdLUZrOmxY4RlohXLs7C8HPeXgBVMMwzBRjtmDsQzDMIzJsKNnGIaJctjRMwzDRDns6BmG\n",
       "YaIcdvQMwzBRDjt6hmGYKIcdPcMwTJTDjp5hGCbK+T/HvpZElXX1BgAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e20dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creates a bunch of subplot\n",
    "ax1a = plt.subplot(2, 2, 1)\n",
    "ax1b = plt.subplot(2, 2, 2)\n",
    "ax2a = plt.subplot(2, 2, 3)\n",
    "ax2b = plt.subplot(2, 2, 4)\n",
    "\n",
    "# Plots the mean traces with error bars\n",
    "ax1a.errorbar(cnts_etoh_220, pwr_etoh_220.mean(0), yerr=pwr_etoh_220.std(0), marker='o', linestyle='none', mfc='none', mec='b')\n",
    "ax1a.errorbar(cnts_etoh_new, pwr_etoh_new.mean(0), yerr=pwr_etoh_new.std(0), marker='o', linestyle='none', mfc='none', mec='g')\n",
    "ax2a.errorbar(cnts_season_220, pwr_season_220.mean(0), yerr=pwr_season_220.std(0), marker='o', linestyle='none', mfc='none', mec='b')\n",
    "ax2a.errorbar(cnts_season_220, pwr_season_new.mean(0), yerr=pwr_season_new.std(0), marker='o', linestyle='none', mfc='none', mec='g')\n",
    "\n",
    "ax1a.set_xlim([0, 25])\n",
    "ax2a.set_xlim([0, 25])\n",
    "\n",
    "\n",
    "\n",
    "ax2b.fill_between(counts, season_220_lower, season_220_upper, alpha=0.25)\n",
    "ax2b.fill_between(counts, season_new_lower, season_new_upper, alpha=0.25, color='g')\n",
    "ax2b.plot(counts, season_220_mean, 'b')\n",
    "ax2b.plot(counts, season_new_mean, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Added 22 March 2015**\n",
    "I'd alost like to test the overlap between two runs of the old code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwr_etoh_22a, cnts_etoh_22a = skbio.stats.power.subsample_paired_power(test_alpha,\n",
    "                                                                     map_,\n",
    "                                                                     'ALCOHOL_FREQUENCY',\n",
    "                                                                     ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                                     ['Never', 'Daily'],\n",
    "                                                                     num_iter=500,\n",
    "                                                                     counts_interval=2,\n",
    "                                                                     min_observations=15,\n",
    "                                                                     max_counts=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etoh_mean2, etoh_bounds2 = collate_effect_size([cnts_etoh_22a, cnts_etoh_220], [pwr_etoh_220, pwr_etoh_220], 0.05)\n",
    "\n",
    "etoh_22a_mean = np.array([ft.solve_power(effect_size=etoh_mean2[0], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_22a_lower = np.array([ft.solve_power(effect_size=etoh_mean2[0] - etoh_bounds2[0], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_22a_upper = np.array([ft.solve_power(effect_size=etoh_mean2[0] + etoh_bounds2[0], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_220_mean = np.array([ft.solve_power(effect_size=etoh_mean2[1], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_220_lower = np.array([ft.solve_power(effect_size=etoh_mean2[1] - etoh_bounds2[1], nobs=c, alpha=0.05) for c in counts])\n",
    "etoh_200_upper = np.array([ft.solve_power(effect_size=etoh_mean2[1] + etoh_bounds2[1], nobs=c, alpha=0.05) for c in counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10ed6cf50>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXoAAACFCAYAAABVEzPoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJztnXt0XNWVp79dpYdlyXpasmRJtiU/wLINljFvApJlMCHP\n",
       "xga600mGnmCYntUr/U+nk0xgSkpDgpvurKxOJt3BpLsn6ZkOxGRNng0OBOEkNA8bY4MNxraMwTY2\n",
       "fj/wS489f9QtqSSVqkqqe2+pSvtbq5aq7r3n7FOqU7vOPWfv3xFVxTAMw8heAulugGEYhuEt5ugN\n",
       "wzCyHHP0hmEYWY45esMwjCwnoaMXkZUi0iYiqxNc96XRljGM8YiIrIlzzvq2kXHEdfQisgRAVZ91\n",
       "XjePcN1y4ObRlDGM8YiI3AusHOGc9W0jI0k0or8TOO487wKWj3BddIzmXUmWMYxxh6o+SrjfxiLZ\n",
       "74NhjCsSOfpS4FjU64qhF4hIc2SE41CSqIxhZCgJvw+GMR5JZjFWEpwvH0MZw8hUrG8bGUciR3+C\n",
       "AUdeBhyNPhljNJ+wjGFkMNa3jYwkJ8H5x4GlwLNAA/AbABEpVdUTQKOINBK+hS13FqdilolGREx3\n",
       "wfAUVXVt5B3V361vG2lnLH07rqNX1c0islRE2oATqvqac+oZYKmqPgnghJqVhIvoayOUSbmxo0FE\n",
       "2lW13UsbftnJFht+2UnF2YrIKmCpiNyjqo85hyP9faTvwyAytW9LqxQQoIZgoJpNgb/i6sqXCAaq\n",
       "kPwgWgAySWGSQH4vmtfDxZJejlxRxolLyjlTX8H5igouFJfTPbmcvpwCci6cInjhFDnnT5N77gw5\n",
       "586Qe+4sOefOknvuPLlnz3PwkcU0fG4Dkw4GyTsolO4pZsr+YiYfm0LeuSnkXigit2cKwd7J5PQV\n",
       "ENRCAPo4jXIK5QR9nAROopxEOY1yEjiFcho4zb9zG5/hMYQzBDiD8CF5nAMuRB4a0t6U/nf+fX/G\n",
       "1LcTjehR1bXO02ejji2Ncc3aeGUMIxNQ1XXAuiHHlkY9z5q+La0iBGggWDCPnOJFTJlRCyWgpcqk\n",
       "XZVISw49JfuQXEUFjs6byqFFjZyqb+BsRT3dhVXknj1K/qmDTDp+iLKuNyg6eJSS944x5cBpAr2D\n",
       "nZJ2C4FjRQSOF1F4sIqiI3VsPFLH8pc/SV5vCTl95cAF+tiH8h7Km8AeAuwhh3eBQ87jQ/168mqM\n",
       "8og06hp9xs3/XaaR0NEbhpFdyDKpJbfoKoqmL0XKitCqXvoqj9Mz9R0Ihi/q2TefCzMusPfGJo5c\n",
       "2sSZmvmoBJh8ZDfF+/dQ/4cXqNp2kLwPu0e2dCqPwAdl5B8qoWxfLYWnq5l8sZy83unAafrYRi/v\n",
       "Ucj3EN4CdmlIT/jwL5hwZLOj78wiO9liw0872UznaAtIqwhBmsirvIWiuQ1o3UV6Z3wAxYcHXagC\n",
       "79w0l9PNs3jus18n/9QBSve8QeOzG6h64xDxZg60WwgcKCf3/TLK906n5OR0Ci/WkKMV9LGJAE8h\n",
       "/CewUUN6BEAelBZ9XUf9fkaJ1/X7ZWPMSDr06EVEvZ7HNCYu6exf47FvS5tcSn7VJ8iZNoPe2cfQ\n",
       "+uPDLrowJY+3Pn0th5uuR/p6mfrWi8zq3EzJe6fi134hQGB/BXnvljL13VmUnammoPcSlDcJ8HPC\n",
       "6xsbNaRxRv5Gsoy1f5mjN7IOc/RhZJmUkFf6R+RNX0rvvKMxHfy5snzevP1GDs+/kcLDu5nx++ep\n",
       "f2FP3JE7gBwsJrC3gspdtUw9OZ3JvQuBFxB+AvwsMmI33GWs/Subp26MCYQILUBLmpsxbpBbci6n\n",
       "sP5PYU6Anvm7+ufeI/QFhe0rr+bAlR+l8NDbNP/Ld6ja9kH8WnshsGca+TvLqNlXR/n5ywhwAuEx\n",
       "4Mca0gTljXSRcEQvIisJJ4o0RkUcRJ9fRVj/4w5V/W/OsTWq+mURWT1CmXEz6jGyj4k8opdWCZI7\n",
       "+WNMmnkLPc0HoOLssIveX1zDmys/g/R2M++XP6V24764lWq3ENxVS8GOEma8X8eUnmsQfg18F3hR\n",
       "Q7YfqV94MqKPVusTkUYnE3Zz1Pk2oE1V/1xEviwii53Y4tUicjtw32gbZBjG2JBWKWBS+d3kNjTR\n",
       "c0UX5PcNuqA3N8CWzy3jcFMLdS/9gqZ1L8WfoumF4M4a8neUMmt/PUW91yL8CLhPQ/qup2/GcJVE\n",
       "Uzd3Auud5xG1vn5H78gfROKJy6MSSFZHkqkMw/AeaZUCCiruI9g0k57Fu4ddcLqmiE333g3ay1X/\n",
       "6+8o2xM/jFH2l5G7vZKZu6so625FeAL4gob0fW/egeEliRx9MuqVJcC9wDejDpc7o/0lqvpIyq00\n",
       "DGNEpFUKKZh6L8GmOnov3zvsgv1X1rN91Z9R1rWRJY/9x7BEpmj0fA65W+qpeLOIGadbCPAmcK2G\n",
       "9G0P34LhMcksxsadD1LVk8AjIrJeRF5V1T2ReXkRuVlE2mIInxmG4QLSKrkUVHyB4ILp9F723rAL\n",
       "dq1oYvfNn6HhuSeY96utcSsLvFNJ7tZy5r3bQIHOR/gi8HObg898Ejn6ROqVSwjr22wGXgVWicgJ\n",
       "4JgzdXMUaCRGuriItEe97FT1PGnCyFJEpIUa7qaMWelui+/kF68kOGc2vZftGXburU818+4Nt9O0\n",
       "bi31Lw4f6UfQbiFnywymvl7AjDO3EeBp4A4N6WkPW274SKrqlW2EHTyEp3leBk4CG51jFcRQ+APw\n",
       "QwDImBg4g4TOyOuJoiApt0xqZdK86+lu7hp2371t1VXsv+o2Lvu371G9ZeR5dTk+iZxN9cx+u5yS\n",
       "3haE1RrSX3rbcsNvUlKvBB4F7nSkio+r6k+hfwNlgCMjKfwZE4chMe4tDDjlTtXxnTo+XpE2aaRw\n",
       "7u30XLkXyR38w/b2bYvYf/XHWPwv36Vq++ERqggvuOa/XEnTvkXkEgCWakj3e9x0Iw1YZqzhKyKo\n",
       "qre7NKXSv5LIG0l03vO+La1SQGH1l9Drgmjt4GzXd26czY5P3s3CH38/bnx84O1qijYWccnRWwnw\n",
       "K+CvTKZg/GOZsYaRIknkjTQDXc6dLkPP+0b+lI8TmF1KT+3gWPYPmirZ8cm7mffLH8Z18sGttZRv\n",
       "mkzDmZUIX9eQfs/rJhvpJZk9Yw1jonAn4SxvGMgbGcoa529jOpy8tEkTeXU30b1ocITN+ZJ8tn72\n",
       "C9S+/CsaOneOWEHOqzOoeqWIhjN3IvxXc/ITA3P0hjFA3LwRx7HvEZFjQ67zhXAoZfUd9C78YNC8\n",
       "vAq88ud/QuHhLhY+8eKIFQQ3zqR6UwH1Z1cifFpD+ms/2m2kH5u6MYzBjDj/KSKlwC5gNbA2kjcS\n",
       "47r2qJfuhQ7n5t9AYEY5PdWDbW75fAvdk8u45ts/GrFscPMMpm8uoub8JxBu05BuHPFaY9wgIi24\n",
       "INaX0NGPUdQsbhnDGKfEzRsh7OC/r6qnnHyRVcCwzG9P9nNdJiUUzvgYPU2Do2IOXl7DoUXLufIf\n",
       "v0Xu+dj7nga31lL1agE15z+FsEJDaVhXMMZEjNDh0FjqiTt1E7045bxuHnI+Imr2LNAoIs2JyhjG\n",
       "OOZxwgl+MCRvJHKBqp5y/j5L+IfBH/KKPwqNAlMu9h/ryQ+y7Y4/pfblX1C+O/ZUUmBnNRWvFlF/\n",
       "dhXCH5mTn5i4LWq2WUTWAE+PVMaYeEhH1O3n3TchHc+3O6c6NTR+MqIT5Y2o6iMi8iXC/brcr7tV\n",
       "WSa1FM25lu5L3xk0sfTa3beQe+4kC37yUuyC75VR/HIJs06vRPishvQPfrTXGH94IWpWkqiMMbFw\n",
       "nHkngHRISEPjNys6ynk/G3VsadRz/0X68krb0IbzgxZg32+eztG513HNtx+JLTV8dDIFL1cy99ht\n",
       "CH+tIX06xkXGBMF1UbNkyoBp3Rju4daC1XhElsk0CmdfQc/sgdG8Crz1qVVM3/hrSvbF2NP1QoC8\n",
       "V2qZf+BqAvxfDem/+tlmY/zhuqhZojIRTOvGcAu3FqzGJXklLTCje9Bo/s3bl6LBHBb8JHYoZc6m\n",
       "Bi7ZNYcc3gG+5ks7jXFNojj6RItTbQw49VJg90hlDMMYHbJMKsgtu4beuQf6D54tn8S+az7B3F+t\n",
       "i6krH9w+ndo3SinQGcDdGtK+YdcYE464jj6S+TfC4hSERc0aRWQ1jqhZnDKG4Ski3CjCg+luh2vk\n",
       "Ft0As/oGbQn4xp+soOj97dS/OHwrPzk0hZLNpUy78FGEVSYzbERIOEcfb3HKmZ8fFnkQq4wx/sgm\n",
       "VUkRbgRWqPI1kcyfrpBWyaeo7np6Gwckho83lHK88Squ/dbDw0tcCJC/qZbZx25G+EsN6TYfm2uM\n",
       "cywzdgLjOPNO6FeVbElne1LkFtXMd/D95AYWITX5UNjTf+ytT6+gfOcLFO8fPlLP2TqTuXsaCfCc\n",
       "hvT/+NlUY/xjWjdGttCT+JIMIndqK30zBsKUD8+v5FTtIprW/XbYtbK3gqrXyyjomwP8pY+tNDIE\n",
       "c/RGtpA1d6fSJjMJls+gb/rJ/oM7PvFRKrd3Unjk3OCrLwSYvHkadR/eivB5m5c3YpHQ0Tu7RbU5\n",
       "C66xzq92Hg9HHVsTOedeU41Mpn+h9LkQIjzozKm7yXoRHnK5zvSQW3INWjfg0A9eXsPZytks+MmG\n",
       "YdcGX69nzr6FCD/QkP7ez2YamYMbWjfPOIuvjc5rgNUispNwuKUxwYlaKL2f1g5UuR9Y4aazV2UD\n",
       "8LQIf+NWnelAWqWQvJKr6W082H9w983LqNz+PPmnLw6++GAx1a9Xk68VQIfPTTUyiEQj+kQbMTRG\n",
       "HesiHDcPsFpV56rq8PlEYyIybKHUeX2zq1baBdols7eoDDIfqoP9IZXHZpdzpqaJS372wuALe2HS\n",
       "5jqmn2lFuEdDej4NrTUyhESOPtFGDGujQimXABGN63JnuudL7jTTyHBGWiiNLas7BqRDwncNIb0/\n",
       "pXoST1Uuca7xZloyr+p6eqcPqGLuvK2F8l0vMvnYYEcefHM6jV2zCfD/NKS/86QtRtaQzGJsMro1\n",
       "S4BNkeQo5wfgWaAiajrHmLiMtFAadNHGLRrSlMIrk5TY/oqqPgmUui3BLcukjGBRIzo9fBd9Zloh\n",
       "J2ZdwbxfPD/4ytN5lG2to7BvPvAVN9tgZCeJHH1SujWENem/Cv2Lsyud40cZkEMYhIi0Rz1aRtds\n",
       "I8MYtlAqwjdwSR5DRFp4ghsi/SmFquJOVTqb7LwCYRVL1/eMzcldCNXa//u345MfoXjflmHCZTnb\n",
       "6ph5dImjSumfJr6RsaSqdYOI3BuRbnVG710MSCRU4HwxhqKq7VGPzjG/A2PcM2ihNBx18zfAU85x\n",
       "F+rXTu7k95H+lEJViWS5lxK+S232ZFoyt/w6+urCg6nuSUGOzruO2es7B10jB4up3TaDIMcBS4wy\n",
       "kiIlrRsRWQ48LCK7nA2T1bntXe6M6o+Y1s34RTqkRTqkXTqknbtbiDx3NgpxFVU2qPKAE3XzgFtO\n",
       "Por10iFuhFcmmqo8EvW9WJng2uSNLpMagsW16LRwHPyuWy8n7/T7VG37YNCFk7bWUXX2BoS/0JDG\n",
       "EqI3jGGkqnXzDANTO9FlnnSrgYZ3+LkhiLNYeovz/EFgvYbUNWevId0gHYJ0SCrhlYmmKo8Ce6Ku\n",
       "vRIY1tfHtNdCTv4CtGZgcfpg8w3UvvzcoGsC71Qys2suwk81pJsS1mlkPG7ttWCZsYbnDI2Icf6u\n",
       "cI67hoZ0g4b0gRSqSDRVuS7qfCnwcsx2jGVaMrfsWvpqjwBwYEkt3QVlzF4fJUzWC0Vb6yjuXoyQ\n",
       "yns0MghV7YzuT2Otxxz9BMeHjFWIERHjvHY3jj5FEk1Vquoe4IQzZVOuqj91w64sk2kEp1SiUz8E\n",
       "YO9N1zN1xwsEuwfkiQNd1czcdynCtzWkh9ywa0wczNFPYPzIWHXwPI7eLSKhwdEbfw/ZM3atqj4Z\n",
       "iTJzhZzceVAVdupnKwo4VbeYOf/xnwON6hbKXptJQe8s4O9ds2tMGMzRT2z8yVj1J44+c8kpv5K+\n",
       "6nBY564VSyj8YAfFB84MnN9ZQ/2hRQjtGtIzI1VjGCPhlahZ3DLGuMGvkfawiBjpENfi6DMZWSYl\n",
       "5BTMpG9aWKnyyPyrqdn0Uv8F2i1M3TqHPC0AHktTM40MJ27UTXSmoIg0ikhzdJJIlKjZHhF5wnl9\n",
       "LF4ZIzl82v3Jl5H20IgY5+9TbkbdZCwB5kAVEISDl1XTk19Mw3M7+s/n7Kxh+pGFCP9TQ9qdvoYa\n",
       "mUyi8Mo7gfXO80imYLTTbnQea53zjYRv+38Tp4yRBD7t/rRehIeip2+cjNWn3DbkOPUN0iH3pxgZ\n",
       "k13kViyhb1p4Oubdj1xFWdcr/Zt+h0fzc8lRgB+nr5FGppPI0ScUNYt6uYRweNoVDI4/HppdaCSB\n",
       "k7TUAsDdNyEdz7c7pzqd+PeUUWWDCOFM1ZtCSLu7GatGfML7wtZfSm/NfnryApyYtZTmf/5O/wWR\n",
       "0XyABzSk427h2sgcktmVZzSiZpslrBKb2VKx4wC/kpkcp75BOjru1852G2n7SYDZSEVYknhP2wJy\n",
       "zx6h8s3D4ZO9ULVlHjnaB/wkre00Mp5Ejn7UombJlhlT9qDhOl5nrPqBW9mDvpNTdAk6NbwgfnDx\n",
       "VVRuG0jACu6uofroIgJ81UbzRqp4IWoWs8xQTNQs/fiVseo1bmUP+k5u0WX0VR/hbEUBH1bOo/HZ\n",
       "Lf3nKvrn5k1OxEgZL0TNRipjjD8yImM1G5FlUkmgqBwtO8+eZYsoPLyTyUfD+8TK3gpqDjUR4CEb\n",
       "zRtu4JWo2bAyxrgkYzJWs44AM2Fq+PmRS5cwbcuL/efKX5tLXl8x8G/paZyRbVhm7MTGMlaHkGyy\n",
       "X8p69LlTF9NXeYbTNUWcL51Jw2/DAmZysJjpBxYgrNGQXkxQi2EkhTn6cYwPgmNZk7EqQosI7SK0\n",
       "j72OpLYSjExZjnl6S1olSE7+JfRWH2dP62KKDm4j/0w4GarktblM6qlFLAvWcA9z9OMUPwTHnOia\n",
       "p73OWB3khMM/Wu3Oo8UtG6p0qtKuOnZHT4KtBKPNpWADAtQjpbnIpB6OzlvCtK2vhk+cnETN3oXA\n",
       "dzWkH6ZkwzCiSFnrxrlmTazXpnWTEr4IjkVruGtIH/AitHKQEw7/aLU7j063baVIoq0EcSQ9Ult7\n",
       "CubPQSt7Od5QysUp05jVGZY8KHxjJkUX5xDguynVbxhDiOvok7mVFZF7gaFbqq0WkZ3AbpfaORGx\n",
       "hdL0kCjZb1jwwajJKV1MX+VJ9n5kMVP2v07OhV64EKBmx+Uo6zSkHySuxDCSJ1WtG1T1URFZNaTc\n",
       "attOMGVyYiUzgU7YhVIfiJvs58ZoXlqlgCkzaump3Mvx2Zcx4/fh9ZC8HXWUfdhEgC+kUr9hxCIl\n",
       "rZs4lDtx9EsiyVTGKLn1iwfZfvs39PEnb5AO+ZqG9H65a9UfuPWL/w7/kO7WZSuPA0sJhwUPShBU\n",
       "1RNAo4g0Ev4elI+kzBo36zvATCgXTs4q5mJRNTN+9zYANVsvQ9mkIX3Tm7dmZCJuZX27onUzlEgc\n",
       "vYjcLCJtKc9pTkSu+U417fo/5IlowbF1X6VdbjZH7w2OVtPSERIEl0buUp21pxJGWJSNm50bLGhA\n",
       "y3rY+5FFFB3cTu75XuTdMipOLCDIZ119Q0bG4wwSOiOvRSQ0lnoSLcYmq3XTj7MJSWTO/igDcgjG\n",
       "6OhRZYMqDzgLmA84AmSuzdH7EQ2TaSTaSjDqmrljyvrOLV5EX+VJjs25nMrtYcmDqs2LCOiHwG9T\n",
       "bL5hxCTRiD7RrWwsuoCNzvMKRojJzmRRs2zZFGSQ5n1HR0g729vdqjuaQZLL8Lx09H/2rkgui0gL\n",
       "NdxNGbNSrctLpFUKmTJjOicWHuZ8aT0zn38LTuVR9f5ChL/XkKYWtmkYIxDX0Se6lQVwFmKXisg9\n",
       "qvqYs7PUSkeu+MhIo56MEp8agm+bgnTIQ9FaNE4yk+ubgnhNtOSyJ/UPv70dnw4zQD2UwzutCyk6\n",
       "tIP8M90Ub1nEpO5pBPhhuptnZC8pad04z9cB64aUSUvEjU8jbV+w7feykGDhXPqm9nBs7mVUvbER\n",
       "7Raq315MHz/UDkuQMrwjmcXYjMGnkbZv2PZ7WUZuURNn55zlbMVsZm74IZN21lJy9hICw/JQDMNV\n",
       "ssrRG6PD67lzY4Dw/PysGvZ+uoSC4+9QcPwC1Vua6eVF7dB30t0+I7sxRz8G/NjP1Q+8njs3oggw\n",
       "E8rgyPyFlO1+HY5MpvzYAnL4XLqbZmQ/CR29Eyp5Amgcshl49DVrVPXLoynjBdIhLbzf/F84Onc2\n",
       "nypA7ji3gYqdu6nZ/L/ddMB+7edqZBHBgpn0VPZypno+Tet+xdRNlxPs60ZszwbDe+I6+mitGxFp\n",
       "jJUJGKV18+Vky3hGu/YBB1T5M+kQ1ZDeKMJDQB9jSjMYGUdF8hYnmSm812o4zt2t+luI3DWEbbQ7\n",
       "pzJuYdkAcooX8t7KUnLPHad050mq9l5GH/+oX9e+dDfNyH4SJUwllG1V1Uedc0mX8RBfFB99kRDO\n",
       "HMVHIwHSKvnk5Ndy4KZGSva+zuTtMym8MJNc/indbTMmBl5o3YxVH8cNekYQAnNb8fEW2uVp6eDB\n",
       "fjvtPE273gzujeqNLCFAPVoKp+oXsuCJf6Xm9evo4df6kB5LXNgwUieZjUdGrXUzxjKps/ifG4EV\n",
       "GtL7AZy/K2j+QYOrdpofq41t57E6V+0Y2UEwt57DbWUgQWrWn6DsRBO5rElc0DDcwXWtmzGWcYdr\n",
       "/gHahyRFtqtw1XfctTP3qTnRGasAGtKvMfep2e4aMrKCYNkC3vtULVP2b2P6S1eAfqDt+kq6m2VM\n",
       "HLzQuolZZiieaN1Ub+kCfisSrfjIU9RsWZZy3dGUde0S4aHo9QARvsF9Xa5ttGIx7snjlpSrU1fc\n",
       "iLGoXdNmq+pXEtbXKkGK6mZxbOFsZmx4mop9N9Nn8qOGv3ihdTNSmaF1t7v3NvrJcSJfNkhHx/3a\n",
       "2f4AgHS4uxhLzeb9wPrhPyibXbNjMe7J45aUa6KIMadPP6Oqe0TkiaQkuAPUcXZ+ERdKqlnwvV4K\n",
       "LlYT4AdjaZ9hjJWEc/SJZFtVdZ2qlqvqY/HK+MR66ZCHog84QmAx7ypSsUO7rIiWEKZdbvXAjuEv\n",
       "iSLGGqOOdZGMBHcwUMu+P55F4eG3qdt0Bd38XEN6xq0GG0YyJLMYmzm0a4CfrZ0ud618nj03IXet\n",
       "fJ6fra2hXV19n44GzdMmOJZ1xI0YcwYwkcHLEiDxPHuwvIlDN8yg8tVdlJxoIsjfutZaw0iSrJJA\n",
       "CMeY39MJ9+AkTN3kmS0THMtWEkaMOVM8mxJtPCKtIuTPnsfphll8/LPvorpfH/QpedAwosgqR28Y\n",
       "KZJsxFibqn51pEr6Aw1yKWT6oqvI/fAwtVsuoZdvudlYI/txK9BANA2b2oiIqqrrsfZDIlVaiNaj\n",
       "9yhSxblzSE/egBGTsfYvEWkmvDfsWhH5EvAbVX0tOspMRO51ssGJtRgbbVuWyxW80bmW8vfOc8fn\n",
       "LidApYb0bOrv0JiojLVvZ9WI3q9IlUE/KO/chIU+ZgeJosxEZDnwsIj8NeGR/6q4FeaUzuX45bP4\n",
       "+H8/wEV+rt80J2+kh5TVK2Odj6hZisjqNETeeM/gpKznB51zWTzN8Jd4O6qp6jMMTO0k5sTy60By\n",
       "qHlzJj183tWGGsYoSEm9Ms751SJyO3Cfl41PF9E7WRlGLKRVpnDwR4tZ+p2jKBf0m/pquttkTFxS\n",
       "Va8c6fxqVZ2rqr91pZWGkWkEqOfodbO44tHJXNTvp7s5xsQmkaNPpEQ50vlyEWlzFrQMY+Jxbsl8\n",
       "cnuqKd03hULM0RtpxQ31ymHnI5mxQIWzsGUYE4sPPvdJrl9znov6S4u0MdJNosXYRHHF0edLgaOO\n",
       "6NMxVX3Sub4Rhm+X5omomTEhcVPUzA2kVfI59dyVLHwgn14eSXd7DCNV9cro842Ew9DKgY1O+QpG\n",
       "0H/xSNTMmIC4JWrmGn3FdVTtn01f3wH9W5MjNtJP3KmbSITNCHHFsc5vdqZsljthl0cSpYkbRtbR\n",
       "9eD1XLE2QN/Z76W7KYYBScTRx4srjnP+SbcaaBgZR+npa6l9BeC76W6KYUCWZcYaxrhgxdfepZef\n",
       "6Ro9l+6mGAZkmdaNYUB6+1fEtnRIQEPal442GNnLmHWczNEb2cZ4cPTpsG1kP2PtX9m18YhhGIYx\n",
       "DK9EzeKWMYzxylj6u2GMd+KO6KNFy5zXzYnOJyrjF04STVbYyRYbftoZC2Pp73630bHbkg02/LKT\n",
       "LTZSwQtRszsJj3hGKgOA3LXqd/LRL/7FaBs8Clo8rNtvO9liw087Y2GsIn5+05IlNvyyky02xowX\n",
       "omaJygCgj6/7CMX7/9hjZ28Yo2GsIn6GMa7xRNQsWfTxJ2+g+MCdYy1vGB7gWX83jHThuqiZ8zzh\n",
       "Bssi0h/XKU+IJzGefmme+GEnW2z4aWcMjKa/J9W3vcL6w8S0MVbcFjX7DeERz7Ay0VicsTFOGU1/\n",
       "t75tZAxui5q9FqeM79jGJ/ERkTVDXq90NoxZ7bGd1c7jYa9sRB1Pug+Mpb+n1OhxQjL9INW+EcPG\n",
       "GuevazaMOKiqbw9gtfN42Adby4H1Hta/BFhJeNtEL9/HSqDNbTvAvcCuoe8n6nNq9shOG9DgPH8C\n",
       "aHPbhl99wI/Pyal7TeRzcdteMv0g1b4R6/MhvKi9E1jmVv+L5V9i/Z9S+d+NYMPVzwdY5ZT9J7fe\n",
       "h2+Zsc4o6BkNJ5k0+rDzlNfzpF/RsEpnqVfx1E69XRqO2+5y046qPko4RDCCJ6GDMew0RtXd5bx2\n",
       "20b/qVTrTgYf4utXi8hOYLfb9pLsB0mFTI/CBgzfVzql/hfLv0T+L+pSnk8cH+ba5+PU2eaUbRyp\n",
       "zaO14acEgutf8JEQkebIP8Cj+lcBrwCo6iPq3NJ7ROSWt9FjO76EDmp4m8lIRukSnP+j23jdB4bg\n",
       "dXy9q04xAWMOmR4lQ/eVTtVGLP9yF8N/oFL50Rpqo8F57trno6rPquqfOy/Lne/8XTHqG9X78M3R\n",
       "+/UFdyj8tPEnAAACOElEQVRPfElKLCW8H26zl+sAzoe8R0SOMfhL4BW+LSQ6I5JN6t08t9d9IBqv\n",
       "fyTddoqJ8LwfaOx9pcceqj3cv2xkcCQgpPijNYINcPnzEZESp65vOodKYtQ3Khu+i5p5/QX3cSR3\n",
       "RAcW51Z6YUBESoFdhOcE14pIQ4IiqZBU6KCLtKnqV72o2OfRfL9Zryp22ykmIFbItKt9w1mIj3xn\n",
       "IvtKu2Ijyr9E7n5d/z8N9WEe/GidVNVHgPuivvMpvY90qFd69gV3aHRW7+8l/Evrxfz5UWCP8/wE\n",
       "cKUHNiDs4L/vrAXcQXiRxiseZ2A6LWbooFuIyL1OR0a8Wavxow9E49mPpJdOcQSi+0EkZNrtvtGF\n",
       "E8lEeCT6ios2ov2LVz9a/Tbc/nxEZElUf32V8Hc+5ffhq6P34QuOqj7pOEYlfMvjxYLcOgY6ZSnw\n",
       "sgc2AFDVU87fZxmYk0sZZ51hqYjc49TvSejgUDsishx4WER2OVNSKX8+Md6LH30gGi9/JL10ikn1\n",
       "g1T7Rgwbw/aVdqP/xfAvrv9oxbDh9ufTxmCnvtuN9+HbxiPOF/wJwvNK5cCqqMWLjMOJ9T0GLPXy\n",
       "DsWZq+sivDBjsrjjFKc/dOGBfHHUiLFBVf/Oa3uZyEj+Jdb/aaz/uzg2XPt8RKSE8EIrTtn+O4dU\n",
       "3kdadpgyDMMw/MN2mDIMw8hyzNEbhmFkOeboDcMwshxz9IZhGFmOOXrDMIwsxxy9YRhGlmOO3jAM\n",
       "I8sxR28YhpHl/H/FiWqq0gEtRwAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ed0e6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creates a bunch of subplot\n",
    "ax1a = plt.subplot(2, 2, 1)\n",
    "ax1b = plt.subplot(2, 2, 2)\n",
    "\n",
    "# Plots the mean traces with error bars\n",
    "ax1a.errorbar(cnts_etoh_220, pwr_etoh_220.mean(0), yerr=pwr_etoh_220.std(0), marker='o', linestyle='none', mfc='none', mec='b')\n",
    "ax1a.errorbar(cnts_etoh_new, pwr_etoh_22a.mean(0), yerr=pwr_etoh_22a.std(0), marker='o', linestyle='none', mfc='none', mec='g')\n",
    "\n",
    "ax1b.fill_between(counts, etoh_220_lower, etoh_220_upper, alpha=0.25)\n",
    "ax1b.fill_between(counts, etoh_22a_lower, etoh_22a_upper, alpha=0.25, color='g')\n",
    "ax1b.plot(counts, etoh_220_mean, 'b')\n",
    "ax1b.plot(counts, etoh_new_mean, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these examples, there is a relatively consistent overlap between the values calculated by running the code in either order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Okay, because I'd like to improve the run time on the new code, I'd like to profile both sets of code. Again, HT to the [\"Profiling Python like a Boss\"](https://zapier.com/engineering/profiling-python-boss/) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "def do_cprofile(func):\n",
    "    def profiled_func(*args, **kwargs):\n",
    "        profile = cProfile.Profile()\n",
    "        try:\n",
    "            profile.enable()\n",
    "            result = func(*args, **kwargs)\n",
    "            profile.disable()\n",
    "            return result\n",
    "        finally:\n",
    "            profile.print_stats()\n",
    "    return profiled_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         35953849 function calls (35595389 primitive calls) in 45.195 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   45.195   45.195 <ipython-input-19-93145e9ea0b7>:1(calc_old_etoh_pwr)\n",
      "    35000    0.519    0.000   42.843    0.001 <ipython-input-5-640c322d58e3>:1(test_alpha)\n",
      "   283330    0.213    0.000    0.337    0.000 __init__.py:121(iteritems)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:247(viewitems)\n",
      "      820    0.001    0.000    0.006    0.000 _methods.py:28(_amin)\n",
      "   105070    0.058    0.000    0.609    0.000 _methods.py:31(_sum)\n",
      "    36130    0.024    0.000    0.230    0.000 _methods.py:34(_prod)\n",
      "    73240    0.055    0.000    0.559    0.000 _methods.py:37(_any)\n",
      "      900    0.001    0.000    0.006    0.000 _methods.py:40(_all)\n",
      "       80    0.000    0.000    0.001    0.000 algorithms.py:402(_get_data_algo)\n",
      "       80    0.002    0.000    0.007    0.000 algorithms.py:98(factorize)\n",
      "       80    0.000    0.000    0.000    0.000 base.py:189(__getitem__)\n",
      "       80    0.000    0.000    0.000    0.000 base.py:252(_shallow_copy)\n",
      "    70000    0.013    0.000    0.013    0.000 base.py:289(ndim)\n",
      "       40    0.000    0.000    0.000    0.000 base.py:98(_reset_cache)\n",
      "       80    0.001    0.000    0.014    0.000 categorical.py:212(__init__)\n",
      "       80    0.000    0.000    0.015    0.000 categorical.py:337(from_array)\n",
      "       80    0.000    0.000    0.000    0.000 categorical.py:388(_get_codes)\n",
      "       80    0.000    0.000    0.004    0.000 categorical.py:421(_validate_categories)\n",
      "       80    0.000    0.000    0.005    0.000 categorical.py:440(_set_categories)\n",
      "       80    0.000    0.000    0.000    0.000 categorical.py:448(_get_categories)\n",
      "    73360    0.236    0.000    0.347    0.000 common.py:1072(_maybe_promote)\n",
      "      850    0.000    0.000    0.002    0.000 common.py:191(isnull)\n",
      "       80    0.000    0.000    0.001    0.000 common.py:1982(_possibly_infer_to_datetimelike)\n",
      "   352460    0.429    0.000    1.248    0.000 common.py:2053(_is_bool_indexer)\n",
      "      850    0.001    0.000    0.002    0.000 common.py:212(_isnull_new)\n",
      "   283140    1.512    0.000    3.371    0.000 common.py:2279(_asarray_tuplesafe)\n",
      "   214410    0.218    0.000    0.355    0.000 common.py:2387(_get_dtype_type)\n",
      "       80    0.000    0.000    0.000    0.000 common.py:2402(is_integer_dtype)\n",
      "      980    0.001    0.000    0.003    0.000 common.py:2414(is_datetime64_dtype)\n",
      "      980    0.001    0.000    0.003    0.000 common.py:2423(is_timedelta64_dtype)\n",
      "       80    0.000    0.000    0.000    0.000 common.py:2433(_is_datetime_or_timedelta_dtype)\n",
      "       80    0.000    0.000    0.000    0.000 common.py:2454(is_float_dtype)\n",
      "   212210    0.172    0.000    0.563    0.000 common.py:2464(is_bool_dtype)\n",
      "       80    0.000    0.000    0.000    0.000 common.py:2468(is_categorical_dtype)\n",
      "      240    0.000    0.000    0.000    0.000 common.py:2502(is_list_like)\n",
      "    70820    0.018    0.000    0.018    0.000 common.py:2633(_clean_fill_method)\n",
      "    70820    0.123    0.000    0.292    0.000 common.py:386(array_equivalent)\n",
      "      820    0.002    0.000    0.010    0.000 common.py:535(wrapper)\n",
      "   423440    0.238    0.000    0.587    0.000 common.py:59(_check)\n",
      "    73360    0.089    0.000    0.133    0.000 common.py:703(_get_take_nd_function)\n",
      "    73360    0.647    0.000    1.603    0.000 common.py:735(take_nd)\n",
      "      160    0.000    0.000    0.001    0.000 common.py:969(_coerce_indexer_dtype)\n",
      "    70900    0.132    0.000    0.414    0.000 frame.py:1757(__getitem__)\n",
      "    70900    0.071    0.000    0.195    0.000 frame.py:1782(_getitem_column)\n",
      "      820    0.000    0.000    0.000    0.000 frame.py:188(_constructor)\n",
      "      820    0.004    0.000    0.008    0.000 frame.py:194(__init__)\n",
      "      850    0.003    0.000    0.029    0.000 frame.py:2085(_box_item_values)\n",
      "      850    0.001    0.000    0.021    0.000 frame.py:2092(_box_col_values)\n",
      "      820    0.003    0.000    0.374    0.000 frame.py:2406(reindex_axis)\n",
      "    70000    0.074    0.000    0.074    0.000 frame.py:401(axes)\n",
      "    35000    0.033    0.000    0.088    0.000 fromnumeric.py:1283(ravel)\n",
      "   105000    0.149    0.000    0.803    0.000 fromnumeric.py:1623(sum)\n",
      "    35000    0.024    0.000    0.153    0.000 fromnumeric.py:1917(cumsum)\n",
      "    36130    0.067    0.000    0.369    0.000 fromnumeric.py:2251(prod)\n",
      "       70    0.000    0.000    0.000    0.000 fromnumeric.py:2625(round_)\n",
      "    70000    0.053    0.000    0.226    0.000 fromnumeric.py:795(argsort)\n",
      "    35000    0.634    0.000    0.883    0.000 function_base.py:3625(insert)\n",
      "   140820    0.082    0.000    0.132    0.000 generic.py:1030(_indexer)\n",
      "    70900    0.048    0.000    0.124    0.000 generic.py:1063(_get_item_cache)\n",
      "      850    0.002    0.000    0.007    0.000 generic.py:1077(_set_as_cached)\n",
      "      820    0.001    0.000    0.002    0.000 generic.py:117(_init_mgr)\n",
      "    70000    0.136    0.000    0.725    0.000 generic.py:1341(xs)\n",
      "    70000    0.706    0.000   15.625    0.000 generic.py:1701(reindex)\n",
      "    70000    0.314    0.000   13.436    0.000 generic.py:1733(_reindex_axes)\n",
      "      820    0.005    0.000    0.371    0.000 generic.py:1798(reindex_axis)\n",
      "    70820    0.530    0.000    6.828    0.000 generic.py:1812(_reindex_with_indexers)\n",
      "   140820    0.215    0.000    0.282    0.000 generic.py:1915(__finalize__)\n",
      "    73360    0.125    0.000    0.125    0.000 generic.py:1949(__setattr__)\n",
      "    71660    0.133    0.000    0.494    0.000 generic.py:1986(_consolidate_inplace)\n",
      "    71660    0.055    0.000    0.115    0.000 generic.py:1987(<lambda>)\n",
      "    71660    0.107    0.000    0.240    0.000 generic.py:2047(_protect_consolidate)\n",
      "    70000    0.303    0.000    0.322    0.000 generic.py:238(_construct_axes_from_arguments)\n",
      "      840    0.007    0.000    0.155    0.000 generic.py:2847(groupby)\n",
      "   212500    0.258    0.000    0.325    0.000 generic.py:285(_get_axis_number)\n",
      "   775760    0.732    0.000    1.071    0.000 generic.py:298(_get_axis_name)\n",
      "   774940    0.538    0.000    1.894    0.000 generic.py:311(_get_axis)\n",
      "    70820    0.048    0.000    0.147    0.000 generic.py:315(_get_block_manager_axis)\n",
      "    70000    0.054    0.000    0.094    0.000 generic.py:379(ndim)\n",
      "    71670    0.123    0.000    0.123    0.000 generic.py:87(__init__)\n",
      "      840    0.002    0.000    0.146    0.000 groupby.py:1184(groupby)\n",
      "      840    0.001    0.000    0.001    0.000 groupby.py:1219(__init__)\n",
      "      840    0.002    0.000    0.042    0.000 groupby.py:1344(groups)\n",
      "      100    0.000    0.000    0.000    0.000 groupby.py:1350(<genexpr>)\n",
      "      900    0.006    0.000    0.021    0.000 groupby.py:1865(__init__)\n",
      "      820    0.001    0.000    0.009    0.000 groupby.py:2020(groups)\n",
      "      840    0.016    0.000    0.130    0.000 groupby.py:2026(_get_grouper)\n",
      "     1740    0.001    0.000    0.001    0.000 groupby.py:2080(<genexpr>)\n",
      "     1740    0.001    0.000    0.002    0.000 groupby.py:2081(<genexpr>)\n",
      "     1740    0.001    0.000    0.003    0.000 groupby.py:2086(<genexpr>)\n",
      "      900    0.001    0.000    0.001    0.000 groupby.py:2108(is_in_axis)\n",
      "      900    0.003    0.000    0.004    0.000 groupby.py:2118(is_in_obj)\n",
      "      900    0.001    0.000    0.001    0.000 groupby.py:2154(_is_label_like)\n",
      "      900    0.003    0.000    0.008    0.000 groupby.py:2158(_convert_grouper)\n",
      "      840    0.006    0.000    0.144    0.000 groupby.py:359(__init__)\n",
      "      840    0.003    0.000    0.045    0.000 groupby.py:397(groups)\n",
      "   141720    0.249    0.000    1.064    0.000 index.py:1054(equals)\n",
      "    70000    0.046    0.000    0.261    0.000 index.py:1069(identical)\n",
      "212450/212370    2.084    0.000    7.642    0.000 index.py:125(__new__)\n",
      "     1700    0.002    0.000    0.006    0.000 index.py:1394(get_loc)\n",
      "    70820    0.460    0.000    1.450    0.000 index.py:1465(get_indexer)\n",
      "    70820    0.270    0.000    0.270    0.000 index.py:1548(_possibly_promote)\n",
      "      840    0.002    0.000    0.010    0.000 index.py:1558(groupby)\n",
      "    70710    2.686    0.000    3.445    0.000 index.py:1578(isin)\n",
      "    70820    0.058    0.000    0.073    0.000 index.py:1608(_get_method)\n",
      "    70820    0.442    0.000    6.376    0.000 index.py:1618(reindex)\n",
      "   283330    0.614    0.000    1.210    0.000 index.py:216(_simple_new)\n",
      "   141720    0.090    0.000    0.171    0.000 index.py:230(is_)\n",
      "   283350    0.157    0.000    0.157    0.000 index.py:249(_reset_identity)\n",
      "   218380    0.098    0.000    0.134    0.000 index.py:254(__len__)\n",
      "      110    0.000    0.000    0.001    0.000 index.py:2541(__new__)\n",
      "      110    0.000    0.000    0.001    0.000 index.py:2677(_nan_idxs)\n",
      "      110    0.001    0.000    0.001    0.000 index.py:2682(_isnan)\n",
      "      110    0.000    0.000    0.003    0.000 index.py:2690(is_unique)\n",
      "    70820    0.027    0.000    0.027    0.000 index.py:270(dtype)\n",
      "       20    0.000    0.000    0.003    0.000 index.py:2738(__new__)\n",
      "   496710    0.323    0.000    0.629    0.000 index.py:275(values)\n",
      "      180    0.000    0.000    0.000    0.000 index.py:2796(_get_levels)\n",
      "       20    0.000    0.000    0.001    0.000 index.py:2799(_set_levels)\n",
      "   141640    0.086    0.000    0.239    0.000 index.py:280(get_values)\n",
      "      100    0.000    0.000    0.001    0.000 index.py:2812(<genexpr>)\n",
      "    70710    0.020    0.000    0.020    0.000 index.py:284(_array_values)\n",
      "       20    0.000    0.000    0.000    0.000 index.py:2903(_get_labels)\n",
      "       20    0.000    0.000    0.001    0.000 index.py:2906(_set_labels)\n",
      "      100    0.000    0.000    0.001    0.000 index.py:2915(<genexpr>)\n",
      "       20    0.000    0.000    0.000    0.000 index.py:3105(_get_names)\n",
      "       20    0.000    0.000    0.000    0.000 index.py:3106(<genexpr>)\n",
      "       20    0.000    0.000    0.001    0.000 index.py:3108(_set_names)\n",
      "       20    0.000    0.000    0.004    0.000 index.py:3185(values)\n",
      "      110    0.000    0.000    0.000    0.000 index.py:327(_coerce_to_ndarray)\n",
      "    70900    0.204    0.000    0.218    0.000 index.py:342(_get_attributes_dict)\n",
      "       20    0.000    0.000    0.018    0.001 index.py:3447(from_arrays)\n",
      "       20    0.000    0.000    0.019    0.001 index.py:3492(from_tuples)\n",
      "    70790    0.183    0.000    0.770    0.000 index.py:355(_shallow_copy)\n",
      "       40    0.000    0.000    0.000    0.000 index.py:3581(nlevels)\n",
      "    70710    0.079    0.000    0.848    0.000 index.py:364(copy)\n",
      "    70820    0.012    0.000    0.012    0.000 index.py:455(nlevels)\n",
      "       80    0.000    0.000    0.000    0.000 index.py:462(_set_names)\n",
      "       80    0.000    0.000    0.000    0.000 index.py:470(set_names)\n",
      "   355740    0.387    0.000    5.876    0.000 index.py:4742(_ensure_index)\n",
      "       80    0.000    0.000    0.000    0.000 index.py:4772(_ensure_frozen)\n",
      "    70820    0.036    0.000    0.047    0.000 index.py:4908(_ensure_has_len)\n",
      "       80    0.000    0.000    0.000    0.000 index.py:528(rename)\n",
      "    70900    0.506    0.000    0.866    0.000 index.py:598(is_unique)\n",
      "    70820    0.040    0.000    0.040    0.000 index.py:609(is_floating)\n",
      "    70000    0.062    0.000    0.082    0.000 index.py:624(_convert_scalar_indexer)\n",
      "    70820    0.031    0.000    0.031    0.000 index.py:756(_convert_list_indexer_for_mixed)\n",
      "    70900    0.103    0.000    0.211    0.000 index.py:797(_engine)\n",
      "    70900    0.053    0.000    0.149    0.000 index.py:800(<lambda>)\n",
      "    70820    0.166    0.000    0.434    0.000 index.py:834(is_all_dates)\n",
      "    70710    0.071    0.000    0.194    0.000 index.py:840(__iter__)\n",
      "   141800    0.160    0.000    0.180    0.000 index.py:884(__contains__)\n",
      "      850    0.002    0.000    0.003    0.000 index.py:898(__getitem__)\n",
      "140820/70820    0.146    0.000   37.381    0.001 indexing.py:1198(__getitem__)\n",
      "   140820    1.222    0.000    9.981    0.000 indexing.py:1240(_has_valid_type)\n",
      "   140820    0.551    0.000   35.089    0.000 indexing.py:1311(_getitem_axis)\n",
      "    70820    0.105    0.000    0.318    0.000 indexing.py:135(_should_validate_iterable)\n",
      "    70000    0.184    0.000    0.347    0.000 indexing.py:145(_is_nested_tuple_indexer)\n",
      "    70000    0.166    0.000    0.440    0.000 indexing.py:165(_convert_scalar_indexer)\n",
      "   140000    0.105    0.000    0.373    0.000 indexing.py:1743(_is_label_like)\n",
      "   491640    0.335    0.000    0.720    0.000 indexing.py:1748(_is_list_like)\n",
      "    70000    0.053    0.000   36.710    0.001 indexing.py:697(_getitem_tuple)\n",
      "    70000    0.094    0.000    0.842    0.000 indexing.py:74(_get_label)\n",
      "    70000    0.688    0.000   36.657    0.001 indexing.py:798(_getitem_lowerdim)\n",
      "    70820    0.806    0.000   31.291    0.000 indexing.py:930(_getitem_iterable)\n",
      "    70820    0.167    0.000   16.509    0.000 indexing.py:936(_reindex)\n",
      "    83970    0.021    0.000    0.021    0.000 internals.py:118(mgr_locs)\n",
      "    74130    0.106    0.000    0.607    0.000 internals.py:127(make_block_same_class)\n",
      "    74130    0.105    0.000    0.140    0.000 internals.py:140(mgr_locs)\n",
      "     1670    0.004    0.000    0.013    0.000 internals.py:1420(__init__)\n",
      "    74130    0.115    0.000    0.501    0.000 internals.py:2054(make_block)\n",
      "      820    0.006    0.000    0.085    0.000 internals.py:2161(__init__)\n",
      "     3280    0.001    0.000    0.001    0.000 internals.py:219(shape)\n",
      "    72460    0.239    0.000    0.409    0.000 internals.py:2202(shape)\n",
      "   147380    0.057    0.000    0.170    0.000 internals.py:2204(<genexpr>)\n",
      "    74100    0.034    0.000    0.042    0.000 internals.py:2206(ndim)\n",
      "    70000    0.027    0.000    0.027    0.000 internals.py:2244(_is_single_block)\n",
      "      820    0.023    0.000    0.050    0.000 internals.py:2256(_rebuild_blknos_and_blklocs)\n",
      "    76560    0.031    0.000    0.031    0.000 internals.py:227(dtype)\n",
      "     2520    0.001    0.000    0.001    0.000 internals.py:2277(_get_items)\n",
      "     3280    0.003    0.000    0.004    0.000 internals.py:231(ftype)\n",
      "      820    0.005    0.000    0.019    0.000 internals.py:2382(_verify_integrity)\n",
      "     4100    0.002    0.000    0.003    0.000 internals.py:2384(<genexpr>)\n",
      "     2480    0.001    0.000    0.001    0.000 internals.py:2558(is_consolidated)\n",
      "      820    0.004    0.000    0.008    0.000 internals.py:2566(_consolidate_check)\n",
      "      850    0.001    0.000    0.001    0.000 internals.py:258(iget)\n",
      "    71660    0.044    0.000    0.059    0.000 internals.py:2819(consolidate)\n",
      "      820    0.000    0.000    0.001    0.000 internals.py:2834(_consolidate_inplace)\n",
      "      850    0.003    0.000    0.030    0.000 internals.py:2842(get)\n",
      "      850    0.005    0.000    0.021    0.000 internals.py:2870(iget)\n",
      "    70820    0.359    0.000    4.405    0.000 internals.py:3122(reindex_indexer)\n",
      "    70000    0.324    0.000    3.486    0.000 internals.py:3168(_slice_take_blocks_ax0)\n",
      "    70850    0.204    0.000    0.297    0.000 internals.py:3331(__init__)\n",
      "    70900    0.025    0.000    0.025    0.000 internals.py:3378(_block)\n",
      "    70900    0.049    0.000    0.074    0.000 internals.py:3382(_values)\n",
      "    70000    0.022    0.000    0.022    0.000 internals.py:3432(index)\n",
      "    70900    0.073    0.000    0.192    0.000 internals.py:3465(values)\n",
      "    70000    0.015    0.000    0.015    0.000 internals.py:3481(is_consolidated)\n",
      "    70000    0.012    0.000    0.012    0.000 internals.py:3487(_consolidate_inplace)\n",
      "    70000    0.179    0.000    0.377    0.000 internals.py:4443(_preprocess_slice_or_indexer)\n",
      "    74130    0.181    0.000    0.381    0.000 internals.py:63(__init__)\n",
      "    73280    0.283    0.000    2.533    0.000 internals.py:838(take_nd)\n",
      "    73280    0.020    0.000    0.020    0.000 internals.py:867(get_values)\n",
      "      530    0.001    0.000    0.003    0.000 newrange.py:134(__iter__)\n",
      "      530    0.001    0.000    0.002    0.000 newrange.py:143(__init__)\n",
      "    36380    0.035    0.000    0.075    0.000 newrange.py:149(next)\n",
      "    36380    0.016    0.000    0.016    0.000 newrange.py:154(_count)\n",
      "      530    0.002    0.000    0.003    0.000 newrange.py:32(__init__)\n",
      "      530    0.000    0.000    0.000    0.000 newrange.py:59(start)\n",
      "      530    0.000    0.000    0.000    0.000 newrange.py:67(step)\n",
      "      530    0.000    0.000    0.000    0.000 newrange.py:82(__len__)\n",
      "    35000    0.037    0.000    0.037    0.000 numeric.py:1347(rollaxis)\n",
      "       10    0.000    0.000    0.000    0.000 numeric.py:141(ones)\n",
      "    70980    0.040    0.000    0.072    0.000 numeric.py:1910(isscalar)\n",
      "   847940    0.554    0.000    2.223    0.000 numeric.py:394(asarray)\n",
      "    71280    0.065    0.000    0.153    0.000 numeric.py:464(asanyarray)\n",
      "    70000    0.027    0.000    0.051    0.000 numerictypes.py:668(issubclass_)\n",
      "    70000    0.081    0.000    0.145    0.000 numerictypes.py:736(issubdtype)\n",
      "        1    0.001    0.001   45.195   45.195 power.py:328(subsample_paired_power)\n",
      "       10    0.029    0.003    0.886    0.089 power.py:666(paired_subsamples)\n",
      "     3320    0.002    0.000    0.002    0.000 power.py:794(_check_strs)\n",
      "       70    0.001    0.000    0.002    0.000 power.py:805(_calculate_power)\n",
      "       70    0.330    0.005   44.304    0.633 power.py:829(_compare_distributions)\n",
      "       10    0.001    0.000   44.308    4.431 power.py:916(_calculate_power_curve)\n",
      "    70850    0.383    0.000    1.405    0.000 series.py:114(__init__)\n",
      "    70000    0.017    0.000    0.017    0.000 series.py:2137(_needs_reindex_multi)\n",
      "    70000    0.205    0.000   15.830    0.000 series.py:2147(reindex)\n",
      "    70000    0.116    0.000   15.946    0.000 series.py:2151(reindex_axis)\n",
      "      850    0.002    0.000    0.019    0.000 series.py:220(from_array)\n",
      "    70000    0.016    0.000    0.016    0.000 series.py:230(_constructor)\n",
      "    70850    0.277    0.000    0.791    0.000 series.py:245(_set_axis)\n",
      "    70850    0.081    0.000    0.081    0.000 series.py:265(_set_subtyp)\n",
      "    70900    0.056    0.000    0.248    0.000 series.py:296(values)\n",
      "      640    0.002    0.000    0.009    0.000 shape_base.py:230(hstack)\n",
      "     1280    0.002    0.000    0.005    0.000 shape_base.py:8(atleast_1d)\n",
      "    70000    0.056    0.000    0.164    0.000 stats.py:212(_chk_asarray)\n",
      "    35000    0.703    0.000    5.221    0.000 stats.py:4149(kruskal)\n",
      "    35000    0.240    0.000    0.240    0.000 stats.py:4363(chisqprob)\n",
      "    70000    0.198    0.000    1.017    0.000 stats.py:4549(square_of_sums)\n",
      "    70840    0.018    0.000    0.021    0.000 {all}\n",
      "    71700    0.021    0.000    0.024    0.000 {any}\n",
      "   283350    0.103    0.000    0.103    0.000 {built-in method __new__ of type object at 0x10017ff20}\n",
      "      900    0.000    0.000    0.000    0.000 {callable}\n",
      "       80    0.000    0.000    0.000    0.000 {function __getitem__ at 0x1085e7140}\n",
      "2046180/1976180    0.904    0.000    0.937    0.000 {getattr}\n",
      "  1057630    0.471    0.000    0.471    0.000 {hasattr}\n",
      "   141800    0.019    0.000    0.019    0.000 {hash}\n",
      "      900    0.000    0.000    0.000    0.000 {id}\n",
      "  7235790    2.067    0.000    2.654    0.000 {isinstance}\n",
      "  1993330    0.441    0.000    0.441    0.000 {issubclass}\n",
      "    70710    0.021    0.000    0.021    0.000 {iter}\n",
      "1494082/1275702    0.381    0.000    0.480    0.000 {len}\n",
      "    70000    0.088    0.000    0.189    0.000 {map}\n",
      "      530    0.000    0.000    0.000    0.000 {max}\n",
      "      900    0.001    0.000    0.006    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "    73240    0.067    0.000    0.627    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "     3800    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "    70080    0.173    0.000    0.173    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "       70    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "    36130    0.609    0.000    0.978    0.000 {method 'choice' of 'mtrand.RandomState' objects}\n",
      "    35000    0.129    0.000    0.129    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      810    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "     1640    0.001    0.000    0.001    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
      "  1693360    0.252    0.000    0.252    0.000 {method 'get' of 'dict' objects}\n",
      "    70820    0.476    0.000    0.476    0.000 {method 'get_indexer' of 'pandas.index.IndexEngine' objects}\n",
      "       80    0.001    0.000    0.001    0.000 {method 'get_labels' of 'pandas.hashtable.PyObjectHashTable' objects}\n",
      "     1700    0.002    0.000    0.002    0.000 {method 'get_loc' of 'pandas.index.IndexEngine' objects}\n",
      "    35000    0.010    0.000    0.010    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "    70820    0.026    0.000    0.026    0.000 {method 'items' of 'dict' objects}\n",
      "   283330    0.065    0.000    0.065    0.000 {method 'iteritems' of 'dict' objects}\n",
      "    70820    0.018    0.000    0.018    0.000 {method 'keys' of 'dict' objects}\n",
      "      820    0.001    0.000    0.007    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
      "      110    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "      110    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "    36130    0.072    0.000    0.301    0.000 {method 'prod' of 'numpy.generic' objects}\n",
      "       80    0.000    0.000    0.000    0.000 {method 'put' of 'numpy.ndarray' objects}\n",
      "    35000    0.024    0.000    0.024    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "   216160    1.271    0.000    1.271    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     1120    0.001    0.000    0.001    0.000 {method 'remove' of 'list' objects}\n",
      "       70    0.000    0.000    0.000    0.000 {method 'round' of 'numpy.ndarray' objects}\n",
      "      220    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       70    0.000    0.000    0.001    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "      160    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "       80    0.000    0.000    0.000    0.000 {method 'to_array' of 'pandas.hashtable.ObjectVector' objects}\n",
      "    70790    0.026    0.000    0.026    0.000 {method 'update' of 'dict' objects}\n",
      "   569490    0.352    0.000    0.352    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'viewitems' of 'dict' objects}\n",
      "    70081    0.037    0.000    0.037    0.000 {min}\n",
      "    36380    0.023    0.000    0.039    0.000 {next}\n",
      "    38362    0.110    0.000    0.110    0.000 {numpy.core.multiarray.arange}\n",
      "   991230    1.860    0.000    1.860    0.000 {numpy.core.multiarray.array}\n",
      "    35640    0.126    0.000    0.126    0.000 {numpy.core.multiarray.concatenate}\n",
      "       10    0.000    0.000    0.000    0.000 {numpy.core.multiarray.copyto}\n",
      "   110200    0.166    0.000    0.166    0.000 {numpy.core.multiarray.empty}\n",
      "       80    0.000    0.000    0.000    0.000 {numpy.core.multiarray.putmask}\n",
      "       81    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}\n",
      "   217540    0.033    0.000    0.033    0.000 {pandas.algos.ensure_int64}\n",
      "      160    0.000    0.000    0.000    0.000 {pandas.algos.ensure_int8}\n",
      "    70910    0.015    0.000    0.015    0.000 {pandas.algos.ensure_object}\n",
      "    70900    0.016    0.000    0.016    0.000 {pandas.algos.ensure_platform_int}\n",
      "      840    0.006    0.000    0.006    0.000 {pandas.algos.groupby_object}\n",
      "    70000    0.260    0.000    0.260    0.000 {pandas.algos.take_1d_float64_float64}\n",
      "       80    0.000    0.000    0.000    0.000 {pandas.algos.take_1d_object_object}\n",
      "      820    0.007    0.000    0.007    0.000 {pandas.algos.take_2d_axis1_bool_bool}\n",
      "      820    0.008    0.000    0.008    0.000 {pandas.algos.take_2d_axis1_float64_float64}\n",
      "      820    0.006    0.000    0.006    0.000 {pandas.algos.take_2d_axis1_int64_int64}\n",
      "      820    0.025    0.000    0.025    0.000 {pandas.algos.take_2d_axis1_object_object}\n",
      "      850    0.001    0.000    0.001    0.000 {pandas.lib.checknull}\n",
      "      820    0.018    0.000    0.018    0.000 {pandas.lib.clean_index_list}\n",
      "       20    0.001    0.000    0.001    0.000 {pandas.lib.fast_zip}\n",
      "   212400    1.480    0.000    1.480    0.000 {pandas.lib.infer_dtype}\n",
      "    70820    0.140    0.000    0.140    0.000 {pandas.lib.is_datetime_array}\n",
      "   143360    0.033    0.000    0.033    0.000 {pandas.lib.is_float}\n",
      "   212500    0.039    0.000    0.039    0.000 {pandas.lib.is_integer}\n",
      "       10    0.000    0.000    0.000    0.000 {pandas.lib.is_possible_datetimelike_array}\n",
      "      110    0.000    0.000    0.000    0.000 {pandas.lib.is_timedelta_array}\n",
      "    70710    0.546    0.000    0.546    0.000 {pandas.lib.ismember}\n",
      "      850    0.000    0.000    0.000    0.000 {pandas.lib.isscalar}\n",
      "      110    0.001    0.000    0.001    0.000 {pandas.lib.list_to_object_array}\n",
      "       20    0.001    0.000    0.001    0.000 {pandas.lib.to_object_array_tuples}\n",
      "   144180    0.084    0.000    0.324    0.000 {pandas.lib.values_from_object}\n",
      "      110    0.000    0.000    0.000    0.000 {pandas.tslib.is_timestamp_array}\n",
      "    35000    0.030    0.000    0.030    0.000 {range}\n",
      "    35000    0.570    0.000    1.036    0.000 {scipy.stats._rank.rankdata}\n",
      "    35000    0.343    0.000    0.482    0.000 {scipy.stats._rank.tiecorrect}\n",
      "    70840    0.097    0.000    0.097    0.000 {sorted}\n",
      "      820    0.001    0.000    0.004    0.000 {sum}\n",
      "       20    0.001    0.000    0.001    0.000 {zip}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@do_cprofile\n",
    "def calc_old_etoh_pwr():\n",
    "    pwr_etoh_220, cnts_etoh_220 = skbio.stats.power.subsample_paired_power(test_alpha,\n",
    "                                                                     map_,\n",
    "                                                                     'ALCOHOL_FREQUENCY',\n",
    "                                                                     ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                                     ['Never', 'Daily'],\n",
    "                                                                     num_iter=500,\n",
    "                                                                     counts_interval=2,\n",
    "                                                                     min_observations=15,\n",
    "                                                                     max_counts=16)\n",
    "    return 'Etanol Power!'\n",
    "results_old = calc_old_etoh_pwr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         39462702 function calls (39052626 primitive calls) in 55.278 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   55.278   55.278 <ipython-input-20-29179cc64850>:1(calc_new_etoh_pwr)\n",
      "        1    0.009    0.009   55.278   55.278 <ipython-input-3-ea3fa562006d>:1(subsample_paired_power)\n",
      "       70    0.002    0.000    0.003    0.000 <ipython-input-3-ea3fa562006d>:118(_calculate_power)\n",
      "       71    0.204    0.003    6.543    0.092 <ipython-input-3-ea3fa562006d>:128(paired_subsamples)\n",
      "    23572    0.011    0.000    0.014    0.000 <ipython-input-3-ea3fa562006d>:187(_check_strs)\n",
      "       70    0.382    0.005   48.722    0.696 <ipython-input-3-ea3fa562006d>:69(_compare_distributions)\n",
      "    35001    0.593    0.000   47.174    0.001 <ipython-input-5-640c322d58e3>:1(test_alpha)\n",
      "   303651    0.250    0.000    0.427    0.000 __init__.py:121(iteritems)\n",
      "       71    0.000    0.000    0.000    0.000 __init__.py:247(viewitems)\n",
      "     5822    0.005    0.000    0.045    0.000 _methods.py:28(_amin)\n",
      "   105073    0.064    0.000    0.677    0.000 _methods.py:31(_sum)\n",
      "    43023    0.031    0.000    0.290    0.000 _methods.py:34(_prod)\n",
      "    92579    0.072    0.000    0.778    0.000 _methods.py:37(_any)\n",
      "     5963    0.004    0.000    0.038    0.000 _methods.py:40(_all)\n",
      "      568    0.001    0.000    0.006    0.000 algorithms.py:402(_get_data_algo)\n",
      "      568    0.017    0.000    0.047    0.000 algorithms.py:98(factorize)\n",
      "      568    0.001    0.000    0.001    0.000 base.py:189(__getitem__)\n",
      "      568    0.000    0.000    0.001    0.000 base.py:252(_shallow_copy)\n",
      "    70002    0.014    0.000    0.014    0.000 base.py:289(ndim)\n",
      "      284    0.000    0.000    0.000    0.000 base.py:98(_reset_cache)\n",
      "      568    0.006    0.000    0.103    0.000 categorical.py:212(__init__)\n",
      "      568    0.001    0.000    0.104    0.000 categorical.py:337(from_array)\n",
      "      568    0.001    0.000    0.001    0.000 categorical.py:388(_get_codes)\n",
      "      568    0.003    0.000    0.032    0.000 categorical.py:421(_validate_categories)\n",
      "      568    0.001    0.000    0.033    0.000 categorical.py:440(_set_categories)\n",
      "      568    0.000    0.000    0.000    0.000 categorical.py:448(_get_categories)\n",
      "    93858    0.333    0.000    0.487    0.000 common.py:1072(_maybe_promote)\n",
      "     6035    0.003    0.000    0.017    0.000 common.py:191(isnull)\n",
      "      568    0.003    0.000    0.010    0.000 common.py:1982(_possibly_infer_to_datetimelike)\n",
      "   367476    0.500    0.000    1.503    0.000 common.py:2053(_is_bool_indexer)\n",
      "     6035    0.008    0.000    0.014    0.000 common.py:212(_isnull_new)\n",
      "   302302    1.763    0.000    3.908    0.000 common.py:2279(_asarray_tuplesafe)\n",
      "   241317    0.263    0.000    0.424    0.000 common.py:2387(_get_dtype_type)\n",
      "      568    0.000    0.000    0.001    0.000 common.py:2402(is_integer_dtype)\n",
      "     6958    0.007    0.000    0.022    0.000 common.py:2414(is_datetime64_dtype)\n",
      "     6958    0.006    0.000    0.019    0.000 common.py:2423(is_timedelta64_dtype)\n",
      "      568    0.001    0.000    0.002    0.000 common.py:2433(_is_datetime_or_timedelta_dtype)\n",
      "      568    0.000    0.000    0.001    0.000 common.py:2454(is_float_dtype)\n",
      "   225697    0.195    0.000    0.638    0.000 common.py:2464(is_bool_dtype)\n",
      "      568    0.002    0.000    0.003    0.000 common.py:2468(is_categorical_dtype)\n",
      "     1704    0.001    0.000    0.002    0.000 common.py:2502(is_list_like)\n",
      "    75824    0.021    0.000    0.021    0.000 common.py:2633(_clean_fill_method)\n",
      "    75824    0.143    0.000    0.337    0.000 common.py:386(array_equivalent)\n",
      "     5822    0.012    0.000    0.071    0.000 common.py:535(wrapper)\n",
      "   444436    0.272    0.000    0.686    0.000 common.py:59(_check)\n",
      "    93858    0.125    0.000    0.185    0.000 common.py:703(_get_take_nd_function)\n",
      "    93858    0.983    0.000    2.653    0.000 common.py:735(take_nd)\n",
      "     1136    0.001    0.000    0.004    0.000 common.py:969(_coerce_indexer_dtype)\n",
      "    76392    0.159    0.000    0.935    0.000 frame.py:1757(__getitem__)\n",
      "    76392    0.086    0.000    0.674    0.000 frame.py:1782(_getitem_column)\n",
      "     5822    0.002    0.000    0.002    0.000 frame.py:188(_constructor)\n",
      "     5822    0.029    0.000    0.058    0.000 frame.py:194(__init__)\n",
      "     6035    0.019    0.000    0.209    0.000 frame.py:2085(_box_item_values)\n",
      "     6035    0.011    0.000    0.148    0.000 frame.py:2092(_box_col_values)\n",
      "     5822    0.022    0.000    2.790    0.000 frame.py:2406(reindex_axis)\n",
      "    70002    0.084    0.000    0.084    0.000 frame.py:401(axes)\n",
      "    35001    0.038    0.000    0.098    0.000 fromnumeric.py:1283(ravel)\n",
      "   105003    0.167    0.000    0.890    0.000 fromnumeric.py:1623(sum)\n",
      "    35001    0.027    0.000    0.179    0.000 fromnumeric.py:1917(cumsum)\n",
      "    43023    0.090    0.000    0.474    0.000 fromnumeric.py:2251(prod)\n",
      "        7    0.000    0.000    0.000    0.000 fromnumeric.py:2625(round_)\n",
      "    70002    0.058    0.000    0.253    0.000 fromnumeric.py:795(argsort)\n",
      "    35001    0.703    0.000    0.971    0.000 function_base.py:3625(insert)\n",
      "   145826    0.094    0.000    0.150    0.000 generic.py:1030(_indexer)\n",
      "    76392    0.078    0.000    0.588    0.000 generic.py:1063(_get_item_cache)\n",
      "     6035    0.018    0.000    0.064    0.000 generic.py:1077(_set_as_cached)\n",
      "     5822    0.009    0.000    0.012    0.000 generic.py:117(_init_mgr)\n",
      "    70002    0.152    0.000    0.797    0.000 generic.py:1341(xs)\n",
      "    70002    0.793    0.000   17.149    0.000 generic.py:1701(reindex)\n",
      "    70002    0.341    0.000   14.713    0.000 generic.py:1733(_reindex_axes)\n",
      "     5822    0.037    0.000    2.768    0.000 generic.py:1798(reindex_axis)\n",
      "    75824    0.633    0.000    9.311    0.000 generic.py:1812(_reindex_with_indexers)\n",
      "   145826    0.231    0.000    0.304    0.000 generic.py:1915(__finalize__)\n",
      "    93858    0.205    0.000    0.205    0.000 generic.py:1949(__setattr__)\n",
      "    81788    0.170    0.000    0.630    0.000 generic.py:1986(_consolidate_inplace)\n",
      "    81788    0.069    0.000    0.147    0.000 generic.py:1987(<lambda>)\n",
      "    81788    0.134    0.000    0.306    0.000 generic.py:2047(_protect_consolidate)\n",
      "    70002    0.339    0.000    0.360    0.000 generic.py:238(_construct_axes_from_arguments)\n",
      "     5964    0.050    0.000    1.156    0.000 generic.py:2847(groupby)\n",
      "   227756    0.304    0.000    0.382    0.000 generic.py:285(_get_axis_number)\n",
      "   810918    0.838    0.000    1.225    0.000 generic.py:298(_get_axis_name)\n",
      "   805096    0.615    0.000    2.153    0.000 generic.py:311(_get_axis)\n",
      "    75824    0.058    0.000    0.174    0.000 generic.py:315(_get_block_manager_axis)\n",
      "    70002    0.061    0.000    0.106    0.000 generic.py:379(ndim)\n",
      "    81859    0.155    0.000    0.155    0.000 generic.py:87(__init__)\n",
      "     5964    0.017    0.000    1.093    0.000 groupby.py:1184(groupby)\n",
      "     5964    0.005    0.000    0.005    0.000 groupby.py:1219(__init__)\n",
      "     5964    0.012    0.000    0.306    0.000 groupby.py:1344(groups)\n",
      "      710    0.000    0.000    0.000    0.000 groupby.py:1350(<genexpr>)\n",
      "     6390    0.041    0.000    0.152    0.000 groupby.py:1865(__init__)\n",
      "     5822    0.010    0.000    0.065    0.000 groupby.py:2020(groups)\n",
      "     5964    0.118    0.000    0.976    0.000 groupby.py:2026(_get_grouper)\n",
      "    12354    0.007    0.000    0.010    0.000 groupby.py:2080(<genexpr>)\n",
      "    12354    0.007    0.000    0.011    0.000 groupby.py:2081(<genexpr>)\n",
      "    12354    0.011    0.000    0.023    0.000 groupby.py:2086(<genexpr>)\n",
      "     6390    0.005    0.000    0.010    0.000 groupby.py:2108(is_in_axis)\n",
      "     6390    0.026    0.000    0.027    0.000 groupby.py:2118(is_in_obj)\n",
      "     6390    0.004    0.000    0.006    0.000 groupby.py:2154(_is_label_like)\n",
      "     6390    0.020    0.000    0.060    0.000 groupby.py:2158(_convert_grouper)\n",
      "     5964    0.043    0.000    1.073    0.000 groupby.py:359(__init__)\n",
      "     5964    0.019    0.000    0.324    0.000 groupby.py:397(groups)\n",
      "   152216    0.289    0.000    1.233    0.000 index.py:1054(equals)\n",
      "    70002    0.051    0.000    0.289    0.000 index.py:1069(identical)\n",
      "227401/226833    2.440    0.000    9.061    0.000 index.py:125(__new__)\n",
      "    12070    0.014    0.000    0.045    0.000 index.py:1394(get_loc)\n",
      "    75824    0.536    0.000    1.692    0.000 index.py:1465(get_indexer)\n",
      "    75824    0.317    0.000    0.317    0.000 index.py:1548(_possibly_promote)\n",
      "     5964    0.015    0.000    0.074    0.000 index.py:1558(groupby)\n",
      "    75043    3.100    0.000    3.991    0.000 index.py:1578(isin)\n",
      "    75824    0.068    0.000    0.086    0.000 index.py:1608(_get_method)\n",
      "    75824    0.520    0.000    7.423    0.000 index.py:1618(reindex)\n",
      "   303651    0.725    0.000    1.459    0.000 index.py:216(_simple_new)\n",
      "   152216    0.108    0.000    0.200    0.000 index.py:230(is_)\n",
      "   303793    0.187    0.000    0.187    0.000 index.py:249(_reset_identity)\n",
      "   269504    0.129    0.000    0.174    0.000 index.py:254(__len__)\n",
      "      781    0.003    0.000    0.008    0.000 index.py:2541(__new__)\n",
      "      781    0.001    0.000    0.007    0.000 index.py:2677(_nan_idxs)\n",
      "      781    0.004    0.000    0.005    0.000 index.py:2682(_isnan)\n",
      "      781    0.003    0.000    0.021    0.000 index.py:2690(is_unique)\n",
      "    75824    0.031    0.000    0.031    0.000 index.py:270(dtype)\n",
      "      142    0.001    0.000    0.024    0.000 index.py:2738(__new__)\n",
      "   537655    0.377    0.000    0.738    0.000 index.py:275(values)\n",
      "     1278    0.000    0.000    0.000    0.000 index.py:2796(_get_levels)\n",
      "      142    0.001    0.000    0.010    0.000 index.py:2799(_set_levels)\n",
      "   151648    0.100    0.000    0.278    0.000 index.py:280(get_values)\n",
      "      710    0.001    0.000    0.007    0.000 index.py:2812(<genexpr>)\n",
      "    75043    0.024    0.000    0.024    0.000 index.py:284(_array_values)\n",
      "      142    0.000    0.000    0.000    0.000 index.py:2903(_get_labels)\n",
      "      142    0.001    0.000    0.006    0.000 index.py:2906(_set_labels)\n",
      "      710    0.001    0.000    0.004    0.000 index.py:2915(<genexpr>)\n",
      "      142    0.001    0.000    0.001    0.000 index.py:3105(_get_names)\n",
      "      142    0.000    0.000    0.000    0.000 index.py:3106(<genexpr>)\n",
      "      142    0.002    0.000    0.007    0.000 index.py:3108(_set_names)\n",
      "      142    0.003    0.000    0.025    0.000 index.py:3185(values)\n",
      "      781    0.001    0.000    0.001    0.000 index.py:327(_coerce_to_ndarray)\n",
      "    76392    0.241    0.000    0.257    0.000 index.py:342(_get_attributes_dict)\n",
      "      142    0.003    0.000    0.132    0.001 index.py:3447(from_arrays)\n",
      "      142    0.002    0.000    0.139    0.001 index.py:3492(from_tuples)\n",
      "    75611    0.214    0.000    0.930    0.000 index.py:355(_shallow_copy)\n",
      "      284    0.000    0.000    0.000    0.000 index.py:3581(nlevels)\n",
      "    75043    0.092    0.000    1.016    0.000 index.py:364(copy)\n",
      "    75824    0.015    0.000    0.015    0.000 index.py:455(nlevels)\n",
      "      568    0.000    0.000    0.000    0.000 index.py:462(_set_names)\n",
      "      568    0.001    0.000    0.003    0.000 index.py:470(set_names)\n",
      "   390764    0.461    0.000    6.990    0.000 index.py:4742(_ensure_index)\n",
      "      568    0.001    0.000    0.002    0.000 index.py:4772(_ensure_frozen)\n",
      "    75824    0.042    0.000    0.055    0.000 index.py:4908(_ensure_has_len)\n",
      "      568    0.001    0.000    0.003    0.000 index.py:528(rename)\n",
      "    76392    0.610    0.000    1.037    0.000 index.py:598(is_unique)\n",
      "    75824    0.048    0.000    0.048    0.000 index.py:609(is_floating)\n",
      "    70002    0.070    0.000    0.091    0.000 index.py:624(_convert_scalar_indexer)\n",
      "    75824    0.036    0.000    0.036    0.000 index.py:756(_convert_list_indexer_for_mixed)\n",
      "    76392    0.126    0.000    0.253    0.000 index.py:797(_engine)\n",
      "    76392    0.061    0.000    0.173    0.000 index.py:800(<lambda>)\n",
      "    75824    0.194    0.000    0.514    0.000 index.py:834(is_all_dates)\n",
      "    75043    0.083    0.000    0.228    0.000 index.py:840(__iter__)\n",
      "   152784    0.196    0.000    0.219    0.000 index.py:884(__contains__)\n",
      "     6035    0.013    0.000    0.022    0.000 index.py:898(__getitem__)\n",
      "145826/75824    0.172    0.000   44.854    0.001 indexing.py:1198(__getitem__)\n",
      "   145826    1.389    0.000   11.735    0.000 indexing.py:1240(_has_valid_type)\n",
      "   145826    0.634    0.000   42.284    0.000 indexing.py:1311(_getitem_axis)\n",
      "    75824    0.124    0.000    0.374    0.000 indexing.py:135(_should_validate_iterable)\n",
      "    70002    0.209    0.000    0.392    0.000 indexing.py:145(_is_nested_tuple_indexer)\n",
      "    70002    0.189    0.000    0.487    0.000 indexing.py:165(_convert_scalar_indexer)\n",
      "   140004    0.118    0.000    0.414    0.000 indexing.py:1743(_is_label_like)\n",
      "   501658    0.371    0.000    0.798    0.000 indexing.py:1748(_is_list_like)\n",
      "    70002    0.061    0.000   40.339    0.001 indexing.py:697(_getitem_tuple)\n",
      "    70002    0.105    0.000    0.928    0.000 indexing.py:74(_get_label)\n",
      "    70002    0.777    0.000   40.278    0.001 indexing.py:798(_getitem_lowerdim)\n",
      "    75824    0.945    0.000   37.995    0.001 indexing.py:930(_getitem_iterable)\n",
      "    75824    0.194    0.000   20.528    0.000 indexing.py:936(_reindex)\n",
      "   169189    0.047    0.000    0.047    0.000 internals.py:118(mgr_locs)\n",
      "    99325    0.154    0.000    0.897    0.000 internals.py:127(make_block_same_class)\n",
      "    99325    0.141    0.000    0.186    0.000 internals.py:140(mgr_locs)\n",
      "    11857    0.031    0.000    0.097    0.000 internals.py:1420(__init__)\n",
      "    99325    0.170    0.000    0.744    0.000 internals.py:2054(make_block)\n",
      "     5822    0.045    0.000    0.616    0.000 internals.py:2161(__init__)\n",
      "    23288    0.008    0.000    0.008    0.000 internals.py:219(shape)\n",
      "    87468    0.310    0.000    0.540    0.000 internals.py:2202(shape)\n",
      "   192402    0.074    0.000    0.230    0.000 internals.py:2204(<genexpr>)\n",
      "    99112    0.048    0.000    0.059    0.000 internals.py:2206(ndim)\n",
      "    70002    0.030    0.000    0.030    0.000 internals.py:2244(_is_single_block)\n",
      "     5822    0.171    0.000    0.367    0.000 internals.py:2256(_rebuild_blknos_and_blklocs)\n",
      "   116578    0.045    0.000    0.045    0.000 internals.py:227(dtype)\n",
      "    17892    0.005    0.000    0.005    0.000 internals.py:2277(_get_items)\n",
      "    23288    0.025    0.000    0.032    0.000 internals.py:231(ftype)\n",
      "     5822    0.036    0.000    0.127    0.000 internals.py:2382(_verify_integrity)\n",
      "    29110    0.017    0.000    0.026    0.000 internals.py:2384(<genexpr>)\n",
      "    17608    0.007    0.000    0.007    0.000 internals.py:2558(is_consolidated)\n",
      "     5822    0.027    0.000    0.060    0.000 internals.py:2566(_consolidate_check)\n",
      "     6035    0.008    0.000    0.008    0.000 internals.py:258(iget)\n",
      "    81788    0.057    0.000    0.078    0.000 internals.py:2819(consolidate)\n",
      "     5822    0.003    0.000    0.006    0.000 internals.py:2834(_consolidate_inplace)\n",
      "     6035    0.020    0.000    0.219    0.000 internals.py:2842(get)\n",
      "     6035    0.041    0.000    0.153    0.000 internals.py:2870(iget)\n",
      "    75824    0.380    0.000    6.525    0.000 internals.py:3122(reindex_indexer)\n",
      "    70002    0.368    0.000    3.910    0.000 internals.py:3168(_slice_take_blocks_ax0)\n",
      "    76037    0.235    0.000    0.343    0.000 internals.py:3331(__init__)\n",
      "    76392    0.029    0.000    0.029    0.000 internals.py:3378(_block)\n",
      "    76392    0.059    0.000    0.088    0.000 internals.py:3382(_values)\n",
      "    70002    0.024    0.000    0.024    0.000 internals.py:3432(index)\n",
      "    76392    0.087    0.000    0.228    0.000 internals.py:3465(values)\n",
      "    70002    0.016    0.000    0.016    0.000 internals.py:3481(is_consolidated)\n",
      "    70002    0.013    0.000    0.013    0.000 internals.py:3487(_consolidate_inplace)\n",
      "    70002    0.197    0.000    0.411    0.000 internals.py:4443(_preprocess_slice_or_indexer)\n",
      "    99325    0.263    0.000    0.536    0.000 internals.py:63(__init__)\n",
      "    93290    0.405    0.000    3.942    0.000 internals.py:838(take_nd)\n",
      "    93290    0.027    0.000    0.027    0.000 internals.py:867(get_values)\n",
      "    35001    0.040    0.000    0.040    0.000 numeric.py:1347(rollaxis)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:141(ones)\n",
      "    76960    0.051    0.000    0.086    0.000 numeric.py:1910(isscalar)\n",
      "   896257    0.634    0.000    2.587    0.000 numeric.py:394(asarray)\n",
      "    79160    0.077    0.000    0.178    0.000 numeric.py:464(asanyarray)\n",
      "    70002    0.030    0.000    0.056    0.000 numerictypes.py:668(issubclass_)\n",
      "    70002    0.089    0.000    0.161    0.000 numerictypes.py:736(issubdtype)\n",
      "    76037    0.441    0.000    1.628    0.000 series.py:114(__init__)\n",
      "    70002    0.019    0.000    0.019    0.000 series.py:2137(_needs_reindex_multi)\n",
      "    70002    0.234    0.000   17.383    0.000 series.py:2147(reindex)\n",
      "    70002    0.135    0.000   17.518    0.000 series.py:2151(reindex_axis)\n",
      "     6035    0.015    0.000    0.137    0.000 series.py:220(from_array)\n",
      "    70002    0.017    0.000    0.017    0.000 series.py:230(_constructor)\n",
      "    76037    0.321    0.000    0.927    0.000 series.py:245(_set_axis)\n",
      "    76037    0.093    0.000    0.093    0.000 series.py:265(_set_subtyp)\n",
      "    76392    0.067    0.000    0.295    0.000 series.py:296(values)\n",
      "     4614    0.012    0.000    0.065    0.000 shape_base.py:230(hstack)\n",
      "     9158    0.017    0.000    0.036    0.000 shape_base.py:8(atleast_1d)\n",
      "    70002    0.060    0.000    0.175    0.000 stats.py:212(_chk_asarray)\n",
      "    35001    0.787    0.000    5.806    0.000 stats.py:4149(kruskal)\n",
      "    35001    0.280    0.000    0.280    0.000 stats.py:4363(chisqprob)\n",
      "    70002    0.223    0.000    1.129    0.000 stats.py:4549(square_of_sums)\n",
      "    75966    0.023    0.000    0.046    0.000 {all}\n",
      "    82072    0.033    0.000    0.054    0.000 {any}\n",
      "   303793    0.120    0.000    0.120    0.000 {built-in method __new__ of type object at 0x10017ff20}\n",
      "     6390    0.001    0.000    0.001    0.000 {callable}\n",
      "      568    0.000    0.000    0.000    0.000 {function __getitem__ at 0x1085e7140}\n",
      "2144936/2074934    1.043    0.000    1.078    0.000 {getattr}\n",
      "  1104203    0.545    0.000    0.545    0.000 {hasattr}\n",
      "   152784    0.023    0.000    0.023    0.000 {hash}\n",
      "     6390    0.001    0.000    0.001    0.000 {id}\n",
      "  7819816    2.394    0.000    3.080    0.000 {isinstance}\n",
      "  2196699    0.528    0.000    0.528    0.000 {issubclass}\n",
      "    75043    0.025    0.000    0.025    0.000 {iter}\n",
      "1845346/1575842    0.505    0.000    0.635    0.000 {len}\n",
      "    70002    0.098    0.000    0.206    0.000 {map}\n",
      "     5963    0.005    0.000    0.043    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "    92579    0.092    0.000    0.870    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "    27050    0.007    0.000    0.007    0.000 {method 'append' of 'list' objects}\n",
      "    70570    0.197    0.000    0.197    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "    43023    0.782    0.000    1.257    0.000 {method 'choice' of 'mtrand.RandomState' objects}\n",
      "    35001    0.151    0.000    0.151    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "     5751    0.002    0.000    0.002    0.000 {method 'extend' of 'list' objects}\n",
      "    11644    0.010    0.000    0.010    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
      "  1774904    0.292    0.000    0.292    0.000 {method 'get' of 'dict' objects}\n",
      "    75824    0.566    0.000    0.566    0.000 {method 'get_indexer' of 'pandas.index.IndexEngine' objects}\n",
      "      568    0.010    0.000    0.010    0.000 {method 'get_labels' of 'pandas.hashtable.PyObjectHashTable' objects}\n",
      "    12070    0.016    0.000    0.016    0.000 {method 'get_loc' of 'pandas.index.IndexEngine' objects}\n",
      "    35001    0.012    0.000    0.012    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "    75824    0.031    0.000    0.031    0.000 {method 'items' of 'dict' objects}\n",
      "   303651    0.108    0.000    0.108    0.000 {method 'iteritems' of 'dict' objects}\n",
      "    75824    0.021    0.000    0.021    0.000 {method 'keys' of 'dict' objects}\n",
      "     5822    0.007    0.000    0.052    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
      "      781    0.001    0.000    0.001    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "      781    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "    43023    0.094    0.000    0.385    0.000 {method 'prod' of 'numpy.generic' objects}\n",
      "      568    0.001    0.000    0.001    0.000 {method 'put' of 'numpy.ndarray' objects}\n",
      "    35001    0.026    0.000    0.026    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "   252460    1.652    0.000    1.652    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     7952    0.005    0.000    0.005    0.000 {method 'remove' of 'list' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'round' of 'numpy.ndarray' objects}\n",
      "     1562    0.001    0.000    0.001    0.000 {method 'startswith' of 'str' objects}\n",
      "       70    0.000    0.000    0.001    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "     1136    0.002    0.000    0.002    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "      568    0.001    0.000    0.001    0.000 {method 'to_array' of 'pandas.hashtable.ObjectVector' objects}\n",
      "    75611    0.031    0.000    0.031    0.000 {method 'update' of 'dict' objects}\n",
      "   627395    0.425    0.000    0.425    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "       71    0.000    0.000    0.000    0.000 {method 'viewitems' of 'dict' objects}\n",
      "    70571    0.042    0.000    0.042    0.000 {min}\n",
      "    58857    0.156    0.000    0.156    0.000 {numpy.core.multiarray.arange}\n",
      "  1058835    2.195    0.000    2.195    0.000 {numpy.core.multiarray.array}\n",
      "    39615    0.157    0.000    0.157    0.000 {numpy.core.multiarray.concatenate}\n",
      "        1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.copyto}\n",
      "   141853    0.254    0.000    0.254    0.000 {numpy.core.multiarray.empty}\n",
      "      568    0.001    0.000    0.001    0.000 {numpy.core.multiarray.putmask}\n",
      "       71    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}\n",
      "   263540    0.044    0.000    0.044    0.000 {pandas.algos.ensure_int64}\n",
      "     1136    0.002    0.000    0.002    0.000 {pandas.algos.ensure_int8}\n",
      "    76463    0.018    0.000    0.018    0.000 {pandas.algos.ensure_object}\n",
      "    76392    0.020    0.000    0.020    0.000 {pandas.algos.ensure_platform_int}\n",
      "     5964    0.043    0.000    0.043    0.000 {pandas.algos.groupby_object}\n",
      "    70002    0.295    0.000    0.295    0.000 {pandas.algos.take_1d_float64_float64}\n",
      "      568    0.003    0.000    0.003    0.000 {pandas.algos.take_1d_object_object}\n",
      "     5822    0.049    0.000    0.049    0.000 {pandas.algos.take_2d_axis1_bool_bool}\n",
      "     5822    0.061    0.000    0.061    0.000 {pandas.algos.take_2d_axis1_float64_float64}\n",
      "     5822    0.043    0.000    0.043    0.000 {pandas.algos.take_2d_axis1_int64_int64}\n",
      "     5822    0.210    0.000    0.210    0.000 {pandas.algos.take_2d_axis1_object_object}\n",
      "     6035    0.004    0.000    0.004    0.000 {pandas.lib.checknull}\n",
      "     5822    0.134    0.000    0.134    0.000 {pandas.lib.clean_index_list}\n",
      "      142    0.005    0.000    0.005    0.000 {pandas.lib.fast_zip}\n",
      "   227046    1.755    0.000    1.755    0.000 {pandas.lib.infer_dtype}\n",
      "    75824    0.168    0.000    0.168    0.000 {pandas.lib.is_datetime_array}\n",
      "   163860    0.039    0.000    0.039    0.000 {pandas.lib.is_float}\n",
      "   227756    0.045    0.000    0.045    0.000 {pandas.lib.is_integer}\n",
      "       71    0.000    0.000    0.000    0.000 {pandas.lib.is_possible_datetimelike_array}\n",
      "      781    0.000    0.000    0.000    0.000 {pandas.lib.is_timedelta_array}\n",
      "    75043    0.640    0.000    0.640    0.000 {pandas.lib.ismember}\n",
      "     6035    0.002    0.000    0.002    0.000 {pandas.lib.isscalar}\n",
      "      781    0.005    0.000    0.005    0.000 {pandas.lib.list_to_object_array}\n",
      "      142    0.005    0.000    0.005    0.000 {pandas.lib.to_object_array_tuples}\n",
      "   169682    0.117    0.000    0.395    0.000 {pandas.lib.values_from_object}\n",
      "      781    0.002    0.000    0.002    0.000 {pandas.tslib.is_timestamp_array}\n",
      "    37490    0.036    0.000    0.036    0.000 {range}\n",
      "    35001    0.644    0.000    1.162    0.000 {scipy.stats._rank.rankdata}\n",
      "    35001    0.370    0.000    0.519    0.000 {scipy.stats._rank.tiecorrect}\n",
      "    75966    0.144    0.000    0.144    0.000 {sorted}\n",
      "     5822    0.007    0.000    0.033    0.000 {sum}\n",
      "      142    0.011    0.000    0.011    0.000 {zip}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@do_cprofile\n",
    "def calc_new_etoh_pwr():\n",
    "    pwr_etoh_220, cnts_etoh_220 = subsample_paired_power(test_alpha,\n",
    "                                                         map_,\n",
    "                                                         'ALCOHOL_FREQUENCY',\n",
    "                                                         ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                         ['Never', 'Daily'],\n",
    "                                                         num_iter=500,\n",
    "                                                         counts_interval=2,\n",
    "                                                         min_observations=15,\n",
    "                                                         max_counts=16)\n",
    "    return 'Etanol Power!'\n",
    "results_new = calc_new_etoh_pwr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for some reason, I find this output entirely uninteligable. I can try the line profiler, which will be substantially slower than the results I see here, but will probably better indicate where I'm having an issue, and how it can be solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from line_profiler import LineProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from line_profiler import LineProfiler\n",
    "\n",
    "    def do_profile(follow=[]):\n",
    "        def inner(func):\n",
    "            def profiled_func(*args, **kwargs):\n",
    "                try:\n",
    "                    profiler = LineProfiler()\n",
    "                    profiler.add_function(func)\n",
    "                    for f in follow:\n",
    "                        profiler.add_function(f)\n",
    "                    profiler.enable_by_count()\n",
    "                    return func(*args, **kwargs)\n",
    "                finally:\n",
    "                    profiler.print_stats()\n",
    "            return profiled_func\n",
    "        return inner\n",
    "\n",
    "except ImportError:\n",
    "    def do_profile():\n",
    "        \"Helpful if you accidentally leave in production!\"\n",
    "        def inner(func):\n",
    "            def nothing(*args, **kwargs):\n",
    "                return func(*args, **kwargs)\n",
    "            return nothing\n",
    "        return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 64.1193 s\n",
      "File: /Users/jwdebelius/.virtualenvs/playground/lib/python2.7/site-packages/skbio/stats/power.py\n",
      "Function: subsample_paired_power at line 328\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   328                                           def subsample_paired_power(test, meta, cat, control_cats, order=None,\n",
      "   329                                                                      strict_match=True, alpha_pwr=0.05,\n",
      "   330                                                                      min_observations=20, max_counts=50,\n",
      "   331                                                                      counts_interval=10, min_counts=None,\n",
      "   332                                                                      num_iter=500, num_runs=10):\n",
      "   333                                               r\"\"\"Estimates power iteratively using samples with matching metadata\n",
      "   334                                           \n",
      "   335                                               Parameters\n",
      "   336                                               ----------\n",
      "   337                                               test : function\n",
      "   338                                                   The statistical test which accepts a list of arrays sample ids and\n",
      "   339                                                   returns a p value.\n",
      "   340                                               meta : pandas.DataFrame\n",
      "   341                                                   The metadata associated with the samples.\n",
      "   342                                               cat : str\n",
      "   343                                                   The metadata category being varied between samples.\n",
      "   344                                               control_cats : list\n",
      "   345                                                   The metadata categories to be used as controls. For example, if\n",
      "   346                                                   you wanted to vary age (`cat` = \"AGE\"), you might want to control\n",
      "   347                                                   for gender and health status (i.e. `control_cats` = [\"SEX\",\n",
      "   348                                                   \"HEALTHY\"]).\n",
      "   349                                               order : list, optional\n",
      "   350                                                   The order of groups in the category. This can be used\n",
      "   351                                                   to limit the groups selected. For example, if there's a category with\n",
      "   352                                                   groups 'A', 'B' and 'C', and you only want to look at A vs B, `order`\n",
      "   353                                                   would be set to ['A', 'B'].\n",
      "   354                                               strict_match : bool, optional\n",
      "   355                                                   This determines how data is grouped using\n",
      "   356                                                   `control_cats`. If a sample within `meta` has an undefined value (NaN)\n",
      "   357                                                   for any of the columns in `control_cats`, the sample will not be\n",
      "   358                                                   considered as having a match and will be ignored when `strict_match`\n",
      "   359                                                   is True. If `strict_match` is False, missing values (NaN) in the\n",
      "   360                                                   `control_cats` can be considered matches.\n",
      "   361                                               alpha_pwr : float, optional\n",
      "   362                                                   The critical value used to calculate the power.\n",
      "   363                                               min_observations : unsigned int, optional\n",
      "   364                                                   The minimum number of paired samples which must exist\n",
      "   365                                                   for a category and set of control categories to be able to subsample\n",
      "   366                                                   and make power calculations. This is not the same as the minimum\n",
      "   367                                                   number of observations to draw during subsampling.\n",
      "   368                                               max_counts : unsigned int, optional\n",
      "   369                                                   The maximum number of observations per sample to draw\n",
      "   370                                                   for effect size calculation.\n",
      "   371                                               counts_interval : unsigned int, optional\n",
      "   372                                                   The difference between each subsampling count.\n",
      "   373                                               min_counts : unsigned int, optional\n",
      "   374                                                   How many samples should be drawn for the smallest\n",
      "   375                                                   subsample. If this is None, the `counts_interval` will be used.\n",
      "   376                                               num_iter : unsigned int, optional\n",
      "   377                                                   The number of p-values to generate for each point on the curve.\n",
      "   378                                               num_runs : unsigned int, optional\n",
      "   379                                                   The number of times to calculate each curve.\n",
      "   380                                           \n",
      "   381                                               Returns\n",
      "   382                                               -------\n",
      "   383                                               power : array\n",
      "   384                                                   The power calculated for each subsample at each count.\n",
      "   385                                               sample_counts : array\n",
      "   386                                                   The number of samples drawn at each power calculation.\n",
      "   387                                           \n",
      "   388                                               Raises\n",
      "   389                                               ------\n",
      "   390                                               ValueError\n",
      "   391                                                   There is a value error if there are fewer samples than the minimum\n",
      "   392                                                   count.\n",
      "   393                                               ValueError\n",
      "   394                                                   If the `counts_interval` is greater than the difference between the\n",
      "   395                                                   sample start and the max value, the function raises a ValueError.\n",
      "   396                                           \n",
      "   397                                               Examples\n",
      "   398                                               --------\n",
      "   399                                               Assume you are interested in the role of a specific cytokine of protein\n",
      "   400                                               translocation in myloid-lineage cells. You are able to culture two\n",
      "   401                                               macrophage lineages (bone marrow derived phagocytes and\n",
      "   402                                               peritoneally-derived macrophages). Due to unfortunate circumstances, your\n",
      "   403                                               growth media must be acquired from multiple sources (lab, company A,\n",
      "   404                                               company B). Also unfortunate, you must use labor-intense low throughput\n",
      "   405                                               assays. You have some preliminary measurements, and you'd like to\n",
      "   406                                               predict how many (more) cells you need to analyze for 80% power.\n",
      "   407                                           \n",
      "   408                                               You have information about 60 cells, which we'll simulate below. Note\n",
      "   409                                               that we are setting a random seed value for consistency.\n",
      "   410                                           \n",
      "   411                                               >>> import numpy as np\n",
      "   412                                               >>> import pandas as pd\n",
      "   413                                               >>> np.random.seed(25)\n",
      "   414                                               >>> data = pd.DataFrame.from_dict({\n",
      "   415                                               ...     'CELL_LINE': np.random.binomial(1, 0.5, size=(60,)),\n",
      "   416                                               ...     'SOURCE': np.random.binomial(2, 0.33, size=(60,)),\n",
      "   417                                               ...     'TREATMENT': np.hstack((np.zeros((30)), np.ones((30)))),\n",
      "   418                                               ...     'INCUBATOR': np.random.binomial(1, 0.2, size=(60,))})\n",
      "   419                                               >>> data['OUTCOME'] = (0.25 + data.TREATMENT * 0.25) + \\\n",
      "   420                                               ...     np.random.randn(60) * (0.1 + data.SOURCE/10 + data.CELL_LINE/5)\n",
      "   421                                               >>> data.loc[data.OUTCOME < 0, 'OUTCOME'] = 0\n",
      "   422                                               >>> data.loc[data.OUTCOME > 1, 'OUTCOME'] = 1\n",
      "   423                                           \n",
      "   424                                               We will approach this by assuming that the distribution of our outcome is\n",
      "   425                                               not normally distributed, and apply a kruskal-wallis test to compare\n",
      "   426                                               between the cytokine treated and untreated cells.\n",
      "   427                                           \n",
      "   428                                               >>> from scipy.stats import kruskal\n",
      "   429                                               >>> f = lambda x: kruskal(*[data.loc[i, 'OUTCOME'] for i in x])[1]\n",
      "   430                                           \n",
      "   431                                               Let's check that cytokine treatment has a signifigant effect across all\n",
      "   432                                               the cells.\n",
      "   433                                           \n",
      "   434                                               >>> treatment_stat = [g for g in data.groupby('TREATMENT').groups.values()]\n",
      "   435                                               >>> f(treatment_stat)\n",
      "   436                                               0.0019386336266250209\n",
      "   437                                           \n",
      "   438                                               Now, let's pick the control categories. It seems reasonable to assume there\n",
      "   439                                               may be an effect of cell line on the treatment outcome, which may be\n",
      "   440                                               attributed to differences in receptor expression. It may also be possible\n",
      "   441                                               that there are differences due cytokine source. Incubators were maintained\n",
      "   442                                               under the same conditions throughout the experiment, within one degree of\n",
      "   443                                               temperature difference at any given time, and the same level of CO2.\n",
      "   444                                               So, at least initially, let's ignore differences due to the incubator.\n",
      "   445                                           \n",
      "   446                                               It's recommended that as a first pass analysis, control variables be\n",
      "   447                                               selected based on an idea of what may be biologically relevant to the\n",
      "   448                                               system, although further iteration might encourage the consideration of\n",
      "   449                                               variable with effect sizes similar, or larger than the variable of\n",
      "   450                                               interest.\n",
      "   451                                           \n",
      "   452                                               >>> control_cats = ['SOURCE', 'CELL_LINE']\n",
      "   453                                               >>> from skbio.stats.power import subsample_paired_power\n",
      "   454                                               >>> pwr, cnt = subsample_paired_power(test=f,\n",
      "   455                                               ...                                   meta=data,\n",
      "   456                                               ...                                   cat='TREATMENT',\n",
      "   457                                               ...                                   control_cats=control_cats,\n",
      "   458                                               ...                                   min_observations=5,\n",
      "   459                                               ...                                   counts_interval=5,\n",
      "   460                                               ...                                   num_iter=100,\n",
      "   461                                               ...                                   num_runs=5)\n",
      "   462                                               >>> cnt\n",
      "   463                                               array([ 5, 10, 15, 20])\n",
      "   464                                               >>> pwr.mean(0)\n",
      "   465                                               array([ 0.15 ,  0.376,  0.614,  0.836])\n",
      "   466                                               >>> pwr.std(0).round(3)\n",
      "   467                                               array([ 0.046,  0.106,  0.176,  0.153])\n",
      "   468                                           \n",
      "   469                                               Estimating off the power curve, it looks like 20 cells per group may\n",
      "   470                                               provide addiquite power for this experiment, although the large variance\n",
      "   471                                               in power might suggest extending the curves or increasing the number of\n",
      "   472                                               samples per group.\n",
      "   473                                           \n",
      "   474                                               \"\"\"\n",
      "   475                                           \n",
      "   476                                               # Checks for the number of sampling pairs avaliable\n",
      "   477         1       134624 134624.0      0.2      sub_ids = paired_subsamples(meta, cat, control_cats, order, strict_match)\n",
      "   478                                           \n",
      "   479                                               # Determines the minimum number of ids avaliable\n",
      "   480         1            2      2.0      0.0      num_ids = len(sub_ids[0])\n",
      "   481                                           \n",
      "   482                                               # Checks there are enough samples to subsample\n",
      "   483         1            1      1.0      0.0      if num_ids <= min_observations:\n",
      "   484                                                   raise ValueError('There are not enough samples for subsampling.')\n",
      "   485                                           \n",
      "   486                                               # Calculates the effect size vector\n",
      "   487         1            1      1.0      0.0      if min_counts is None:\n",
      "   488         1            1      1.0      0.0          min_counts = counts_interval\n",
      "   489                                           \n",
      "   490         1            1      1.0      0.0      if (max_counts - min_counts) < counts_interval:\n",
      "   491                                                   raise ValueError(\"No subsamples of the specified size can be drawn.\")\n",
      "   492                                           \n",
      "   493         1            2      2.0      0.0      sample_counts = np.arange(min_counts,\n",
      "   494         1            3      3.0      0.0                                min(max_counts, num_ids),\n",
      "   495         1            8      8.0      0.0                                counts_interval)\n",
      "   496                                           \n",
      "   497                                               # Prealocates the power array\n",
      "   498         1            5      5.0      0.0      power = np.zeros((num_runs, len(sample_counts)))\n",
      "   499                                           \n",
      "   500         1            1      1.0      0.0      power[0, :] = _calculate_power_curve(test,\n",
      "   501         1            1      1.0      0.0                                           sub_ids,\n",
      "   502         1            1      1.0      0.0                                           sample_counts,\n",
      "   503         1            1      1.0      0.0                                           mode=\"matched\",\n",
      "   504         1            1      1.0      0.0                                           num_iter=num_iter,\n",
      "   505         1      5393962 5393962.0      8.4                                           alpha=alpha_pwr)\n",
      "   506                                           \n",
      "   507        10           21      2.1      0.0      for id1 in np.arange(1, num_runs):\n",
      "   508         9            8      0.9      0.0          sub_ids = paired_subsamples(meta, cat, control_cats, order,\n",
      "   509         9      1175590 130621.1      1.8                                      strict_match)\n",
      "   510                                                   # Calculates the power curve\n",
      "   511         9           28      3.1      0.0          power[id1, :] = _calculate_power_curve(test,\n",
      "   512         9            6      0.7      0.0                                                 sub_ids,\n",
      "   513         9           10      1.1      0.0                                                 sample_counts,\n",
      "   514         9            9      1.0      0.0                                                 num_iter=num_iter,\n",
      "   515         9            8      0.9      0.0                                                 alpha=alpha_pwr,\n",
      "   516         9     57415003 6379444.8     89.5                                                 mode=\"matched\")\n",
      "   517                                           \n",
      "   518         1            1      1.0      0.0      return power, sample_counts\n",
      "\n",
      "Total time: 1.28471 s\n",
      "File: /Users/jwdebelius/.virtualenvs/playground/lib/python2.7/site-packages/skbio/stats/power.py\n",
      "Function: paired_subsamples at line 666\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   666                                           def paired_subsamples(meta, cat, control_cats, order=None, strict_match=True):\n",
      "   667                                               r\"\"\"Gets a set of samples to serve as controls\n",
      "   668                                           \n",
      "   669                                               This function is designed to provide controlled samples, based on a\n",
      "   670                                               metadata category. For example, one could control for age, sex, education\n",
      "   671                                               level, and diet type while measuring exercise frequency. No outcome\n",
      "   672                                               value is considered in this subsampling process.\n",
      "   673                                           \n",
      "   674                                               Parameters\n",
      "   675                                               ----------\n",
      "   676                                               meta : pandas.DataFrame\n",
      "   677                                                   The metadata associated with the samples.\n",
      "   678                                               cat : str, list\n",
      "   679                                                   The metadata category (or a list of categories) for comparison.\n",
      "   680                                               control_cats : list\n",
      "   681                                                   The metadata categories to be used as controls. For example, if you\n",
      "   682                                                   wanted to vary age (`cat` = \"AGE\"), you might want to control for\n",
      "   683                                                   gender and health status (i.e. `control_cats` = [\"SEX\", \"HEALTHY\"])\n",
      "   684                                               order : list, optional\n",
      "   685                                                   The order of groups in the category. This can be used\n",
      "   686                                                   to limit the groups selected. For example, if there's a category with\n",
      "   687                                                   groups 'A', 'B' and 'C', and you only want to look at A vs B, `order`\n",
      "   688                                                   would be set to ['A', 'B'].\n",
      "   689                                               strict_match: bool, optional\n",
      "   690                                                   This determines how data is grouped using\n",
      "   691                                                   `control_cats`. If a sample within `meta` has an undefined value (NaN)\n",
      "   692                                                   for any of the columns in `control_cats`, the sample will not be\n",
      "   693                                                   considered as having a match and will be ignored when `strict_match`\n",
      "   694                                                   is True. If `strict_match` is False, missing values (NaN) in the\n",
      "   695                                                   `control_cats` can be considered matches.\n",
      "   696                                           \n",
      "   697                                               Returns\n",
      "   698                                               -------\n",
      "   699                                               ids : array\n",
      "   700                                                   a set of ids which satisfy the criteria. These are not grouped by\n",
      "   701                                                   `cat`. An empty array indicates there are no sample ids which satisfy\n",
      "   702                                                   the requirements.\n",
      "   703                                           \n",
      "   704                                               Examples\n",
      "   705                                               --------\n",
      "   706                                               If we have a mapping file for a set of random individuals looking at\n",
      "   707                                               housing, sex, age and antibiotic use.\n",
      "   708                                           \n",
      "   709                                               >>> import pandas as pd\n",
      "   710                                               >>> import numpy as np\n",
      "   711                                               >>> meta = {'SW': {'HOUSING': '2', 'SEX': 'M', 'AGE': np.nan, 'ABX': 'Y'},\n",
      "   712                                               ...         'TS': {'HOUSING': '2', 'SEX': 'M', 'AGE': '40s', 'ABX': 'Y'},\n",
      "   713                                               ...         'CB': {'HOUSING': '3', 'SEX': 'M', 'AGE': '40s', 'ABX': 'Y'},\n",
      "   714                                               ...         'BB': {'HOUSING': '1', 'SEX': 'M', 'AGE': '40s', 'ABX': 'Y'}}\n",
      "   715                                               >>> meta = pd.DataFrame.from_dict(meta, orient=\"index\")\n",
      "   716                                               >>> meta #doctest: +SKIP\n",
      "   717                                                  ABX HOUSING  AGE SEX\n",
      "   718                                               BB   Y       1  40s   M\n",
      "   719                                               CB   Y       3  40s   M\n",
      "   720                                               SW   Y       2  NaN   M\n",
      "   721                                               TS   Y       2  40s   M\n",
      "   722                                           \n",
      "   723                                               We may want to vary an individual's housing situation, while holding\n",
      "   724                                               constant their age, sex and antibiotic use so we can estimate the effect\n",
      "   725                                               size for housing, and later compare it to the effects of other variables.\n",
      "   726                                           \n",
      "   727                                               >>> from skbio.stats.power import paired_subsamples\n",
      "   728                                               >>> ids = paired_subsamples(meta, 'HOUSING', ['SEX', 'AGE', 'ABX'])\n",
      "   729                                               >>> np.hstack(ids) #doctest: +ELLIPSIS\n",
      "   730                                               array(['BB', 'TS', 'CB']...\n",
      "   731                                           \n",
      "   732                                               So, for this set of data, we can match TS, CB, and BB based on their age,\n",
      "   733                                               sex, and antibiotic use. SW cannot be matched in either group becuase\n",
      "   734                                               `strict_match` was true, and there is missing AGE data for this sample.\n",
      "   735                                           \n",
      "   736                                               \"\"\"\n",
      "   737                                           \n",
      "   738                                               # Sets the index data\n",
      "   739                                               # Groups meta by category\n",
      "   740        10         2754    275.4      0.2      cat_groups = meta.groupby(cat).groups\n",
      "   741                                           \n",
      "   742                                               # Handles the order argument\n",
      "   743        10           12      1.2      0.0      if order is None:\n",
      "   744                                                   order = sorted(cat_groups.keys())\n",
      "   745        10           81      8.1      0.0      order = np.array(order)\n",
      "   746        10           12      1.2      0.0      num_groups = len(order)\n",
      "   747                                           \n",
      "   748                                               # Determines the number of samples, and the experimental and control group\n",
      "   749        30          115      3.8      0.0      group_size = np.array([len(cat_groups[o]) for o in order])\n",
      "   750        10          315     31.5      0.0      ctrl_name = order[group_size == group_size.min()][0]\n",
      "   751        10          108     10.8      0.0      order = order[order != ctrl_name]\n",
      "   752                                           \n",
      "   753                                               # Gets a control group table\n",
      "   754        10        34912   3491.2      2.7      ctrl_match_groups = meta.groupby(control_cats).groups\n",
      "   755        10        16522   1652.2      1.3      ctrl_group = meta.loc[cat_groups[ctrl_name]\n",
      "   756        10        23756   2375.6      1.8                            ].groupby(list(control_cats)).groups\n",
      "   757                                           \n",
      "   758        10           87      8.7      0.0      ids = [np.array([])] * num_groups\n",
      "   759                                               # Loops through samples in the experimental group to match for controls\n",
      "   760       840         1166      1.4      0.1      for check_group, ctrl_ids in viewitems(ctrl_group):\n",
      "   761                                                   # Checks the categories have been defined\n",
      "   762      4150        17788      4.3      1.4          undefed_check = np.array([_check_strs(p) for p in check_group])\n",
      "   763       830         8116      9.8      0.6          if not undefed_check.all() and strict_match:\n",
      "   764        20           22      1.1      0.0              continue\n",
      "   765                                                   # Removes the matched ids from order\n",
      "   766       810         1481      1.8      0.1          matched_ids = ctrl_match_groups[check_group]\n",
      "   767      1930         1935      1.0      0.2          for id_ in ctrl_ids:\n",
      "   768      1120         2052      1.8      0.2              matched_ids.remove(id_)\n",
      "   769       810          772      1.0      0.1          pos_ids = []\n",
      "   770       810         1192      1.5      0.1          num_ids = [len(ctrl_ids)]\n",
      "   771                                                   # Gets the matrix of the matched ids and groups them\n",
      "   772       810      1083847   1338.1     84.4          exp_group = meta.loc[matched_ids].groupby(cat).groups\n",
      "   773      1130         3986      3.5      0.3          for grp in order:\n",
      "   774                                                       # Checks group to be considered is included in the grouping\n",
      "   775       810          998      1.2      0.1              if grp not in exp_group:\n",
      "   776       490          468      1.0      0.0                  break\n",
      "   777                                                       # Gets the id associated with the group\n",
      "   778       320          538      1.7      0.0              pos_ids.append(exp_group[grp])\n",
      "   779       320          711      2.2      0.1              num_ids.append(len(exp_group[grp]))\n",
      "   780                                                   # Determines the minimum number of samples\n",
      "   781       810        13949     17.2      1.1          num_draw = np.array(num_ids).min()\n",
      "   782                                                   # Draws samples from possible ids\n",
      "   783       810        31347     38.7      2.4          exp_ids = [np.random.choice(ctrl_ids, num_draw, replace=False)]\n",
      "   784       810         1164      1.4      0.1          exp_ids.extend([np.random.choice(id_, num_draw, replace=False)\n",
      "   785      1130         9334      8.3      0.7                          for id_ in pos_ids])\n",
      "   786                                           \n",
      "   787       810         1029      1.3      0.1          if len(exp_ids) == num_groups:\n",
      "   788       960        10485     10.9      0.8              for idx in range(num_groups):\n",
      "   789       640        13650     21.3      1.1                  ids[idx] = np.hstack((ids[idx], exp_ids[idx]))\n",
      "   790                                           \n",
      "   791        10            9      0.9      0.0      return ids\n",
      "\n",
      "Total time: 0.004246 s\n",
      "File: /Users/jwdebelius/.virtualenvs/playground/lib/python2.7/site-packages/skbio/stats/power.py\n",
      "Function: _check_strs at line 794\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   794                                           def _check_strs(x):\n",
      "   795                                               r\"\"\"Returns False if x is a nan and True is x is a string or number\"\"\"\n",
      "   796                                           \n",
      "   797      3320         2334      0.7     55.0      if isinstance(x, str):\n",
      "   798      3300         1748      0.5     41.2          return True\n",
      "   799        20           20      1.0      0.5      elif isinstance(x, (float, int)):\n",
      "   800        20          144      7.2      3.4          return not np.isnan(x)\n",
      "   801                                               else:\n",
      "   802                                                   raise TypeError('input must be a string, float or a nan')\n",
      "\n",
      "Total time: 0.002024 s\n",
      "File: /Users/jwdebelius/.virtualenvs/playground/lib/python2.7/site-packages/skbio/stats/power.py\n",
      "Function: _calculate_power at line 805\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   805                                           def _calculate_power(p_values, alpha=0.05):\n",
      "   806                                               r\"\"\"Calculates statical power empirically\n",
      "   807                                           \n",
      "   808                                               Parameters\n",
      "   809                                               ----------\n",
      "   810                                               p_values : 1-D array\n",
      "   811                                                   A 1-D numpy array with the test results.\n",
      "   812                                           \n",
      "   813                                               alpha : float\n",
      "   814                                                   The critical value for the power calculation.\n",
      "   815                                           \n",
      "   816                                               Returns\n",
      "   817                                               -------\n",
      "   818                                               power : float\n",
      "   819                                                   The emperical power, or the fraction of observed p values below the\n",
      "   820                                                   critical value.\n",
      "   821                                           \n",
      "   822                                               \"\"\"\n",
      "   823                                           \n",
      "   824        70         1980     28.3     97.8      w = (p_values < float(alpha)).sum()/float(p_values.shape[0])\n",
      "   825                                           \n",
      "   826        70           44      0.6      2.2      return w\n",
      "\n",
      "Total time: 62.5166 s\n",
      "File: /Users/jwdebelius/.virtualenvs/playground/lib/python2.7/site-packages/skbio/stats/power.py\n",
      "Function: _compare_distributions at line 829\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   829                                           def _compare_distributions(test, samples, counts=5, mode=\"ind\", num_iter=1000):\n",
      "   830                                               r\"\"\"Compares two distribution arrays iteratively\n",
      "   831                                           \n",
      "   832                                               Parameters\n",
      "   833                                               ----------\n",
      "   834                                               test : function\n",
      "   835                                                   The statistical test which accepts an array_like of sample ids\n",
      "   836                                                   (list of lists) and returns a p-value.\n",
      "   837                                               samples : list of arrays\n",
      "   838                                                   A list where each 1-d array represents a sample. If `mode` is\n",
      "   839                                                   \"matched\", there must be an equal number of observations in each\n",
      "   840                                                   sample.\n",
      "   841                                               counts : unsigned int or 1-D array, optional\n",
      "   842                                                   The number of samples to draw from each distribution.\n",
      "   843                                                   If this is a 1-D array, the length must correspond to the number of\n",
      "   844                                                   samples. The function will not draw more observations than are in a\n",
      "   845                                                   sample. In \"matched\" `mode`, the same number of observations will be\n",
      "   846                                                   drawn from each group.\n",
      "   847                                               mode : {\"ind\", \"matched\"}, optional\n",
      "   848                                                   \"matched\" samples should be used when observations in\n",
      "   849                                                   samples have corresponding observations in other groups. For instance,\n",
      "   850                                                   this may be useful when working with regression data where\n",
      "   851                                                   :math:`x_{1}, x_{2}, ..., x_{n}` maps to :math:`y_{1}, y_{2}, ... ,\n",
      "   852                                                   y_{n}`.\n",
      "   853                                               num_iter : int, optional\n",
      "   854                                                   Default 1000. The number of p-values to generate for each point on the\n",
      "   855                                                   curve.\n",
      "   856                                           \n",
      "   857                                               Returns\n",
      "   858                                               -------\n",
      "   859                                               p_values : array\n",
      "   860                                                   The p-values for `n_iter` subsampled tests.\n",
      "   861                                           \n",
      "   862                                               Raises\n",
      "   863                                               ------\n",
      "   864                                               ValueError\n",
      "   865                                                   If mode is not \"ind\" or \"matched\".\n",
      "   866                                               ValueError\n",
      "   867                                                   If the arrays in samples are not the same length in \"matched\" mode.\n",
      "   868                                               ValueError\n",
      "   869                                                   If counts is a 1-D array and counts and samples are different lengths.\n",
      "   870                                           \n",
      "   871                                               \"\"\"\n",
      "   872                                           \n",
      "   873                                               # Determines the number of groups\n",
      "   874        70           89      1.3      0.0      num_groups = len(samples)\n",
      "   875                                           \n",
      "   876                                               # Checks the mode\n",
      "   877        70          132      1.9      0.0      if mode not in {'ind', 'matched'}:\n",
      "   878                                                   raise ValueError('Supported sample modes are \"ind\" and \"matched\".')\n",
      "   879                                           \n",
      "   880                                               # Handles the number of samples for later instances\n",
      "   881        70          121      1.7      0.0      if isinstance(counts, int):\n",
      "   882                                                   counts = np.array([counts] * num_groups)\n",
      "   883                                           \n",
      "   884        70           66      0.9      0.0      if not len(counts) == num_groups:\n",
      "   885                                                   raise ValueError('If counts is a 1-D array, there must be a count to'\n",
      "   886                                                                    ' draw for each group.')\n",
      "   887                                           \n",
      "   888                                               # Checks the group length\n",
      "   889       210          226      1.1      0.0      samp_lens = [len(sample) for sample in samples]\n",
      "   890                                               # Checks the group length\n",
      "   891        70           84      1.2      0.0      if mode == 'matched' and np.array([samp_lens[i] != samp_lens[i+1] for i in\n",
      "   892       140         3149     22.5      0.0                                         range(num_groups-1)]).all():\n",
      "   893                                                   raise ValueError('In \"matched\" mode, each sample must have the same'\n",
      "   894                                                                    ' number of observations.')\n",
      "   895       210         2447     11.7      0.0      if np.array([samp_lens[i] < counts[i] for i in range(num_groups)]).any():\n",
      "   896                                                   raise ValueError('You cannot choose more observations that exist '\n",
      "   897                                                                    'in a sample.')\n",
      "   898                                           \n",
      "   899                                               # Prealocates the pvalue matrix\n",
      "   900        70          366      5.2      0.0      p_values = np.zeros((num_iter))\n",
      "   901                                           \n",
      "   902     35070       210213      6.0      0.3      for idx in range(num_iter):\n",
      "   903     35000        38484      1.1      0.1          if mode == \"matched\":\n",
      "   904     35000       204789      5.9      0.3              pos = np.random.choice(np.arange(0, samp_lens[0]), counts[0],\n",
      "   905     35000      1228567     35.1      2.0                                     replace=False)\n",
      "   906    105000       198359      1.9      0.3              subs = [sample[pos] for sample in samples]\n",
      "   907                                                   else:\n",
      "   908                                                       subs = [np.random.choice(np.array(pop), counts[i], replace=False)\n",
      "   909                                                               for i, pop in enumerate(samples)]\n",
      "   910                                           \n",
      "   911     35000     60629495   1732.3     97.0          p_values[idx] = test(subs)\n",
      "   912                                           \n",
      "   913        70           59      0.8      0.0      return p_values\n",
      "\n",
      "Total time: 64.1195 s\n",
      "File: <ipython-input-26-bd523165e7f4>\n",
      "Function: calc_new_etoh_pwr at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@do_profile(follow=[skbio.stats.power._compare_distributions, skbio.stats.power.paired_subsamples, skbio.stats.power._check_strs, skbio.stats.power.subsample_paired_power, skbio.stats.power._calculate_power])\n",
    "def calc_new_etoh_pwr():\n",
    "    pwr_etoh_220, cnts_etoh_220 = skbio.stats.power.subsample_paired_power(test_alpha,\n",
    "                                                                           map_,\n",
    "                                                                           'ALCOHOL_FREQUENCY',\n",
    "                                                                           ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                                           ['Never', 'Daily'],\n",
    "                                                                           num_iter=500,\n",
    "                                                                           counts_interval=2,\n",
    "                                                                           min_observations=15,\n",
    "                                                                           max_counts=16)\n",
    "results = calc_new_etoh_pwr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 62.1717 s\n",
      "File: <ipython-input-29-ea3fa562006d>\n",
      "Function: subsample_paired_power at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def subsample_paired_power(test, meta, cat, control_cats, order=None,\n",
      "     2                                                                      strict_match=True, alpha_pwr=0.05, ratio=None,\n",
      "     3                                                                      min_observations=20, max_counts=50,\n",
      "     4                                                                      counts_interval=10, min_counts=None,\n",
      "     5                                                                      num_iter=500, num_runs=10):\n",
      "     6                                               r\"\"\"Estimates power iteratively using samples with matching metadata\"\"\"\n",
      "     7                                           \n",
      "     8                                               # Checks for the number of sampling pairs avaliable\n",
      "     9         1       125444 125444.0      0.2      sub_ids = paired_subsamples(meta, cat, control_cats, order, strict_match)\n",
      "    10                                           \n",
      "    11                                               # Determines the minimum number of ids avaliable\n",
      "    12         1            3      3.0      0.0      num_ids = len(sub_ids[0])\n",
      "    13                                           \n",
      "    14                                               # Checks there are enough samples to subsample\n",
      "    15         1            1      1.0      0.0      if num_ids <= min_observations:\n",
      "    16                                                   raise ValueError('There are not enough samples for subsampling.')\n",
      "    17                                           \n",
      "    18                                               # Checks the ratio\n",
      "    19         1            1      1.0      0.0      num_groups = len(sub_ids)\n",
      "    20         1            1      1.0      0.0      if ratio is None:\n",
      "    21         1           18     18.0      0.0          ratio = np.ones((num_groups))\n",
      "    22         1            5      5.0      0.0      ratio = np.asarray(ratio)\n",
      "    23         1            1      1.0      0.0      if not ratio.shape == (num_groups,):\n",
      "    24                                                   raise ValueError('There must be a ratio for each group.')\n",
      "    25                                           \n",
      "    26                                               # Determines the number of p values returned by the test\n",
      "    27         1         3689   3689.0      0.0      p_return = test(sub_ids)\n",
      "    28         1            6      6.0      0.0      if isinstance(p_return, float):\n",
      "    29         1            1      1.0      0.0          num_p = 1\n",
      "    30                                               elif isinstance(p_return, np.ndarray) and len(p_return.shape) == 1:\n",
      "    31                                                   num_p = p_return.shape[0]\n",
      "    32                                               else:\n",
      "    33                                                   raise TypeError('test must return a float or one-dimensional array.')\n",
      "    34                                           \n",
      "    35                                               # Calculates the effect size vector\n",
      "    36         1            1      1.0      0.0      if min_counts is None:\n",
      "    37         1            1      1.0      0.0          min_counts = counts_interval\n",
      "    38                                           \n",
      "    39         1            1      1.0      0.0      if (max_counts - min_counts) < counts_interval:\n",
      "    40                                                   raise ValueError(\"No subsamples of the specified size can be drawn.\")\n",
      "    41                                           \n",
      "    42         1            2      2.0      0.0      sample_counts = np.arange(min_counts,\n",
      "    43         1            4      4.0      0.0                                min(max_counts, num_ids),\n",
      "    44         1           14     14.0      0.0                                counts_interval)\n",
      "    45                                           \n",
      "    46                                               # Prealocates the power array\n",
      "    47         1            7      7.0      0.0      power = np.zeros((num_runs, len(sample_counts), num_p))\n",
      "    48                                           \n",
      "    49                                               # Calculates power instances\n",
      "    50         8           20      2.5      0.0      for id2, c in enumerate(sample_counts):\n",
      "    51         7          120     17.1      0.0          count = np.round(c * ratio, 0).astype(int)\n",
      "    52        77          129      1.7      0.0          for id1 in range(num_runs):\n",
      "    53        70           89      1.3      0.0              sub_ids = paired_subsamples(meta, cat, control_cats, order,\n",
      "    54        70      7362298 105175.7     11.8                                          strict_match)\n",
      "    55        70           98      1.4      0.0              ps = _compare_distributions(test=test,\n",
      "    56        70           64      0.9      0.0                                          samples=sub_ids,\n",
      "    57        70           58      0.8      0.0                                          num_p=num_p,\n",
      "    58        70           63      0.9      0.0                                          counts=count,\n",
      "    59        70           64      0.9      0.0                                          num_iter=num_iter,\n",
      "    60        70     54675960 781085.1     87.9                                          mode=\"matched\")\n",
      "    61        70         3491     49.9      0.0              power[id1, id2, :] = _calculate_power(ps, alpha_pwr)\n",
      "    62                                           \n",
      "    63         1            1      1.0      0.0      if num_p == 1:\n",
      "    64         1            2      2.0      0.0          power = power[:, :, 0]\n",
      "    65                                           \n",
      "    66         1            1      1.0      0.0      return power, sample_counts\n",
      "\n",
      "Total time: 54.4233 s\n",
      "File: <ipython-input-29-ea3fa562006d>\n",
      "Function: _compare_distributions at line 69\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    69                                           def _compare_distributions(test, samples, num_p, counts=5, mode=\"ind\",\n",
      "    70                                                                      num_iter=1000):\n",
      "    71                                               r\"\"\"Compares two distribution arrays iteratively\"\"\"\n",
      "    72                                           \n",
      "    73                                               # Determines the number of groups\n",
      "    74        70           68      1.0      0.0      num_groups = len(samples)\n",
      "    75                                           \n",
      "    76                                               # Checks the mode\n",
      "    77        70           94      1.3      0.0      if mode not in {'ind', 'matched'}:\n",
      "    78                                                   raise ValueError('Supported sample modes are \"ind\" and \"matched\".')\n",
      "    79                                           \n",
      "    80                                               # Handles the number of samples for later instances\n",
      "    81        70          131      1.9      0.0      if isinstance(counts, int):\n",
      "    82                                                   counts = np.array([counts] * num_groups)\n",
      "    83                                           \n",
      "    84        70           69      1.0      0.0      if not len(counts) == num_groups:\n",
      "    85                                                   raise ValueError('If counts is a 1-D array, there must be a count to'\n",
      "    86                                                                    ' draw for each group.')\n",
      "    87                                           \n",
      "    88                                               # Checks the group length\n",
      "    89       210          195      0.9      0.0      samp_lens = [len(sample) for sample in samples]\n",
      "    90                                               # Checks the group length\n",
      "    91        70           72      1.0      0.0      if mode == 'matched' and np.array([samp_lens[i] != samp_lens[i+1] for i in\n",
      "    92       140         1013      7.2      0.0                                         range(num_groups-1)]).all():\n",
      "    93                                                   raise ValueError('In \"matched\" mode, each sample must have the same'\n",
      "    94                                                                    ' number of observations.')\n",
      "    95       210          907      4.3      0.0      if np.array([samp_lens[i] < counts[i] for i in range(num_groups)]).any():\n",
      "    96                                                   raise ValueError('You cannot choose more observations that exist '\n",
      "    97                                                                    'in a sample.')\n",
      "    98                                           \n",
      "    99                                               # Prealocates the pvalue matrix\n",
      "   100        70          261      3.7      0.0      p_values = np.zeros((num_p, num_iter))\n",
      "   101                                           \n",
      "   102     35070        49321      1.4      0.1      for idx in range(num_iter):\n",
      "   103     35000        31386      0.9      0.1          if mode == \"matched\":\n",
      "   104     35000       161506      4.6      0.3              pos = np.random.choice(np.arange(0, samp_lens[0]), counts[0],\n",
      "   105     35000      1038469     29.7      1.9                                     replace=False)\n",
      "   106    105000       171183      1.6      0.3              subs = [sample[pos] for sample in samples]\n",
      "   107                                                   else:\n",
      "   108                                                       subs = [np.random.choice(np.array(pop), counts[i], replace=False)\n",
      "   109                                                               for i, pop in enumerate(samples)]\n",
      "   110                                           \n",
      "   111     35000     52967010   1513.3     97.3          p_values[:, idx] = test(subs)\n",
      "   112                                           \n",
      "   113        70           61      0.9      0.0      if num_p == 1:\n",
      "   114        70         1477     21.1      0.0          p_values = np.hstack(p_values)\n",
      "   115                                           \n",
      "   116        70           65      0.9      0.0      return p_values\n",
      "\n",
      "Total time: 0.002831 s\n",
      "File: <ipython-input-29-ea3fa562006d>\n",
      "Function: _calculate_power at line 118\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   118                                           def _calculate_power(p_values, alpha=0.05):\n",
      "   119                                               r\"\"\"Calculates statical power empirically\"\"\"\n",
      "   120                                           \n",
      "   121        70           80      1.1      2.8      if len(p_values.shape) == 1:\n",
      "   122        70         1074     15.3     37.9          p_values = p_values * np.array([[1]])\n",
      "   123                                           \n",
      "   124        70         1627     23.2     57.5      w = (p_values < float(alpha)).sum(1)/float(p_values.shape[1])\n",
      "   125                                           \n",
      "   126        70           50      0.7      1.8      return w\n",
      "\n",
      "Total time: 7.34681 s\n",
      "File: <ipython-input-29-ea3fa562006d>\n",
      "Function: paired_subsamples at line 128\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   128                                           def paired_subsamples(meta, cat, control_cats, order=None, strict_match=True):\n",
      "   129                                               r\"\"\"Gets a set of samples to serve as controls\n",
      "   130                                               \"\"\"\n",
      "   131                                           \n",
      "   132                                               # Sets the index data\n",
      "   133                                               # Groups meta by category\n",
      "   134        71        17174    241.9      0.2      cat_groups = meta.groupby(cat).groups\n",
      "   135                                           \n",
      "   136                                               # Handles the order argument\n",
      "   137        71           84      1.2      0.0      if order is None:\n",
      "   138                                                   order = sorted(cat_groups.keys())\n",
      "   139        71          405      5.7      0.0      order = np.array(order)\n",
      "   140        71           80      1.1      0.0      num_groups = len(order)\n",
      "   141                                           \n",
      "   142                                               # Determines the number of samples, and the experimental and control group\n",
      "   143       213          688      3.2      0.0      group_size = np.array([len(cat_groups[o]) for o in order])\n",
      "   144        71         1631     23.0      0.0      ctrl_name = order[group_size == group_size.min()][0]\n",
      "   145        71          716     10.1      0.0      order = order[order != ctrl_name]\n",
      "   146                                           \n",
      "   147                                               # Gets a control group table\n",
      "   148        71       183810   2588.9      2.5      ctrl_match_groups = meta.groupby(control_cats).groups\n",
      "   149        71        87659   1234.6      1.2      ctrl_group = meta.loc[cat_groups[ctrl_name]\n",
      "   150        71       144226   2031.4      2.0                            ].groupby(list(control_cats)).groups\n",
      "   151                                           \n",
      "   152        71          429      6.0      0.0      ids = [np.array([])] * num_groups\n",
      "   153                                               # Loops through samples in the experimental group to match for controls\n",
      "   154      5964         5982      1.0      0.1      for check_group, ctrl_ids in viewitems(ctrl_group):\n",
      "   155                                                   # Checks the categories have been defined\n",
      "   156     29465        63113      2.1      0.9          undefed_check = np.array([_check_strs(p) for p in check_group])\n",
      "   157      5893        46656      7.9      0.6          if not undefed_check.all() and strict_match:\n",
      "   158       142          116      0.8      0.0              continue\n",
      "   159                                                   # Removes the matched ids from order\n",
      "   160      5751         8225      1.4      0.1          matched_ids = ctrl_match_groups[check_group]\n",
      "   161     13703        12146      0.9      0.2          for id_ in ctrl_ids:\n",
      "   162      7952        11164      1.4      0.2              matched_ids.remove(id_)\n",
      "   163      5751         4992      0.9      0.1          pos_ids = []\n",
      "   164      5751         7132      1.2      0.1          num_ids = [len(ctrl_ids)]\n",
      "   165                                                   # Gets the matrix of the matched ids and groups them\n",
      "   166      5751      6315867   1098.2     86.0          exp_group = meta.loc[matched_ids].groupby(cat).groups\n",
      "   167      8023        20269      2.5      0.3          for grp in order:\n",
      "   168                                                       # Checks group to be considered is included in the grouping\n",
      "   169      5751         6051      1.1      0.1              if grp not in exp_group:\n",
      "   170      3479         2981      0.9      0.0                  break\n",
      "   171                                                       # Gets the id associated with the group\n",
      "   172      2272         3337      1.5      0.0              pos_ids.append(exp_group[grp])\n",
      "   173      2272         3881      1.7      0.1              num_ids.append(len(exp_group[grp]))\n",
      "   174                                                   # Determines the minimum number of samples\n",
      "   175      5751        72201     12.6      1.0          num_draw = np.array(num_ids).min()\n",
      "   176                                                   # Draws samples from possible ids\n",
      "   177      5751       164111     28.5      2.2          exp_ids = [np.random.choice(ctrl_ids, num_draw, replace=False)]\n",
      "   178      5751         7241      1.3      0.1          exp_ids.extend([np.random.choice(id_, num_draw, replace=False)\n",
      "   179      8023        58450      7.3      0.8                          for id_ in pos_ids])\n",
      "   180                                           \n",
      "   181      5751         6528      1.1      0.1          if len(exp_ids) == num_groups:\n",
      "   182      6816         9169      1.3      0.1              for idx in range(num_groups):\n",
      "   183      4544        80243     17.7      1.1                  ids[idx] = np.hstack((ids[idx], exp_ids[idx]))\n",
      "   184                                           \n",
      "   185        71           52      0.7      0.0      return ids\n",
      "\n",
      "Total time: 62.1727 s\n",
      "File: <ipython-input-30-c00093c344a6>\n",
      "Function: calc_new_etoh_pwr at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           @do_profile(follow=[_compare_distributions, paired_subsamples, subsample_paired_power, _calculate_power])\n",
      "     2                                           def calc_new_etoh_pwr():\n",
      "     3         1            2      2.0      0.0      pwr_etoh_220, cnts_etoh_220 = subsample_paired_power(test_alpha,\n",
      "     4         1            0      0.0      0.0                                                           map_,\n",
      "     5         1            1      1.0      0.0                                                           'ALCOHOL_FREQUENCY',\n",
      "     6         1            0      0.0      0.0                                                           ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
      "     7         1            1      1.0      0.0                                                           ['Never', 'Daily'],\n",
      "     8         1            1      1.0      0.0                                                           num_iter=500,\n",
      "     9         1            0      0.0      0.0                                                           counts_interval=2,\n",
      "    10         1            0      0.0      0.0                                                           min_observations=15,\n",
      "    11         1     62172667 62172667.0    100.0                                                           max_counts=16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@do_profile(follow=[_compare_distributions, paired_subsamples, subsample_paired_power, _calculate_power])\n",
    "def calc_new_etoh_pwr():\n",
    "    pwr_etoh_220, cnts_etoh_220 = subsample_paired_power(test_alpha,\n",
    "                                                         map_,\n",
    "                                                         'ALCOHOL_FREQUENCY',\n",
    "                                                         ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                         ['Never', 'Daily'],\n",
    "                                                         num_iter=500,\n",
    "                                                         counts_interval=2,\n",
    "                                                         min_observations=15,\n",
    "                                                         max_counts=16)\n",
    "results = calc_new_etoh_pwr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what I'm reading, the expensive step is the test function (which I can't really make that much faster) and grouping my data in pandas (which I again, can't really make faster). So, I think if I parallelize... or Josh parallelizes the test function, it would make it faster. We cna try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def subsample_paired_power_pool(test, meta, cat, control_cats, order=None,\n",
    "                                strict_match=True, alpha_pwr=0.05, ratio=None,\n",
    "                                min_observations=20, max_counts=50,\n",
    "                                counts_interval=10, min_counts=None,\n",
    "                                num_iter=500, num_runs=10, num_cpus=1):\n",
    "    r\"\"\"Estimates power iteratively using samples with matching metadata\"\"\"\n",
    "\n",
    "    # Checks for the number of sampling pairs avaliable\n",
    "    sub_ids = paired_subsamples(meta, cat, control_cats, order, strict_match)\n",
    "\n",
    "    # Determines the minimum number of ids avaliable\n",
    "    num_ids = len(sub_ids[0])\n",
    "\n",
    "    # Checks there are enough samples to subsample\n",
    "    if num_ids <= min_observations:\n",
    "        raise ValueError('There are not enough samples for subsampling.')\n",
    "\n",
    "    # Checks the ratio\n",
    "    num_groups = len(sub_ids)\n",
    "    if ratio is None:\n",
    "        ratio = np.ones((num_groups))\n",
    "    ratio = np.asarray(ratio)\n",
    "    if not ratio.shape == (num_groups,):\n",
    "        raise ValueError('There must be a ratio for each group.')\n",
    "\n",
    "    # Determines the number of p values returned by the test\n",
    "    p_return = test(sub_ids)\n",
    "    if isinstance(p_return, float):\n",
    "        num_p = 1\n",
    "    elif isinstance(p_return, np.ndarray) and len(p_return.shape) == 1:\n",
    "        num_p = p_return.shape[0]\n",
    "    else:\n",
    "        raise TypeError('test must return a float or one-dimensional array.')\n",
    "\n",
    "    # Calculates the effect size vector\n",
    "    if min_counts is None:\n",
    "        min_counts = counts_interval\n",
    "\n",
    "    if (max_counts - min_counts) < counts_interval:\n",
    "        raise ValueError(\"No subsamples of the specified size can be drawn.\")\n",
    "\n",
    "    sample_counts = np.arange(min_counts,\n",
    "                              min(max_counts, num_ids),\n",
    "                              counts_interval)\n",
    "\n",
    "    # Prealocates the power array\n",
    "    power = np.zeros((num_runs, len(sample_counts), num_p))\n",
    "\n",
    "    # Calculates power instances\n",
    "    # We're going to attempt multithreading to speed this up. So, we'll make a pool object\n",
    "    for id2, c in enumerate(sample_counts):\n",
    "        count = np.round(c * ratio, 0).astype(int)\n",
    "        for id1 in range(num_runs):\n",
    "            sub_ids = paired_subsamples(meta, cat, control_cats, order,\n",
    "                                        strict_match)\n",
    "            ps = _compare_distributions_pool(test=test,\n",
    "                                             samples=sub_ids,\n",
    "                                             num_p=num_p,\n",
    "                                             counts=count,\n",
    "                                             num_iter=num_iter,\n",
    "                                             mode=\"matched\",\n",
    "                                             num_cpus=num_cpus)\n",
    "            power[id1, id2, :] = _calculate_power(ps, alpha_pwr)\n",
    "\n",
    "    if num_p == 1:\n",
    "        power = power[:, :, 0]\n",
    "\n",
    "    return power, sample_counts\n",
    "\n",
    "def _compare_distributions_pool(test, samples, num_p, counts=5, mode=\"ind\",\n",
    "                                num_iter=1000, num_cpus=1):\n",
    "    r\"\"\"Compares two distribution arrays iteratively\"\"\"\n",
    "\n",
    "    # Determines the number of groups\n",
    "    num_groups = len(samples)\n",
    "\n",
    "#     # Checks the mode\n",
    "#     if mode not in {'ind', 'matched'}:\n",
    "#         raise ValueError('Supported sample modes are \"ind\" and \"matched\".')\n",
    "\n",
    "    # Handles the number of samples for later instances\n",
    "    if isinstance(counts, int):\n",
    "        counts = np.array([counts] * num_groups)\n",
    "\n",
    "#     if not len(counts) == num_groups:\n",
    "#         raise ValueError('If counts is a 1-D array, there must be a count to'\n",
    "#                          ' draw for each group.')\n",
    "\n",
    "    # Checks the group length\n",
    "    samp_lens = [len(sample) for sample in samples]\n",
    "#     # Checks the group length\n",
    "#     if mode == 'matched' and np.array([samp_lens[i] != samp_lens[i+1] for i in\n",
    "#                                        range(num_groups-1)]).all():\n",
    "#         raise ValueError('In \"matched\" mode, each sample must have the same'\n",
    "#                          ' number of observations.')\n",
    "#     if np.array([samp_lens[i] < counts[i] for i in range(num_groups)]).any():\n",
    "#         raise ValueError('You cannot choose more observations that exist '\n",
    "#                          'in a sample.')\n",
    "\n",
    "    # Prealocates the pvalue matrix\n",
    "    p_values = []\n",
    "\n",
    "    swimmingly = Pool(num_cpus)\n",
    "    for idx in range(num_iter):\n",
    "        if mode == \"matched\":\n",
    "            pos = np.random.choice(np.arange(0, samp_lens[0]), counts[0],\n",
    "                                   replace=False)\n",
    "            subs = [sample[pos] for sample in samples]\n",
    "        else:\n",
    "            subs = [np.random.choice(np.array(pop), counts[i], replace=False)\n",
    "                    for i, pop in enumerate(samples)]\n",
    "\n",
    "        swimmingly.apply_async(test, [subs], callback=p_values.append)\n",
    "    \n",
    "    swimmingly.close()\n",
    "    swimmingly.join()\n",
    "    \n",
    "    p_values = np.asarray(p_values)\n",
    "\n",
    "    if num_p == 1:\n",
    "        p_values = np.hstack(p_values)\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@do_profile(follow=[power._compare_distributions, power.paired_subsamples, power._check_strs, power.subsample_paired_power_pool])\n",
    "def calc_new_etoh_pwr_pool():\n",
    "    pwr_etoh_220, cnts_etoh_220 = subsample_paired_power_pool(test_alpha,\n",
    "                                                              map_,\n",
    "                                                             'ALCOHOL_FREQUENCY',\n",
    "                                                             ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                             ['Never', 'Daily'],\n",
    "                                                             num_iter=500,\n",
    "                                                             counts_interval=2,\n",
    "                                                             min_observations=15,\n",
    "                                                             max_counts=16,\n",
    "                                                             num_cpus=4)\n",
    "results = calc_new_etoh_pwr_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 33.1467 s\n",
      "File: <ipython-input-22-4c7d0132ab82>\n",
      "Function: subsample_paired_power_pool at line 3\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     3                                           def subsample_paired_power_pool(test, meta, cat, control_cats, order=None,\n",
      "     4                                                                           strict_match=True, alpha_pwr=0.05, ratio=None,\n",
      "     5                                                                           min_observations=20, max_counts=50,\n",
      "     6                                                                           counts_interval=10, min_counts=None,\n",
      "     7                                                                           num_iter=500, num_runs=10, num_cpus=1):\n",
      "     8                                               r\"\"\"Estimates power iteratively using samples with matching metadata\"\"\"\n",
      "     9                                           \n",
      "    10                                               # Checks for the number of sampling pairs avaliable\n",
      "    11         1       125333 125333.0      0.4      sub_ids = paired_subsamples(meta, cat, control_cats, order, strict_match)\n",
      "    12                                           \n",
      "    13                                               # Determines the minimum number of ids avaliable\n",
      "    14         1            2      2.0      0.0      num_ids = len(sub_ids[0])\n",
      "    15                                           \n",
      "    16                                               # Checks there are enough samples to subsample\n",
      "    17         1            1      1.0      0.0      if num_ids <= min_observations:\n",
      "    18                                                   raise ValueError('There are not enough samples for subsampling.')\n",
      "    19                                           \n",
      "    20                                               # Checks the ratio\n",
      "    21         1            1      1.0      0.0      num_groups = len(sub_ids)\n",
      "    22         1            1      1.0      0.0      if ratio is None:\n",
      "    23         1           11     11.0      0.0          ratio = np.ones((num_groups))\n",
      "    24         1            3      3.0      0.0      ratio = np.asarray(ratio)\n",
      "    25         1            1      1.0      0.0      if not ratio.shape == (num_groups,):\n",
      "    26                                                   raise ValueError('There must be a ratio for each group.')\n",
      "    27                                           \n",
      "    28                                               # Determines the number of p values returned by the test\n",
      "    29         1         1698   1698.0      0.0      p_return = test(sub_ids)\n",
      "    30         1            2      2.0      0.0      if isinstance(p_return, float):\n",
      "    31         1            1      1.0      0.0          num_p = 1\n",
      "    32                                               elif isinstance(p_return, np.ndarray) and len(p_return.shape) == 1:\n",
      "    33                                                   num_p = p_return.shape[0]\n",
      "    34                                               else:\n",
      "    35                                                   raise TypeError('test must return a float or one-dimensional array.')\n",
      "    36                                           \n",
      "    37                                               # Calculates the effect size vector\n",
      "    38         1            1      1.0      0.0      if min_counts is None:\n",
      "    39         1            1      1.0      0.0          min_counts = counts_interval\n",
      "    40                                           \n",
      "    41         1            1      1.0      0.0      if (max_counts - min_counts) < counts_interval:\n",
      "    42                                                   raise ValueError(\"No subsamples of the specified size can be drawn.\")\n",
      "    43                                           \n",
      "    44         1            1      1.0      0.0      sample_counts = np.arange(min_counts,\n",
      "    45         1            2      2.0      0.0                                min(max_counts, num_ids),\n",
      "    46         1            5      5.0      0.0                                counts_interval)\n",
      "    47                                           \n",
      "    48                                               # Prealocates the power array\n",
      "    49         1            4      4.0      0.0      power = np.zeros((num_runs, len(sample_counts), num_p))\n",
      "    50                                           \n",
      "    51                                               # Calculates power instances\n",
      "    52                                               # We're going to attempt multithreading to speed this up. So, we'll make a pool object\n",
      "    53         8           31      3.9      0.0      for id2, c in enumerate(sample_counts):\n",
      "    54         7          756    108.0      0.0          count = np.round(c * ratio, 0).astype(int)\n",
      "    55        77          194      2.5      0.0          for id1 in range(num_runs):\n",
      "    56        70         2362     33.7      0.0              sub_ids = paired_subsamples(meta, cat, control_cats, order,\n",
      "    57        70      8147887 116398.4     24.6                                          strict_match)\n",
      "    58        70          102      1.5      0.0              ps = _compare_distributions_pool(test=test,\n",
      "    59        70           62      0.9      0.0                                               samples=sub_ids,\n",
      "    60        70           60      0.9      0.0                                               num_p=num_p,\n",
      "    61        70           66      0.9      0.0                                               counts=count,\n",
      "    62        70           69      1.0      0.0                                               num_iter=num_iter,\n",
      "    63        70           66      0.9      0.0                                               mode=\"matched\",\n",
      "    64        70     24849301 354990.0     75.0                                               num_cpus=num_cpus)\n",
      "    65        70        18653    266.5      0.1              power[id1, id2, :] = _calculate_power(ps, alpha_pwr)\n",
      "    66                                           \n",
      "    67         1            1      1.0      0.0      if num_p == 1:\n",
      "    68         1            2      2.0      0.0          power = power[:, :, 0]\n",
      "    69                                           \n",
      "    70         1            1      1.0      0.0      return power, sample_counts\n",
      "\n",
      "Total time: 24.3687 s\n",
      "File: <ipython-input-22-4c7d0132ab82>\n",
      "Function: _compare_distributions_pool at line 72\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    72                                           def _compare_distributions_pool(test, samples, num_p, counts=5, mode=\"ind\",\n",
      "    73                                                                           num_iter=1000, num_cpus=1):\n",
      "    74                                               r\"\"\"Compares two distribution arrays iteratively\"\"\"\n",
      "    75                                           \n",
      "    76                                               # Determines the number of groups\n",
      "    77        70           83      1.2      0.0      num_groups = len(samples)\n",
      "    78                                           \n",
      "    79                                               # Checks the mode\n",
      "    80        70          111      1.6      0.0      if mode not in {'ind', 'matched'}:\n",
      "    81                                                   raise ValueError('Supported sample modes are \"ind\" and \"matched\".')\n",
      "    82                                           \n",
      "    83                                               # Handles the number of samples for later instances\n",
      "    84        70          132      1.9      0.0      if isinstance(counts, int):\n",
      "    85                                                   counts = np.array([counts] * num_groups)\n",
      "    86                                           \n",
      "    87        70           70      1.0      0.0      if not len(counts) == num_groups:\n",
      "    88                                                   raise ValueError('If counts is a 1-D array, there must be a count to'\n",
      "    89                                                                    ' draw for each group.')\n",
      "    90                                           \n",
      "    91                                               # Checks the group length\n",
      "    92       210          220      1.0      0.0      samp_lens = [len(sample) for sample in samples]\n",
      "    93                                               # Checks the group length\n",
      "    94        70           80      1.1      0.0      if mode == 'matched' and np.array([samp_lens[i] != samp_lens[i+1] for i in\n",
      "    95       140         1183      8.4      0.0                                         range(num_groups-1)]).all():\n",
      "    96                                                   raise ValueError('In \"matched\" mode, each sample must have the same'\n",
      "    97                                                                    ' number of observations.')\n",
      "    98       210          980      4.7      0.0      if np.array([samp_lens[i] < counts[i] for i in range(num_groups)]).any():\n",
      "    99                                                   raise ValueError('You cannot choose more observations that exist '\n",
      "   100                                                                    'in a sample.')\n",
      "   101                                           \n",
      "   102                                               # Prealocates the pvalue matrix\n",
      "   103        70           67      1.0      0.0      p_values = []\n",
      "   104                                           \n",
      "   105        70       734031  10486.2      3.0      swimmingly = Pool(num_cpus)\n",
      "   106     35070        85859      2.4      0.4      for idx in range(num_iter):\n",
      "   107     35000        52395      1.5      0.2          if mode == \"matched\":\n",
      "   108     35000       474623     13.6      1.9              pos = np.random.choice(np.arange(0, samp_lens[0]), counts[0],\n",
      "   109     35000      2006543     57.3      8.2                                     replace=False)\n",
      "   110    105000       339943      3.2      1.4              subs = [sample[pos] for sample in samples]\n",
      "   111                                                   else:\n",
      "   112                                                       subs = [np.random.choice(np.array(pop), counts[i], replace=False)\n",
      "   113                                                               for i, pop in enumerate(samples)]\n",
      "   114                                           \n",
      "   115     35000      5935581    169.6     24.4          swimmingly.apply_async(test, [subs], callback=p_values.append)\n",
      "   116                                               \n",
      "   117        70          630      9.0      0.0      swimmingly.close()\n",
      "   118        70     14322982 204614.0     58.8      swimmingly.join()\n",
      "   119                                               \n",
      "   120        70        32868    469.5      0.1      p_values = np.asarray(p_values)\n",
      "   121                                           \n",
      "   122        70          141      2.0      0.0      if num_p == 1:\n",
      "   123        70       380084   5429.8      1.6          p_values = np.hstack(p_values)\n",
      "   124                                           \n",
      "   125        70          120      1.7      0.0      return p_values\n",
      "\n",
      "Total time: 33.148 s\n",
      "File: <ipython-input-23-85142949a53c>\n",
      "Function: calc_new_etoh_pwr_pool at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           @do_profile(follow=[_compare_distributions_pool, paired_subsamples, _check_strs, subsample_paired_power_pool])\n",
      "     2                                           def calc_new_etoh_pwr_pool():\n",
      "     3         1            2      2.0      0.0      pwr_etoh_220, cnts_etoh_220 = subsample_paired_power_pool(test_alpha,\n",
      "     4         1            1      1.0      0.0                                                                map_,\n",
      "     5         1            0      0.0      0.0                                                               'ALCOHOL_FREQUENCY',\n",
      "     6         1            0      0.0      0.0                                                               ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
      "     7         1            1      1.0      0.0                                                               ['Never', 'Daily'],\n",
      "     8         1            1      1.0      0.0                                                               num_iter=500,\n",
      "     9         1            0      0.0      0.0                                                               counts_interval=2,\n",
      "    10         1            0      0.0      0.0                                                               min_observations=15,\n",
      "    11         1            1      1.0      0.0                                                               max_counts=16,\n",
      "    12         1     33147952 33147952.0    100.0                                                               num_cpus=4)\n",
      "\n",
      "Total time: 8.12646 s\n",
      "File: <ipython-input-3-ea3fa562006d>\n",
      "Function: paired_subsamples at line 128\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   128                                           def paired_subsamples(meta, cat, control_cats, order=None, strict_match=True):\n",
      "   129                                               r\"\"\"Gets a set of samples to serve as controls\n",
      "   130                                               \"\"\"\n",
      "   131                                           \n",
      "   132                                               # Sets the index data\n",
      "   133                                               # Groups meta by category\n",
      "   134        71       109356   1540.2      1.3      cat_groups = meta.groupby(cat).groups\n",
      "   135                                           \n",
      "   136                                               # Handles the order argument\n",
      "   137        71          118      1.7      0.0      if order is None:\n",
      "   138                                                   order = sorted(cat_groups.keys())\n",
      "   139        71         1046     14.7      0.0      order = np.array(order)\n",
      "   140        71          104      1.5      0.0      num_groups = len(order)\n",
      "   141                                           \n",
      "   142                                               # Determines the number of samples, and the experimental and control group\n",
      "   143       213         1419      6.7      0.0      group_size = np.array([len(cat_groups[o]) for o in order])\n",
      "   144        71         8087    113.9      0.1      ctrl_name = order[group_size == group_size.min()][0]\n",
      "   145        71         2019     28.4      0.0      order = order[order != ctrl_name]\n",
      "   146                                           \n",
      "   147                                               # Gets a control group table\n",
      "   148        71       241759   3405.1      3.0      ctrl_match_groups = meta.groupby(control_cats).groups\n",
      "   149        71       128956   1816.3      1.6      ctrl_group = meta.loc[cat_groups[ctrl_name]\n",
      "   150        71       166870   2350.3      2.1                            ].groupby(list(control_cats)).groups\n",
      "   151                                           \n",
      "   152        71          481      6.8      0.0      ids = [np.array([])] * num_groups\n",
      "   153                                               # Loops through samples in the experimental group to match for controls\n",
      "   154      5964         7970      1.3      0.1      for check_group, ctrl_ids in viewitems(ctrl_group):\n",
      "   155                                                   # Checks the categories have been defined\n",
      "   156     29465       116133      3.9      1.4          undefed_check = np.array([_check_strs(p) for p in check_group])\n",
      "   157      5893        51430      8.7      0.6          if not undefed_check.all() and strict_match:\n",
      "   158       142          144      1.0      0.0              continue\n",
      "   159                                                   # Removes the matched ids from order\n",
      "   160      5751         8804      1.5      0.1          matched_ids = ctrl_match_groups[check_group]\n",
      "   161     13703        12819      0.9      0.2          for id_ in ctrl_ids:\n",
      "   162      7952        12786      1.6      0.2              matched_ids.remove(id_)\n",
      "   163      5751         5157      0.9      0.1          pos_ids = []\n",
      "   164      5751         7817      1.4      0.1          num_ids = [len(ctrl_ids)]\n",
      "   165                                                   # Gets the matrix of the matched ids and groups them\n",
      "   166      5751      6770481   1177.3     83.3          exp_group = meta.loc[matched_ids].groupby(cat).groups\n",
      "   167      8023        21924      2.7      0.3          for grp in order:\n",
      "   168                                                       # Checks group to be considered is included in the grouping\n",
      "   169      5751         6373      1.1      0.1              if grp not in exp_group:\n",
      "   170      3479         2962      0.9      0.0                  break\n",
      "   171                                                       # Gets the id associated with the group\n",
      "   172      2272         3481      1.5      0.0              pos_ids.append(exp_group[grp])\n",
      "   173      2272         4180      1.8      0.1              num_ids.append(len(exp_group[grp]))\n",
      "   174                                                   # Determines the minimum number of samples\n",
      "   175      5751        76445     13.3      0.9          num_draw = np.array(num_ids).min()\n",
      "   176                                                   # Draws samples from possible ids\n",
      "   177      5751       177487     30.9      2.2          exp_ids = [np.random.choice(ctrl_ids, num_draw, replace=False)]\n",
      "   178      5751         7872      1.4      0.1          exp_ids.extend([np.random.choice(id_, num_draw, replace=False)\n",
      "   179      8023        64060      8.0      0.8                          for id_ in pos_ids])\n",
      "   180                                           \n",
      "   181      5751         6711      1.2      0.1          if len(exp_ids) == num_groups:\n",
      "   182      6816         9989      1.5      0.1              for idx in range(num_groups):\n",
      "   183      4544        91166     20.1      1.1                  ids[idx] = np.hstack((ids[idx], exp_ids[idx]))\n",
      "   184                                           \n",
      "   185        71           54      0.8      0.0      return ids\n",
      "\n",
      "Total time: 0.030312 s\n",
      "File: <ipython-input-3-ea3fa562006d>\n",
      "Function: _check_strs at line 187\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   187                                           def _check_strs(x):\n",
      "   188                                               r\"\"\"Returns False if x is a nan and True is x is a string or number\"\"\"\n",
      "   189                                           \n",
      "   190     23572        17526      0.7     57.8      if isinstance(x, str):\n",
      "   191     23430        11887      0.5     39.2          return True\n",
      "   192       142          133      0.9      0.4      elif isinstance(x, (float, int)):\n",
      "   193       142          766      5.4      2.5          return not np.isnan(x)\n",
      "   194                                               else:\n",
      "   195                                                   raise TypeError('input must be a string, float or a nan')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@do_profile(follow=[_compare_distributions_pool, paired_subsamples, _check_strs, subsample_paired_power_pool])\n",
    "def calc_new_etoh_pwr_pool():\n",
    "    pwr_etoh_220, cnts_etoh_220 = subsample_paired_power_pool(test_alpha,\n",
    "                                                              map_,\n",
    "                                                             'ALCOHOL_FREQUENCY',\n",
    "                                                             ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                             ['Never', 'Daily'],\n",
    "                                                             num_iter=500,\n",
    "                                                             counts_interval=2,\n",
    "                                                             min_observations=15,\n",
    "                                                             max_counts=16,\n",
    "                                                             num_cpus=4)\n",
    "results = calc_new_etoh_pwr_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 32.4868 s\n",
      "File: <ipython-input-24-254036a3f1df>\n",
      "Function: subsample_paired_power_pool at line 3\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     3                                           def subsample_paired_power_pool(test, meta, cat, control_cats, order=None,\n",
      "     4                                                                           strict_match=True, alpha_pwr=0.05, ratio=None,\n",
      "     5                                                                           min_observations=20, max_counts=50,\n",
      "     6                                                                           counts_interval=10, min_counts=None,\n",
      "     7                                                                           num_iter=500, num_runs=10, num_cpus=1):\n",
      "     8                                               r\"\"\"Estimates power iteratively using samples with matching metadata\"\"\"\n",
      "     9                                           \n",
      "    10                                               # Checks for the number of sampling pairs avaliable\n",
      "    11         1       122484 122484.0      0.4      sub_ids = paired_subsamples(meta, cat, control_cats, order, strict_match)\n",
      "    12                                           \n",
      "    13                                               # Determines the minimum number of ids avaliable\n",
      "    14         1            1      1.0      0.0      num_ids = len(sub_ids[0])\n",
      "    15                                           \n",
      "    16                                               # Checks there are enough samples to subsample\n",
      "    17         1            1      1.0      0.0      if num_ids <= min_observations:\n",
      "    18                                                   raise ValueError('There are not enough samples for subsampling.')\n",
      "    19                                           \n",
      "    20                                               # Checks the ratio\n",
      "    21         1            1      1.0      0.0      num_groups = len(sub_ids)\n",
      "    22         1            1      1.0      0.0      if ratio is None:\n",
      "    23         1           23     23.0      0.0          ratio = np.ones((num_groups))\n",
      "    24         1            3      3.0      0.0      ratio = np.asarray(ratio)\n",
      "    25         1            2      2.0      0.0      if not ratio.shape == (num_groups,):\n",
      "    26                                                   raise ValueError('There must be a ratio for each group.')\n",
      "    27                                           \n",
      "    28                                               # Determines the number of p values returned by the test\n",
      "    29         1         1886   1886.0      0.0      p_return = test(sub_ids)\n",
      "    30         1            3      3.0      0.0      if isinstance(p_return, float):\n",
      "    31         1            1      1.0      0.0          num_p = 1\n",
      "    32                                               elif isinstance(p_return, np.ndarray) and len(p_return.shape) == 1:\n",
      "    33                                                   num_p = p_return.shape[0]\n",
      "    34                                               else:\n",
      "    35                                                   raise TypeError('test must return a float or one-dimensional array.')\n",
      "    36                                           \n",
      "    37                                               # Calculates the effect size vector\n",
      "    38         1            1      1.0      0.0      if min_counts is None:\n",
      "    39         1            1      1.0      0.0          min_counts = counts_interval\n",
      "    40                                           \n",
      "    41         1            1      1.0      0.0      if (max_counts - min_counts) < counts_interval:\n",
      "    42                                                   raise ValueError(\"No subsamples of the specified size can be drawn.\")\n",
      "    43                                           \n",
      "    44         1            1      1.0      0.0      sample_counts = np.arange(min_counts,\n",
      "    45         1            1      1.0      0.0                                min(max_counts, num_ids),\n",
      "    46         1            4      4.0      0.0                                counts_interval)\n",
      "    47                                           \n",
      "    48                                               # Prealocates the power array\n",
      "    49         1            5      5.0      0.0      power = np.zeros((num_runs, len(sample_counts), num_p))\n",
      "    50                                           \n",
      "    51                                               # Calculates power instances\n",
      "    52                                               # We're going to attempt multithreading to speed this up. So, we'll make a pool object\n",
      "    53         8           33      4.1      0.0      for id2, c in enumerate(sample_counts):\n",
      "    54         7          345     49.3      0.0          count = np.round(c * ratio, 0).astype(int)\n",
      "    55        77         1185     15.4      0.0          for id1 in range(num_runs):\n",
      "    56        70         1499     21.4      0.0              sub_ids = paired_subsamples(meta, cat, control_cats, order,\n",
      "    57        70      8131379 116162.6     25.0                                          strict_match)\n",
      "    58        70          111      1.6      0.0              ps = _compare_distributions_pool(test=test,\n",
      "    59        70           64      0.9      0.0                                               samples=sub_ids,\n",
      "    60        70           74      1.1      0.0                                               num_p=num_p,\n",
      "    61        70           72      1.0      0.0                                               counts=count,\n",
      "    62        70           66      0.9      0.0                                               num_iter=num_iter,\n",
      "    63        70           64      0.9      0.0                                               mode=\"matched\",\n",
      "    64        70     24211670 345881.0     74.5                                               num_cpus=num_cpus)\n",
      "    65        70        15819    226.0      0.0              power[id1, id2, :] = _calculate_power(ps, alpha_pwr)\n",
      "    66                                           \n",
      "    67         1            2      2.0      0.0      if num_p == 1:\n",
      "    68         1            2      2.0      0.0          power = power[:, :, 0]\n",
      "    69                                           \n",
      "    70         1            1      1.0      0.0      return power, sample_counts\n",
      "\n",
      "Total time: 23.764 s\n",
      "File: <ipython-input-24-254036a3f1df>\n",
      "Function: _compare_distributions_pool at line 72\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    72                                           def _compare_distributions_pool(test, samples, num_p, counts=5, mode=\"ind\",\n",
      "    73                                                                           num_iter=1000, num_cpus=1):\n",
      "    74                                               r\"\"\"Compares two distribution arrays iteratively\"\"\"\n",
      "    75                                           \n",
      "    76                                               # Determines the number of groups\n",
      "    77        70           67      1.0      0.0      num_groups = len(samples)\n",
      "    78                                           \n",
      "    79                                           #     # Checks the mode\n",
      "    80                                           #     if mode not in {'ind', 'matched'}:\n",
      "    81                                           #         raise ValueError('Supported sample modes are \"ind\" and \"matched\".')\n",
      "    82                                           \n",
      "    83                                               # Handles the number of samples for later instances\n",
      "    84        70          137      2.0      0.0      if isinstance(counts, int):\n",
      "    85                                                   counts = np.array([counts] * num_groups)\n",
      "    86                                           \n",
      "    87                                           #     if not len(counts) == num_groups:\n",
      "    88                                           #         raise ValueError('If counts is a 1-D array, there must be a count to'\n",
      "    89                                           #                          ' draw for each group.')\n",
      "    90                                           \n",
      "    91                                               # Checks the group length\n",
      "    92       210          232      1.1      0.0      samp_lens = [len(sample) for sample in samples]\n",
      "    93                                           #     # Checks the group length\n",
      "    94                                           #     if mode == 'matched' and np.array([samp_lens[i] != samp_lens[i+1] for i in\n",
      "    95                                           #                                        range(num_groups-1)]).all():\n",
      "    96                                           #         raise ValueError('In \"matched\" mode, each sample must have the same'\n",
      "    97                                           #                          ' number of observations.')\n",
      "    98                                           #     if np.array([samp_lens[i] < counts[i] for i in range(num_groups)]).any():\n",
      "    99                                           #         raise ValueError('You cannot choose more observations that exist '\n",
      "   100                                           #                          'in a sample.')\n",
      "   101                                           \n",
      "   102                                               # Prealocates the pvalue matrix\n",
      "   103        70           49      0.7      0.0      p_values = []\n",
      "   104                                           \n",
      "   105        70       731138  10444.8      3.1      swimmingly = Pool(num_cpus)\n",
      "   106     35070        78849      2.2      0.3      for idx in range(num_iter):\n",
      "   107     35000        47842      1.4      0.2          if mode == \"matched\":\n",
      "   108     35000       493296     14.1      2.1              pos = np.random.choice(np.arange(0, samp_lens[0]), counts[0],\n",
      "   109     35000      2031599     58.0      8.5                                     replace=False)\n",
      "   110    105000       320879      3.1      1.4              subs = [sample[pos] for sample in samples]\n",
      "   111                                                   else:\n",
      "   112                                                       subs = [np.random.choice(np.array(pop), counts[i], replace=False)\n",
      "   113                                                               for i, pop in enumerate(samples)]\n",
      "   114                                           \n",
      "   115     35000      5856365    167.3     24.6          swimmingly.apply_async(test, [subs], callback=p_values.append)\n",
      "   116                                               \n",
      "   117        70          615      8.8      0.0      swimmingly.close()\n",
      "   118        70     13771913 196741.6     58.0      swimmingly.join()\n",
      "   119                                               \n",
      "   120        70        40092    572.7      0.2      p_values = np.asarray(p_values)\n",
      "   121                                           \n",
      "   122        70          152      2.2      0.0      if num_p == 1:\n",
      "   123        70       390632   5580.5      1.6          p_values = np.hstack(p_values)\n",
      "   124                                           \n",
      "   125        70          115      1.6      0.0      return p_values\n",
      "\n",
      "Total time: 32.488 s\n",
      "File: <ipython-input-25-32f9e5f3871f>\n",
      "Function: calc_new_etoh_pwr_pool at line 3\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     3                                           @do_profile(follow=[_compare_distributions_pool, paired_subsamples, _check_strs, subsample_paired_power_pool])\n",
      "     4                                           def calc_new_etoh_pwr_pool():\n",
      "     5         1            2      2.0      0.0      pwr_etoh_220, cnts_etoh_220 = subsample_paired_power_pool(test_alpha,\n",
      "     6         1            1      1.0      0.0                                                                map_,\n",
      "     7         1            0      0.0      0.0                                                               'ALCOHOL_FREQUENCY',\n",
      "     8         1            1      1.0      0.0                                                               ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
      "     9         1            1      1.0      0.0                                                               ['Never', 'Daily'],\n",
      "    10         1            0      0.0      0.0                                                               num_iter=500,\n",
      "    11         1            1      1.0      0.0                                                               counts_interval=2,\n",
      "    12         1            1      1.0      0.0                                                               min_observations=15,\n",
      "    13         1            1      1.0      0.0                                                               max_counts=16,\n",
      "    14         1     32488007 32488007.0    100.0                                                               num_cpus=4)\n",
      "\n",
      "Total time: 8.10681 s\n",
      "File: <ipython-input-3-ea3fa562006d>\n",
      "Function: paired_subsamples at line 128\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   128                                           def paired_subsamples(meta, cat, control_cats, order=None, strict_match=True):\n",
      "   129                                               r\"\"\"Gets a set of samples to serve as controls\n",
      "   130                                               \"\"\"\n",
      "   131                                           \n",
      "   132                                               # Sets the index data\n",
      "   133                                               # Groups meta by category\n",
      "   134        71       104491   1471.7      1.3      cat_groups = meta.groupby(cat).groups\n",
      "   135                                           \n",
      "   136                                               # Handles the order argument\n",
      "   137        71          119      1.7      0.0      if order is None:\n",
      "   138                                                   order = sorted(cat_groups.keys())\n",
      "   139        71          702      9.9      0.0      order = np.array(order)\n",
      "   140        71          103      1.5      0.0      num_groups = len(order)\n",
      "   141                                           \n",
      "   142                                               # Determines the number of samples, and the experimental and control group\n",
      "   143       213         1506      7.1      0.0      group_size = np.array([len(cat_groups[o]) for o in order])\n",
      "   144        71         7871    110.9      0.1      ctrl_name = order[group_size == group_size.min()][0]\n",
      "   145        71         2014     28.4      0.0      order = order[order != ctrl_name]\n",
      "   146                                           \n",
      "   147                                               # Gets a control group table\n",
      "   148        71       241593   3402.7      3.0      ctrl_match_groups = meta.groupby(control_cats).groups\n",
      "   149        71       132131   1861.0      1.6      ctrl_group = meta.loc[cat_groups[ctrl_name]\n",
      "   150        71       167328   2356.7      2.1                            ].groupby(list(control_cats)).groups\n",
      "   151                                           \n",
      "   152        71          491      6.9      0.0      ids = [np.array([])] * num_groups\n",
      "   153                                               # Loops through samples in the experimental group to match for controls\n",
      "   154      5964         8680      1.5      0.1      for check_group, ctrl_ids in viewitems(ctrl_group):\n",
      "   155                                                   # Checks the categories have been defined\n",
      "   156     29465       114558      3.9      1.4          undefed_check = np.array([_check_strs(p) for p in check_group])\n",
      "   157      5893        50369      8.5      0.6          if not undefed_check.all() and strict_match:\n",
      "   158       142          138      1.0      0.0              continue\n",
      "   159                                                   # Removes the matched ids from order\n",
      "   160      5751         9005      1.6      0.1          matched_ids = ctrl_match_groups[check_group]\n",
      "   161     13703        12695      0.9      0.2          for id_ in ctrl_ids:\n",
      "   162      7952        12754      1.6      0.2              matched_ids.remove(id_)\n",
      "   163      5751         5167      0.9      0.1          pos_ids = []\n",
      "   164      5751         7741      1.3      0.1          num_ids = [len(ctrl_ids)]\n",
      "   165                                                   # Gets the matrix of the matched ids and groups them\n",
      "   166      5751      6756410   1174.8     83.3          exp_group = meta.loc[matched_ids].groupby(cat).groups\n",
      "   167      8023        21836      2.7      0.3          for grp in order:\n",
      "   168                                                       # Checks group to be considered is included in the grouping\n",
      "   169      5751         6355      1.1      0.1              if grp not in exp_group:\n",
      "   170      3479         3021      0.9      0.0                  break\n",
      "   171                                                       # Gets the id associated with the group\n",
      "   172      2272         3482      1.5      0.0              pos_ids.append(exp_group[grp])\n",
      "   173      2272         4130      1.8      0.1              num_ids.append(len(exp_group[grp]))\n",
      "   174                                                   # Determines the minimum number of samples\n",
      "   175      5751        75815     13.2      0.9          num_draw = np.array(num_ids).min()\n",
      "   176                                                   # Draws samples from possible ids\n",
      "   177      5751       175607     30.5      2.2          exp_ids = [np.random.choice(ctrl_ids, num_draw, replace=False)]\n",
      "   178      5751         8020      1.4      0.1          exp_ids.extend([np.random.choice(id_, num_draw, replace=False)\n",
      "   179      8023        64387      8.0      0.8                          for id_ in pos_ids])\n",
      "   180                                           \n",
      "   181      5751         6731      1.2      0.1          if len(exp_ids) == num_groups:\n",
      "   182      6816         9945      1.5      0.1              for idx in range(num_groups):\n",
      "   183      4544        91563     20.2      1.1                  ids[idx] = np.hstack((ids[idx], exp_ids[idx]))\n",
      "   184                                           \n",
      "   185        71           55      0.8      0.0      return ids\n",
      "\n",
      "Total time: 0.029829 s\n",
      "File: <ipython-input-3-ea3fa562006d>\n",
      "Function: _check_strs at line 187\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   187                                           def _check_strs(x):\n",
      "   188                                               r\"\"\"Returns False if x is a nan and True is x is a string or number\"\"\"\n",
      "   189                                           \n",
      "   190     23572        17266      0.7     57.9      if isinstance(x, str):\n",
      "   191     23430        11664      0.5     39.1          return True\n",
      "   192       142          141      1.0      0.5      elif isinstance(x, (float, int)):\n",
      "   193       142          758      5.3      2.5          return not np.isnan(x)\n",
      "   194                                               else:\n",
      "   195                                                   raise TypeError('input must be a string, float or a nan')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I removed some error checks from _compare_distributions_pool to see what happens, and if theres an improvement.\n",
    "\n",
    "@do_profile(follow=[_compare_distributions_pool, paired_subsamples, _check_strs, subsample_paired_power_pool])\n",
    "def calc_new_etoh_pwr_pool():\n",
    "    pwr_etoh_220, cnts_etoh_220 = subsample_paired_power_pool(test_alpha,\n",
    "                                                              map_,\n",
    "                                                             'ALCOHOL_FREQUENCY',\n",
    "                                                             ['AGE_CAT', 'TYPES_OF_PLANTS', 'COLLECTION_SEASON', 'SLEEP_DURATION'],\n",
    "                                                             ['Never', 'Daily'],\n",
    "                                                             num_iter=500,\n",
    "                                                             counts_interval=2,\n",
    "                                                             min_observations=15,\n",
    "                                                             max_counts=16,\n",
    "                                                             num_cpus=4)\n",
    "results = calc_new_etoh_pwr_pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the error checks doesn't create an appreciable improvement in the running time. But, I can cut hte run time in half with the multi-processing. I'm going to move this into testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
