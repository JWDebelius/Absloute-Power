{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: J W Debelius<br/>\n",
    "**Date**: 23 August 2015<br/>\n",
    "**virtualenv**: power play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.load_extensions('calico-spell-check', 'calico-document-tools')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.load_extensions('calico-spell-check', 'calico-document-tools')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to test the effect of outliers on traditional power calculations, on emperical power calculations, and on extrapolated power. \n",
    "\n",
    "This notebook will focus on using a Case I t test as a model for introducing outliers. We will test the alternative hypotheses that\n",
    "<center><strong>H</strong><sub>0</sub>: $\\bar{x} = 0$<br>\n",
    "<strong>H</strong><sub>1</sub>: $\\bar{x} \\neq 0$</center>\n",
    "for some sample with mean $\\bar{x}$ and standard deviation, $s$, drawn from an underlying population with mean, $\\mu$ ($\\mu \\neq 0$) and variance $\\sigma^{2}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import absloute_power.utils as ap\n",
    "\n",
    "from absloute_power.traditional import calc_ttest_1\n",
    "from skbio.stats.power import subsample_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test these hypotheses using the scipy function `scipy.stats.ttest_1samp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def emp_ttest_1(samples):\n",
    "    return scipy.stats.ttest_1samp(samples[0], 0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the traditional model of power, the effect size for a sample given by\n",
    "$\\begin{align*}\n",
    "\\lambda &=\\frac{(\\bar{x} - x)}{s}\\\\\n",
    "&= \\frac{\\bar{x}}{s}\\\\\n",
    "&= \\frac{t}{\\sqrt{n}}\n",
    "\\end{align*}\\tag{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to compare the ability of the traditional post-hoc power, emperical post-hoc power and extrapolated post-hoc power to re-capiluate the traditional power calculation. We'll approach this by simuling a random population with a mean, $\\mu$ and standard devation, $\\sigma$, and then drawing a random sample of size $n$ with mean $\\bar{x}$ and standard devation $s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest_1_simulate(mu_lim, sigma_lim, count_lims):\n",
    "    # Gets the distribution parameters\n",
    "    mu = np.random.randint(*mu_lim)\n",
    "    sigma = np.random.randint(*sigma_lim)\n",
    "    n = np.random.randint(*count_lims)\n",
    "    \n",
    "    dist = mu + np.random.randn(n) * sigma\n",
    "\n",
    "    # Draws a sample that fits the parameters\n",
    "    return [mu, sigma, n], dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can design a function that will let us \"spike in\" outliers: points drawn from a distribution `offset` units above or below the central mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_outliers(dist, num_out, offset=50):\n",
    "    # Draws the offset mean\n",
    "    if num_out > 0:\n",
    "        index = np.arange(0, len(dist))\n",
    "        # Selects the points ot be outliers\n",
    "        outlier_pos = np.random.choice(np.arange(0, len(dist)), num_out, replace=False)\n",
    "        # Updates the distribution\n",
    "        dist[outlier_pos] = dist[outlier_pos] + offset\n",
    "    \n",
    "    return [num_out, offset], [dist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the function to simulate several distributions with varying numbers of outliers. We're going to draw distributions with means between 2 and 10, standard deviations between 5 and 15, and at 120 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_lims = [1, 10]\n",
    "sigma_lims = [10, 25]\n",
    "num_counts = 200\n",
    "count_lims = [num_counts, num_counts+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simulate the distributions so they have no outliers, 1%, 2%, 5%, 10% and 20% outliers. The offset mean can fall between -50 and 50 units offset from the original distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_outliers = (np.concatenate((np.array([0, 1]), np.array([0.01, 0.02, 0.05, 0.1, 0.2])*num_counts))).astype(int)\n",
    "len_out = len(num_outliers)\n",
    "offsets = [-50, -25, -10, -5, 5, 10, 25, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we draw traditional and emperical power, we'll do it starting at 5 samples up to 100 samples, counting by 5s. We draw 100 samples to calculate power for each point, and repeat this three times at each point along the curve. We'll use an alpha value of 0.05. And, we'll simulate 1000 distributions for each number of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = np.arange(10, 101, 10)\n",
    "alpha=0.05\n",
    "subsample_params = {'min_counts': 10,\n",
    "                    'max_counts': 101,\n",
    "                    'counts_interval': 10,\n",
    "                    'num_runs': 3,\n",
    "                    'num_iter': 100,\n",
    "                    'alpha_pwr': alpha}\n",
    "num_reps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the simulated populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50 0\n",
      "-50 1\n",
      "-50 2\n",
      "-50 4\n",
      "-50 10\n",
      "-50 20\n",
      "-50 40\n",
      "-25 0\n",
      "-25 1\n",
      "-25 2\n",
      "-25 4\n",
      "-25 10\n",
      "-25 20\n",
      "-25 40\n",
      "-10 0\n",
      "-10 1\n",
      "-10 2\n",
      "-10 4\n",
      "-10 10\n",
      "-10 20\n",
      "-10 40\n",
      "-5 0\n",
      "-5 1\n",
      "-5 2\n",
      "-5 4\n",
      "-5 10\n",
      "-5 20\n",
      "-5 40\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 4\n",
      "5 10\n",
      "5 20\n",
      "5 40\n",
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "10 4\n",
      "10 10\n",
      "10 20\n",
      "10 40\n",
      "25 0\n",
      "25 1\n",
      "25 2\n",
      "25 4\n",
      "25 10\n",
      "25 20\n",
      "25 40\n",
      "50 0\n",
      "50 1\n",
      "50 2\n",
      "50 4\n",
      "50 10\n",
      "50 20\n",
      "50 40\n",
      "100 0\n",
      "100 1\n",
      "100 2\n",
      "100 4\n",
      "100 10\n",
      "100 20\n",
      "100 40\n"
     ]
    }
   ],
   "source": [
    "watch = {n: {o: {'pop_params': [], 'sample_params': [], 'pop__power': [], 'base_power': [], 'samp_power': [], \n",
    "                 'empr_power': [], 'extr_power': []} for o in num_outliers} for n in offsets}\n",
    "for n in offsets:\n",
    "    for o in num_outliers:\n",
    "        v = watch[n][o]\n",
    "        for i in xrange(num_reps):\n",
    "            # Draws a sample distribution\n",
    "            params, sample = ttest_1_simulate(mu_lims, sigma_lims, count_lims)\n",
    "            base_power = calc_ttest_1(sample, x0=0, counts=counts)\n",
    "            # Spikes in outliers, if necessary\n",
    "            (num_out, offset), dist = add_outliers(sample, o, n * params[0] / params[1])\n",
    "            params.append(num_out)\n",
    "            params.append(offset)\n",
    "            # Calculates the effect using the tradtional method\n",
    "            samp_power = calc_ttest_1(dist[0], 0, counts)\n",
    "            #  Calculates the emperical power\n",
    "            empr_power, empr_counts = subsample_power(emp_ttest_1,\n",
    "                                                      dist,\n",
    "                                                      **subsample_params)\n",
    "            # Calculates the extraploted power\n",
    "            extr_power = ap.extrapolate_f(counts, empr_power, empr_counts).flatten()\n",
    "\n",
    "            #Updates watch\n",
    "            v['pop_params'].append(params)\n",
    "            v['base_power'].append(base_power)\n",
    "            v['samp_power'].append(samp_power)\n",
    "            v['empr_power'].append(empr_power.mean(0))\n",
    "            v['extr_power'].append(extr_power)\n",
    "\n",
    "        v['df1'] = pd.DataFrame(data=np.vstack((np.concatenate(v['base_power']),\n",
    "                                               np.concatenate(v['samp_power']),\n",
    "                                               np.concatenate(v['extr_power']),\n",
    "                                               np.concatenate(v['empr_power']))\n",
    "                                             ).transpose(),\n",
    "                  columns=['base', 'samp', 'extr', 'empr'])\n",
    "\n",
    "        stack = v['df1'].stack()\n",
    "        stack.name = 'value'\n",
    "        stack = pd.DataFrame(stack)\n",
    "        stack['source'] = [c[1] for c in stack.index]\n",
    "        stack['base'] = [v['df1'].loc[c[0], 'base'] for c in stack.index]\n",
    "        v['df2'] = stack.loc[stack.source.apply(lambda x: x in {'samp', 'extr', 'empr'})]\n",
    "\n",
    "        v['regA'] = ols('base ~ C(source) * value', data=v['df2']).fit()\n",
    "        v['reg1'] = ols('base ~ samp', data=v['df1']).fit()\n",
    "        v['reg2'] = ols('base ~ empr', data=v['df1']).fit()\n",
    "        v['reg3'] = ols('base ~ extr', data=v['df1']).fit()\n",
    "        v['reg4'] = ols('samp ~ extr', data=v['df1']).fit()\n",
    "        v['reg5'] = ols('samp ~ empr', data=v['df1']).fit()\n",
    "        v['reg6'] = ols('empr ~ extr', data=v['df1']).fit()\n",
    "\n",
    "        v['ancova'] = sm.stats.anova_lm(v['regA'])\n",
    "\n",
    "        watch[n][o] = v\n",
    "        print n, o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's set up a table so we can perform and ANCOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ancv_data = np.zeros((len(offsets), len(num_outliers)))\n",
    "trad_data = np.zeros((len(offsets), len(num_outliers)))\n",
    "empr_data = np.zeros((len(offsets), len(num_outliers)))\n",
    "extr_data = np.zeros((len(offsets), len(num_outliers)))\n",
    "t_mr_data = np.zeros((len(offsets), len(num_outliers)))\n",
    "t_xr_data = np.zeros((len(offsets), len(num_outliers)))\n",
    "mrxr_data = np.zeros((len(offsets), len(num_outliers)))\n",
    "\n",
    "for i, n in enumerate(offsets):\n",
    "    for j, o in enumerate(num_outliers):\n",
    "        ancv_data[i, j] = watch[n][o]['ancova'].loc['C(source):value', 'PR(>F)']\n",
    "        trad_data[i, j] = watch[n][o]['reg1'].rsquared\n",
    "        empr_data[i, j] = watch[n][o]['reg2'].rsquared\n",
    "        extr_data[i, j] = watch[n][o]['reg3'].rsquared\n",
    "        t_mr_data[i, j] = watch[n][o]['reg4'].rsquared\n",
    "        t_xr_data[i, j] = watch[n][o]['reg5'].rsquared\n",
    "        mrxr_data[i, j] = watch[n][o]['reg6'].rsquared\n",
    "\n",
    "ancova_sig = pd.DataFrame(ancv_data, index=offsets, columns=num_outliers)\n",
    "\n",
    "trad_corr = pd.DataFrame(trad_data, index=offsets, columns=num_outliers)\n",
    "empr_corr = pd.DataFrame(empr_data, index=offsets, columns=num_outliers)\n",
    "extr_corr = pd.DataFrame(extr_data, index=offsets, columns=num_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-5.0</th>\n",
       "      <td>1.243365e-64</td>\n",
       "      <td>4.178897e-71</td>\n",
       "      <td>5.845105e-47</td>\n",
       "      <td>3.678745e-63</td>\n",
       "      <td>1.405673e-38</td>\n",
       "      <td>5.917187e-44</td>\n",
       "      <td>8.164105e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.5</th>\n",
       "      <td>8.967653e-63</td>\n",
       "      <td>3.953886e-47</td>\n",
       "      <td>6.390961e-49</td>\n",
       "      <td>4.612876e-58</td>\n",
       "      <td>2.685754e-20</td>\n",
       "      <td>2.181411e-55</td>\n",
       "      <td>1.154960e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>1.489037e-45</td>\n",
       "      <td>4.258586e-69</td>\n",
       "      <td>8.657291e-49</td>\n",
       "      <td>3.756457e-69</td>\n",
       "      <td>1.111133e-44</td>\n",
       "      <td>7.502346e-48</td>\n",
       "      <td>3.942558e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.129888e-66</td>\n",
       "      <td>2.606229e-27</td>\n",
       "      <td>4.147953e-46</td>\n",
       "      <td>1.433922e-57</td>\n",
       "      <td>2.224935e-70</td>\n",
       "      <td>2.708868e-61</td>\n",
       "      <td>8.140533e-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>7.388855e-51</td>\n",
       "      <td>7.038821e-70</td>\n",
       "      <td>1.207559e-63</td>\n",
       "      <td>5.456956e-60</td>\n",
       "      <td>1.653200e-49</td>\n",
       "      <td>1.743008e-60</td>\n",
       "      <td>6.393578e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>1.383051e-37</td>\n",
       "      <td>8.664541e-60</td>\n",
       "      <td>4.167790e-50</td>\n",
       "      <td>2.347666e-72</td>\n",
       "      <td>1.129575e-64</td>\n",
       "      <td>1.271437e-24</td>\n",
       "      <td>1.553242e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>2.649160e-43</td>\n",
       "      <td>4.313342e-40</td>\n",
       "      <td>5.216238e-59</td>\n",
       "      <td>9.697428e-31</td>\n",
       "      <td>7.138316e-39</td>\n",
       "      <td>3.924606e-31</td>\n",
       "      <td>1.251638e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             4             10  \\\n",
       "-5.0   1.243365e-64  4.178897e-71  5.845105e-47  3.678745e-63  1.405673e-38   \n",
       "-2.5   8.967653e-63  3.953886e-47  6.390961e-49  4.612876e-58  2.685754e-20   \n",
       "-1.0   1.489037e-45  4.258586e-69  8.657291e-49  3.756457e-69  1.111133e-44   \n",
       " 1.0   2.129888e-66  2.606229e-27  4.147953e-46  1.433922e-57  2.224935e-70   \n",
       " 2.5   7.388855e-51  7.038821e-70  1.207559e-63  5.456956e-60  1.653200e-49   \n",
       " 5.0   1.383051e-37  8.664541e-60  4.167790e-50  2.347666e-72  1.129575e-64   \n",
       " 10.0  2.649160e-43  4.313342e-40  5.216238e-59  9.697428e-31  7.138316e-39   \n",
       "\n",
       "                 20            40  \n",
       "-5.0   5.917187e-44  8.164105e-26  \n",
       "-2.5   2.181411e-55  1.154960e-46  \n",
       "-1.0   7.502346e-48  3.942558e-47  \n",
       " 1.0   2.708868e-61  8.140533e-48  \n",
       " 2.5   1.743008e-60  6.393578e-41  \n",
       " 5.0   1.271437e-24  1.553242e-31  \n",
       " 10.0  3.924606e-31  1.251638e-14  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ancova_sig * (7 * 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  0.999,  0.995],\n",
       "       [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  0.999],\n",
       "       [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  1.   ],\n",
       "       [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  1.   ],\n",
       "       [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  0.999],\n",
       "       [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ,  0.999,  0.997],\n",
       "       [ 1.   ,  1.   ,  1.   ,  1.   ,  0.999,  0.997,  0.986]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(trad_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.992,  0.991,  0.993,  0.992,  0.992,  0.992,  0.988],\n",
       "       [ 0.993,  0.993,  0.993,  0.992,  0.993,  0.991,  0.991],\n",
       "       [ 0.992,  0.993,  0.992,  0.992,  0.993,  0.992,  0.992],\n",
       "       [ 0.992,  0.992,  0.992,  0.993,  0.993,  0.993,  0.991],\n",
       "       [ 0.993,  0.993,  0.992,  0.992,  0.992,  0.991,  0.99 ],\n",
       "       [ 0.992,  0.994,  0.993,  0.993,  0.992,  0.991,  0.988],\n",
       "       [ 0.992,  0.991,  0.992,  0.992,  0.991,  0.988,  0.977]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(empr_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
